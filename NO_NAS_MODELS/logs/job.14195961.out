
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59683
 Mean Absolute Percentage Error: 0.25453
 Training time:  0.03535
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55253
 Mean Absolute Percentage Error: 0.39635
 Training time:  0.01862
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71587
 Mean Absolute Percentage Error: 0.57650
 Training time:  0.06328
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86121
 Mean Absolute Percentage Error: 0.53731
 Training time:  0.01777
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69224
 Mean Absolute Percentage Error: 0.29209
 Training time:  0.03373
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52216
 Mean Absolute Percentage Error: 0.17590
 Training time:  0.01764
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60469
 Mean Absolute Percentage Error: 0.22746
 Training time:  0.08406
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61097
 Mean Absolute Percentage Error: 0.25818
 Training time:  0.01749
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54014
 Mean Absolute Percentage Error: 0.17925
 Training time:  0.17723
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67733
 Mean Absolute Percentage Error: 0.21839
 Training time:  0.03227
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61667
 Mean Absolute Percentage Error: 0.23955
 Training time:  0.15783
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65617
 Mean Absolute Percentage Error: 0.29548
 Training time:  0.02193
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60243
  MAPE on 10 nodes subset: 0.26879

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71061
  MAPE on 12 nodes subset: 0.57206

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68802
  MAPE on 15 nodes subset: 0.29333

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58611
  MAPE on 20 nodes subset: 0.22957

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52784
  MAPE on 25 nodes subset: 0.18211

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596825 0.254529       0.035348       True             4                       MLP_model_10.pkl       33
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552533 0.396347       0.018621       True             4               MLP_model_10_Circuit.pkl       33
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715867 0.576503       0.063276       True             4                       MLP_model_12.pkl       33
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861212 0.537306       0.017767       True             4               MLP_model_12_Circuit.pkl       33
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692237 0.292091       0.033727       True             3                       MLP_model_15.pkl       33
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522163 0.175898       0.017637       True             4               MLP_model_15_Circuit.pkl       33
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604692 0.227465       0.084062       True             4                       MLP_model_20.pkl       33
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.610972 0.258177       0.017487       True             4               MLP_model_20_Circuit.pkl       33
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540139 0.179253       0.177229       True             4                       MLP_model_25.pkl       33
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677333 0.218386       0.032272       True             4               MLP_model_25_Circuit.pkl       33
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616675 0.239554       0.157832       True             4                     MLP_model_full.pkl       33
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.656171 0.295485       0.021925       True             4             MLP_model_full_Circuit.pkl       33
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602425 0.268791       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710613 0.572056       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.688015 0.293328       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586115 0.229571       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.527844 0.182108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.58104
 Mean Absolute Percentage Error: 0.40931
 Training time:  0.34774
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76438
 Mean Absolute Percentage Error: 0.39694
 Training time:  0.24695
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.00174
 Mean Absolute Percentage Error: 0.67051
 Training time:  0.38088
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10408
 Mean Absolute Percentage Error: 0.66175
 Training time:  0.25912
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62815
 Mean Absolute Percentage Error: 0.19670
 Training time:  0.46839
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.81147
 Mean Absolute Percentage Error: 0.23548
 Training time:  0.25002
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.62387
 Mean Absolute Percentage Error: 0.26164
 Training time:  0.69079
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85202
 Mean Absolute Percentage Error: 0.33103
 Training time:  0.25265
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.72693
 Mean Absolute Percentage Error: 0.21331
 Training time:  0.75979
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69796
 Mean Absolute Percentage Error: 0.18817
 Training time:  0.24678
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.70989
 Mean Absolute Percentage Error: 0.30507
 Training time:  3.14067
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74910
 Mean Absolute Percentage Error: 0.29955
 Training time:  0.31559
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22871
  MAPE on 10 nodes subset: 0.02463

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34215
  MAPE on 12 nodes subset: 0.27719

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.16312
  MAPE on 15 nodes subset: 0.01826

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.36317
  MAPE on 20 nodes subset: 0.07933

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.21500
  MAPE on 25 nodes subset: 0.02689

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.581038 0.409309       0.347736                           xgboost_model_10.pkl       94
       10             Circuit            50           5          4 0.764376 0.396937       0.246947                   xgboost_model_10_Circuit.pkl       94
       12            Q_values            50          78          4 1.001741 0.670506       0.380881                           xgboost_model_12.pkl       94
       12             Circuit            50           5          4 1.104079 0.661745       0.259120                   xgboost_model_12_Circuit.pkl       94
       15            Q_values            50         120          4 0.628151 0.196704       0.468387                           xgboost_model_15.pkl       94
       15             Circuit            50           5          4 0.811472 0.235476       0.250018                   xgboost_model_15_Circuit.pkl       94
       20            Q_values            50         210          4 0.623869 0.261642       0.690787                           xgboost_model_20.pkl       94
       20             Circuit            50           5          4 0.852024 0.331028       0.252647                   xgboost_model_20_Circuit.pkl       94
       25            Q_values            50         325          4 0.726927 0.213313       0.759788                           xgboost_model_25.pkl       94
       25             Circuit            50           5          4 0.697962 0.188174       0.246782                   xgboost_model_25_Circuit.pkl       94
     full            Q_values           250         325          4 0.709894 0.305071       3.140669                         xgboost_model_full.pkl       94
     full             Circuit           250           5          4 0.749103 0.299553       0.315594                 xgboost_model_full_Circuit.pkl       94
       10 Q_values_full_model            50         325          4 0.228707 0.024626       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       12 Q_values_full_model            50         325          4 0.342154 0.277193       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       15 Q_values_full_model            50         325          4 0.163121 0.018256       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       20 Q_values_full_model            50         325          4 0.363167 0.079335       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       25 Q_values_full_model            50         325          4 0.215005 0.026890       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.7771
Epoch 002, Loss: 0.5594
Epoch 003, Loss: 0.5871
Epoch 004, Loss: 0.5866
Epoch 005, Loss: 0.5955
Epoch 006, Loss: 0.5637
Epoch 007, Loss: 0.5836
Epoch 008, Loss: 0.5778
Epoch 009, Loss: 0.6565
Epoch 010, Loss: 0.5835
Epoch 011, Loss: 0.6089
Epoch 012, Loss: 0.6321
Epoch 013, Loss: 0.5664
Epoch 014, Loss: 0.5685
Epoch 015, Loss: 0.5767
Epoch 016, Loss: 0.5711
Epoch 017, Loss: 0.6119
Epoch 018, Loss: 0.5830
Epoch 019, Loss: 0.5443
Epoch 020, Loss: 0.5737
Epoch 021, Loss: 0.5339
Epoch 022, Loss: 0.5890
Epoch 023, Loss: 0.5481
Epoch 024, Loss: 0.5636
Epoch 025, Loss: 0.5594
Epoch 026, Loss: 0.5605
Epoch 027, Loss: 0.5568
Epoch 028, Loss: 0.5621
Epoch 029, Loss: 0.5646
Epoch 030, Loss: 0.5461
Epoch 031, Loss: 0.5688
Epoch 032, Loss: 0.5457
Epoch 033, Loss: 0.5863
Epoch 034, Loss: 0.5657
Epoch 035, Loss: 0.5390
Epoch 036, Loss: 0.5457
Epoch 037, Loss: 0.5710
Epoch 038, Loss: 0.5663
Epoch 039, Loss: 0.5385
Epoch 040, Loss: 0.5216
Epoch 041, Loss: 0.5430
Epoch 042, Loss: 0.5605
Epoch 043, Loss: 0.5415
Epoch 044, Loss: 0.5287
Epoch 045, Loss: 0.5361
Epoch 046, Loss: 0.5579
Epoch 047, Loss: 0.5330
Epoch 048, Loss: 0.5584
Epoch 049, Loss: 0.5022
Epoch 050, Loss: 0.5978
Epoch 051, Loss: 0.5517
Epoch 052, Loss: 0.5341
Epoch 053, Loss: 0.5157
Epoch 054, Loss: 0.5473
Epoch 055, Loss: 0.5322
Epoch 056, Loss: 0.5403
Epoch 057, Loss: 0.5184
Epoch 058, Loss: 0.5142
Epoch 059, Loss: 0.5260
Epoch 060, Loss: 0.5158
Epoch 061, Loss: 0.4978
Epoch 062, Loss: 0.5335
Epoch 063, Loss: 0.5140
Epoch 064, Loss: 0.5191
Epoch 065, Loss: 0.5142
Epoch 066, Loss: 0.5158
Epoch 067, Loss: 0.5101
Epoch 068, Loss: 0.5193
Epoch 069, Loss: 0.5330
Epoch 070, Loss: 0.5268
Epoch 071, Loss: 0.5290
Epoch 072, Loss: 0.5136
Epoch 073, Loss: 0.5133
Epoch 074, Loss: 0.5028
Epoch 075, Loss: 0.5011
Epoch 076, Loss: 0.4943
Epoch 077, Loss: 0.5049
Epoch 078, Loss: 0.4986
Epoch 079, Loss: 0.5284
Epoch 080, Loss: 0.4988
Epoch 081, Loss: 0.4965
Epoch 082, Loss: 0.4963
Epoch 083, Loss: 0.4827
Epoch 084, Loss: 0.4956
Epoch 085, Loss: 0.5091
Epoch 086, Loss: 0.5172
Epoch 087, Loss: 0.4951
Epoch 088, Loss: 0.5074
Epoch 089, Loss: 0.4930
Epoch 090, Loss: 0.5056
Epoch 091, Loss: 0.4952
Epoch 092, Loss: 0.4926
Epoch 093, Loss: 0.4952
Epoch 094, Loss: 0.4870
Epoch 095, Loss: 0.4721
Epoch 096, Loss: 0.4842
Epoch 097, Loss: 0.4913
Epoch 098, Loss: 0.4680
Epoch 099, Loss: 0.4907
Epoch 100, Loss: 0.4899

Test RMSE: 0.6189
Test MAPE: 0.2154
Training time: 15.65 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.2493
Epoch 002, Loss: 0.9208
Epoch 003, Loss: 0.8839
Epoch 004, Loss: 0.8499
Epoch 005, Loss: 0.9235
Epoch 006, Loss: 0.9468
Epoch 007, Loss: 0.8621
Epoch 008, Loss: 0.8533
Epoch 009, Loss: 0.8367
Epoch 010, Loss: 0.8271
Epoch 011, Loss: 0.8525
Epoch 012, Loss: 0.8741
Epoch 013, Loss: 0.8411
Epoch 014, Loss: 0.8369
Epoch 015, Loss: 0.8241
Epoch 016, Loss: 0.8502
Epoch 017, Loss: 0.8919
Epoch 018, Loss: 0.8349
Epoch 019, Loss: 0.8332
Epoch 020, Loss: 0.8541
Epoch 021, Loss: 0.8486
Epoch 022, Loss: 0.8172
Epoch 023, Loss: 0.8365
Epoch 024, Loss: 0.8785
Epoch 025, Loss: 0.8830
Epoch 026, Loss: 0.8030
Epoch 027, Loss: 0.8828
Epoch 028, Loss: 0.8008
Epoch 029, Loss: 0.8609
Epoch 030, Loss: 0.8623
Epoch 031, Loss: 0.7964
Epoch 032, Loss: 0.8182
Epoch 033, Loss: 0.7959
Epoch 034, Loss: 0.9199
Epoch 035, Loss: 0.8548
Epoch 036, Loss: 0.8700
Epoch 037, Loss: 0.8122
Epoch 038, Loss: 0.8209
Epoch 039, Loss: 0.8626
Epoch 040, Loss: 0.8339
Epoch 041, Loss: 0.8037
Epoch 042, Loss: 0.8054
Epoch 043, Loss: 0.8301
Epoch 044, Loss: 0.7967
Epoch 045, Loss: 0.8752
Epoch 046, Loss: 0.7865
Epoch 047, Loss: 0.7689
Epoch 048, Loss: 0.7711
Epoch 049, Loss: 0.8257
Epoch 050, Loss: 0.7696
Epoch 051, Loss: 0.7572
Epoch 052, Loss: 0.7745
Epoch 053, Loss: 0.8275
Epoch 054, Loss: 0.7550
Epoch 055, Loss: 0.7710
Epoch 056, Loss: 0.7594
Epoch 057, Loss: 0.7166
Epoch 058, Loss: 0.7235
Epoch 059, Loss: 0.7380
Epoch 060, Loss: 0.7762
Epoch 061, Loss: 0.7343
Epoch 062, Loss: 0.7347
Epoch 063, Loss: 0.7541
Epoch 064, Loss: 0.7430
Epoch 065, Loss: 0.7432
Epoch 066, Loss: 0.7326
Epoch 067, Loss: 0.6981
Epoch 068, Loss: 0.7184
Epoch 069, Loss: 0.7117
Epoch 070, Loss: 0.6997
Epoch 071, Loss: 0.7026
Epoch 072, Loss: 0.6775
Epoch 073, Loss: 0.7021
Epoch 074, Loss: 0.6842
Epoch 075, Loss: 0.6756
Epoch 076, Loss: 0.7192
Epoch 077, Loss: 0.7213
Epoch 078, Loss: 0.6955
Epoch 079, Loss: 0.6688
Epoch 080, Loss: 0.6674
Epoch 081, Loss: 0.6572
Epoch 082, Loss: 0.6440
Epoch 083, Loss: 0.6336
Epoch 084, Loss: 0.6330
Epoch 085, Loss: 0.6271
Epoch 086, Loss: 0.6246
Epoch 087, Loss: 0.6345
Epoch 088, Loss: 0.6335
Epoch 089, Loss: 0.6467
Epoch 090, Loss: 0.6444
Epoch 091, Loss: 0.6454
Epoch 092, Loss: 0.6778
Epoch 093, Loss: 0.6098
Epoch 094, Loss: 0.6241
Epoch 095, Loss: 0.6182
Epoch 096, Loss: 0.6124
Epoch 097, Loss: 0.6107
Epoch 098, Loss: 0.6084
Epoch 099, Loss: 0.6031
Epoch 100, Loss: 0.5929

Test RMSE: 0.6600
Test MAPE: 0.2140
Training time: 15.89 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.9900
Epoch 002, Loss: 0.9118
Epoch 003, Loss: 1.0036
Epoch 004, Loss: 0.9965
Epoch 005, Loss: 0.9962
Epoch 006, Loss: 0.9073
Epoch 007, Loss: 0.9623
Epoch 008, Loss: 0.9045
Epoch 009, Loss: 0.9414
Epoch 010, Loss: 0.9020
Epoch 011, Loss: 0.9426
Epoch 012, Loss: 0.9373
Epoch 013, Loss: 0.9219
Epoch 014, Loss: 0.9067
Epoch 015, Loss: 0.9775
Epoch 016, Loss: 0.9634
Epoch 017, Loss: 0.9793
Epoch 018, Loss: 0.9247
Epoch 019, Loss: 0.9281
Epoch 020, Loss: 0.8994
Epoch 021, Loss: 0.9780
Epoch 022, Loss: 1.0354
Epoch 023, Loss: 0.9298
Epoch 024, Loss: 0.8554
Epoch 025, Loss: 0.8801
Epoch 026, Loss: 0.8470
Epoch 027, Loss: 0.9098
Epoch 028, Loss: 1.0104
Epoch 029, Loss: 0.9020
Epoch 030, Loss: 0.8316
Epoch 031, Loss: 0.8142
Epoch 032, Loss: 0.8705
Epoch 033, Loss: 0.8177
Epoch 034, Loss: 0.8615
Epoch 035, Loss: 0.8336
Epoch 036, Loss: 0.8397
Epoch 037, Loss: 0.8624
Epoch 038, Loss: 0.7884
Epoch 039, Loss: 0.8382
Epoch 040, Loss: 0.7886
Epoch 041, Loss: 0.8994
Epoch 042, Loss: 0.8447
Epoch 043, Loss: 0.7683
Epoch 044, Loss: 0.7413
Epoch 045, Loss: 0.8278
Epoch 046, Loss: 0.7564
Epoch 047, Loss: 0.7343
Epoch 048, Loss: 0.6537
Epoch 049, Loss: 0.7732
Epoch 050, Loss: 0.7662
Epoch 051, Loss: 0.7540
Epoch 052, Loss: 0.7440
Epoch 053, Loss: 0.7750
Epoch 054, Loss: 0.7729
Epoch 055, Loss: 0.8125
Epoch 056, Loss: 0.7343
Epoch 057, Loss: 0.6803
Epoch 058, Loss: 0.6450
Epoch 059, Loss: 0.6287
Epoch 060, Loss: 0.6251
Epoch 061, Loss: 0.6427
Epoch 062, Loss: 0.6282
Epoch 063, Loss: 0.5909
Epoch 064, Loss: 0.6576
Epoch 065, Loss: 0.6654
Epoch 066, Loss: 0.6312
Epoch 067, Loss: 0.6491
Epoch 068, Loss: 0.6033
Epoch 069, Loss: 0.6011
Epoch 070, Loss: 0.5920
Epoch 071, Loss: 0.6130
Epoch 072, Loss: 0.5853
Epoch 073, Loss: 0.6118
Epoch 074, Loss: 0.5575
Epoch 075, Loss: 0.5787
Epoch 076, Loss: 0.5908
Epoch 077, Loss: 0.6260
Epoch 078, Loss: 0.6129
Epoch 079, Loss: 0.6181
Epoch 080, Loss: 0.5818
Epoch 081, Loss: 0.6916
Epoch 082, Loss: 0.6046
Epoch 083, Loss: 0.5936
Epoch 084, Loss: 0.5845
Epoch 085, Loss: 0.5908
Epoch 086, Loss: 0.5446
Epoch 087, Loss: 0.5695
Epoch 088, Loss: 0.5617
Epoch 089, Loss: 0.5628
Epoch 090, Loss: 0.5371
Epoch 091, Loss: 0.5640
Epoch 092, Loss: 0.5632
Epoch 093, Loss: 0.6017
Epoch 094, Loss: 0.5398
Epoch 095, Loss: 0.5248
Epoch 096, Loss: 0.5556
Epoch 097, Loss: 0.5707
Epoch 098, Loss: 0.5322
Epoch 099, Loss: 0.5147
Epoch 100, Loss: 0.5536

Test RMSE: 0.9277
Test MAPE: 0.2032
Training time: 16.06 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 6.5184
Epoch 002, Loss: 1.3396
Epoch 003, Loss: 1.4259
Epoch 004, Loss: 1.2103
Epoch 005, Loss: 1.4421
Epoch 006, Loss: 1.2542
Epoch 007, Loss: 1.2558
Epoch 008, Loss: 1.2038
Epoch 009, Loss: 1.1996
Epoch 010, Loss: 1.4936
Epoch 011, Loss: 1.4024
Epoch 012, Loss: 1.2871
Epoch 013, Loss: 1.2844
Epoch 014, Loss: 1.2474
Epoch 015, Loss: 1.3281
Epoch 016, Loss: 1.4969
Epoch 017, Loss: 1.2448
Epoch 018, Loss: 1.3661
Epoch 019, Loss: 1.2881
Epoch 020, Loss: 1.4042
Epoch 021, Loss: 1.4884
Epoch 022, Loss: 1.2366
Epoch 023, Loss: 1.2745
Epoch 024, Loss: 1.3982
Epoch 025, Loss: 1.2004
Epoch 026, Loss: 1.4630
Epoch 027, Loss: 1.3403
Epoch 028, Loss: 1.2826
Epoch 029, Loss: 1.3351
Epoch 030, Loss: 1.3493
Epoch 031, Loss: 1.2488
Epoch 032, Loss: 1.2095
Epoch 033, Loss: 1.3669
Epoch 034, Loss: 1.3019
Epoch 035, Loss: 1.1894
Epoch 036, Loss: 1.2773
Epoch 037, Loss: 1.3072
Epoch 038, Loss: 1.2892
Epoch 039, Loss: 1.1500
Epoch 040, Loss: 1.2087
Epoch 041, Loss: 1.1337
Epoch 042, Loss: 1.1421
Epoch 043, Loss: 1.1573
Epoch 044, Loss: 1.1352
Epoch 045, Loss: 1.1298
Epoch 046, Loss: 1.1416
Epoch 047, Loss: 1.1139
Epoch 048, Loss: 1.1520
Epoch 049, Loss: 1.1283
Epoch 050, Loss: 1.0982
Epoch 051, Loss: 0.9786
Epoch 052, Loss: 1.2690
Epoch 053, Loss: 1.1043
Epoch 054, Loss: 0.9532
Epoch 055, Loss: 1.0073
Epoch 056, Loss: 0.9425
Epoch 057, Loss: 0.9346
Epoch 058, Loss: 0.8343
Epoch 059, Loss: 0.9470
Epoch 060, Loss: 0.8102
Epoch 061, Loss: 0.9085
Epoch 062, Loss: 0.8399
Epoch 063, Loss: 0.8062
Epoch 064, Loss: 0.8220
Epoch 065, Loss: 0.7446
Epoch 066, Loss: 0.7490
Epoch 067, Loss: 0.7046
Epoch 068, Loss: 0.8119
Epoch 069, Loss: 0.7200
Epoch 070, Loss: 0.6555
Epoch 071, Loss: 0.7119
Epoch 072, Loss: 0.6863
Epoch 073, Loss: 0.6338
Epoch 074, Loss: 0.6212
Epoch 075, Loss: 0.5457
Epoch 076, Loss: 0.7030
Epoch 077, Loss: 0.6465
Epoch 078, Loss: 0.5569
Epoch 079, Loss: 0.6579
Epoch 080, Loss: 0.5800
Epoch 081, Loss: 0.5918
Epoch 082, Loss: 0.5877
Epoch 083, Loss: 0.5342
Epoch 084, Loss: 0.6035
Epoch 085, Loss: 0.5269
Epoch 086, Loss: 0.5471
Epoch 087, Loss: 0.5399
Epoch 088, Loss: 0.5673
Epoch 089, Loss: 0.6141
Epoch 090, Loss: 0.6528
Epoch 091, Loss: 0.5473
Epoch 092, Loss: 0.5500
Epoch 093, Loss: 0.5321
Epoch 094, Loss: 0.5127
Epoch 095, Loss: 0.4868
Epoch 096, Loss: 0.5721
Epoch 097, Loss: 0.5875
Epoch 098, Loss: 0.5519
Epoch 099, Loss: 0.5211
Epoch 100, Loss: 0.4927

Test RMSE: 0.9280
Test MAPE: 0.2139
Training time: 16.33 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.3813
Epoch 002, Loss: 1.8659
Epoch 003, Loss: 1.7668
Epoch 004, Loss: 1.5986
Epoch 005, Loss: 1.6191
Epoch 006, Loss: 1.6346
Epoch 007, Loss: 1.6182
Epoch 008, Loss: 1.7071
Epoch 009, Loss: 1.4632
Epoch 010, Loss: 1.8613
Epoch 011, Loss: 1.6838
Epoch 012, Loss: 1.5364
Epoch 013, Loss: 1.6094
Epoch 014, Loss: 1.5878
Epoch 015, Loss: 1.7495
Epoch 016, Loss: 1.5513
Epoch 017, Loss: 1.6179
Epoch 018, Loss: 1.8978
Epoch 019, Loss: 1.6811
Epoch 020, Loss: 1.6787
Epoch 021, Loss: 1.6075
Epoch 022, Loss: 1.5679
Epoch 023, Loss: 1.4841
Epoch 024, Loss: 1.5277
Epoch 025, Loss: 1.5914
Epoch 026, Loss: 1.5982
Epoch 027, Loss: 1.6686
Epoch 028, Loss: 1.4956
Epoch 029, Loss: 1.4538
Epoch 030, Loss: 1.5008
Epoch 031, Loss: 1.4559
Epoch 032, Loss: 1.5676
Epoch 033, Loss: 1.7226
Epoch 034, Loss: 1.8071
Epoch 035, Loss: 1.5068
Epoch 036, Loss: 1.9051
Epoch 037, Loss: 1.8545
Epoch 038, Loss: 1.5435
Epoch 039, Loss: 1.5456
Epoch 040, Loss: 1.6474
Epoch 041, Loss: 1.4467
Epoch 042, Loss: 1.4948
Epoch 043, Loss: 1.4735
Epoch 044, Loss: 1.5572
Epoch 045, Loss: 1.5268
Epoch 046, Loss: 1.5340
Epoch 047, Loss: 1.5394
Epoch 048, Loss: 1.4578
Epoch 049, Loss: 1.4738
Epoch 050, Loss: 1.6583
Epoch 051, Loss: 1.4769
Epoch 052, Loss: 1.4605
Epoch 053, Loss: 1.7828
Epoch 054, Loss: 1.6963
Epoch 055, Loss: 1.4403
Epoch 056, Loss: 1.6589
Epoch 057, Loss: 1.3919
Epoch 058, Loss: 1.4226
Epoch 059, Loss: 1.4740
Epoch 060, Loss: 1.5577
Epoch 061, Loss: 1.6096
Epoch 062, Loss: 1.6626
Epoch 063, Loss: 1.4331
Epoch 064, Loss: 1.4830
Epoch 065, Loss: 1.5311
Epoch 066, Loss: 1.4761
Epoch 067, Loss: 1.4651
Epoch 068, Loss: 1.4273
Epoch 069, Loss: 1.6850
Epoch 070, Loss: 1.5036
Epoch 071, Loss: 1.6233
Epoch 072, Loss: 1.8184
Epoch 073, Loss: 1.4200
Epoch 074, Loss: 1.4026
Epoch 075, Loss: 1.4695
Epoch 076, Loss: 1.3597
Epoch 077, Loss: 1.3726
Epoch 078, Loss: 1.5433
Epoch 079, Loss: 1.6540
Epoch 080, Loss: 1.4158
Epoch 081, Loss: 1.4169
Epoch 082, Loss: 1.7482
Epoch 083, Loss: 1.5256
Epoch 084, Loss: 1.3705
Epoch 085, Loss: 1.6309
Epoch 086, Loss: 1.5218
Epoch 087, Loss: 1.5314
Epoch 088, Loss: 1.4125
Epoch 089, Loss: 1.4301
Epoch 090, Loss: 1.4463
Epoch 091, Loss: 1.4049
Epoch 092, Loss: 1.6044
Epoch 093, Loss: 1.4145
Epoch 094, Loss: 1.3596
Epoch 095, Loss: 1.3675
Epoch 096, Loss: 1.5550
Epoch 097, Loss: 1.4285
Epoch 098, Loss: 1.4557
Epoch 099, Loss: 1.4521
Epoch 100, Loss: 1.5173

Test RMSE: 1.4763
Test MAPE: 0.2127
Training time: 16.93 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8072
Epoch 002, Loss: 3.3648
Epoch 003, Loss: 2.8569
Epoch 004, Loss: 1.2915
Epoch 005, Loss: 0.9405
Epoch 006, Loss: 0.7613
Epoch 007, Loss: 0.6768
Epoch 008, Loss: 0.6741
Epoch 009, Loss: 0.7263
Epoch 010, Loss: 0.6582
Epoch 011, Loss: 0.6439
Epoch 012, Loss: 0.6759
Epoch 013, Loss: 0.6559
Epoch 014, Loss: 0.6449
Epoch 015, Loss: 0.6654
Epoch 016, Loss: 0.6895
Epoch 017, Loss: 0.6289
Epoch 018, Loss: 0.6562
Epoch 019, Loss: 0.6101
Epoch 020, Loss: 0.6093
Epoch 021, Loss: 0.7691
Epoch 022, Loss: 0.5913
Epoch 023, Loss: 0.6706
Epoch 024, Loss: 0.6232
Epoch 025, Loss: 0.6097
Epoch 026, Loss: 0.6293
Epoch 027, Loss: 0.5862
Epoch 028, Loss: 0.5880
Epoch 029, Loss: 0.6039
Epoch 030, Loss: 0.5892
Epoch 031, Loss: 0.5415
Epoch 032, Loss: 0.5443
Epoch 033, Loss: 0.6024
Epoch 034, Loss: 0.6214
Epoch 035, Loss: 0.6168
Epoch 036, Loss: 0.5595
Epoch 037, Loss: 0.5835
Epoch 038, Loss: 0.5889
Epoch 039, Loss: 0.5901
Epoch 040, Loss: 0.5424
Epoch 041, Loss: 0.6008
Epoch 042, Loss: 0.6452
Epoch 043, Loss: 0.5899
Epoch 044, Loss: 0.5594
Epoch 045, Loss: 0.6199
Epoch 046, Loss: 0.5749
Epoch 047, Loss: 0.5440
Epoch 048, Loss: 0.5932
Epoch 049, Loss: 0.5684
Epoch 050, Loss: 0.5549
Epoch 051, Loss: 0.5537
Epoch 052, Loss: 0.5575
Epoch 053, Loss: 0.5442
Epoch 054, Loss: 0.5881
Epoch 055, Loss: 0.5280
Epoch 056, Loss: 0.5832
Epoch 057, Loss: 0.5510
Epoch 058, Loss: 0.5334
Epoch 059, Loss: 0.5464
Epoch 060, Loss: 0.5681
Epoch 061, Loss: 0.5188
Epoch 062, Loss: 0.5449
Epoch 063, Loss: 0.5647
Epoch 064, Loss: 0.5196
Epoch 065, Loss: 0.5543
Epoch 066, Loss: 0.5590
Epoch 067, Loss: 0.5381
Epoch 068, Loss: 0.5118
Epoch 069, Loss: 0.5357
Epoch 070, Loss: 0.5355
Epoch 071, Loss: 0.5702
Epoch 072, Loss: 0.5062
Epoch 073, Loss: 0.5317
Epoch 074, Loss: 0.5320
Epoch 075, Loss: 0.5879
Epoch 076, Loss: 0.5654
Epoch 077, Loss: 0.5138
Epoch 078, Loss: 0.5450
Epoch 079, Loss: 0.5309
Epoch 080, Loss: 0.5149
Epoch 081, Loss: 0.5256
Epoch 082, Loss: 0.5459
Epoch 083, Loss: 0.5297
Epoch 084, Loss: 0.5019
Epoch 085, Loss: 0.5369
Epoch 086, Loss: 0.5016
Epoch 087, Loss: 0.5522
Epoch 088, Loss: 0.5277
Epoch 089, Loss: 0.4772
Epoch 090, Loss: 0.4944
Epoch 091, Loss: 0.5545
Epoch 092, Loss: 0.5269
Epoch 093, Loss: 0.5342
Epoch 094, Loss: 0.5132
Epoch 095, Loss: 0.4902
Epoch 096, Loss: 0.5173
Epoch 097, Loss: 0.5088
Epoch 098, Loss: 0.5304
Epoch 099, Loss: 0.5847
Epoch 100, Loss: 0.4948

Test RMSE: 0.6917
Test MAPE: 233590788980736.0000
Training time: 82.18 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.618921 2.154066e-01      15.653487   GNN_model_10.pkl
       12   Q_values        0.2 0.659956 2.140332e-01      15.890072   GNN_model_12.pkl
       15   Q_values        0.2 0.927743 2.032140e-01      16.062157   GNN_model_15.pkl
       20   Q_values        0.2 0.928034 2.138812e-01      16.330402   GNN_model_20.pkl
       25   Q_values        0.2 1.476260 2.127171e-01      16.933577   GNN_model_25.pkl
     full   Q_values        0.2 0.691716 2.335908e+14      82.178015 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 62%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
