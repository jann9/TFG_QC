
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59027
 Mean Absolute Percentage Error: 0.24490
 Training time:  0.11806
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55243
 Mean Absolute Percentage Error: 0.39706
 Training time:  0.09309
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71498
 Mean Absolute Percentage Error: 0.57831
 Training time:  0.12927
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86368
 Mean Absolute Percentage Error: 0.53903
 Training time:  0.03129
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69621
 Mean Absolute Percentage Error: 0.29591
 Training time:  0.06539
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52302
 Mean Absolute Percentage Error: 0.17675
 Training time:  0.10944
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60334
 Mean Absolute Percentage Error: 0.22743
 Training time:  0.09789
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61152
 Mean Absolute Percentage Error: 0.25914
 Training time:  0.09786
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54036
 Mean Absolute Percentage Error: 0.17968
 Training time:  0.15582
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67457
 Mean Absolute Percentage Error: 0.21857
 Training time:  0.03108
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61698
 Mean Absolute Percentage Error: 0.23996
 Training time:  0.14962
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65463
 Mean Absolute Percentage Error: 0.29613
 Training time:  0.02087
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60257
  MAPE on 10 nodes subset: 0.26839

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71069
  MAPE on 12 nodes subset: 0.57138

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68775
  MAPE on 15 nodes subset: 0.29240

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58571
  MAPE on 20 nodes subset: 0.22741

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53446
  MAPE on 25 nodes subset: 0.18741

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.590273 0.244901       0.118063       True             3                       MLP_model_10.pkl       66
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552432 0.397059       0.093094       True             4               MLP_model_10_Circuit.pkl       66
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.714980 0.578314       0.129267       True             4                       MLP_model_12.pkl       66
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863678 0.539033       0.031290       True             4               MLP_model_12_Circuit.pkl       66
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.696209 0.295914       0.065392       True             3                       MLP_model_15.pkl       66
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.523023 0.176749       0.109441       True             4               MLP_model_15_Circuit.pkl       66
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.603335 0.227429       0.097894       True             4                       MLP_model_20.pkl       66
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611525 0.259142       0.097865       True             4               MLP_model_20_Circuit.pkl       66
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540357 0.179680       0.155823       True             4                       MLP_model_25.pkl       66
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674573 0.218572       0.031085       True             4               MLP_model_25_Circuit.pkl       66
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616976 0.239961       0.149623       True             4                     MLP_model_full.pkl       66
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654632 0.296125       0.020874       True             4             MLP_model_full_Circuit.pkl       66
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602574 0.268394       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       66
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710686 0.571380       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       66
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.687749 0.292405       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       66
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585711 0.227411       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       66
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534462 0.187412       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       66

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59539
 Mean Absolute Percentage Error: 0.43709
 Training time:  0.40724
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76245
 Mean Absolute Percentage Error: 0.39529
 Training time:  0.23895
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.01438
 Mean Absolute Percentage Error: 0.68791
 Training time:  0.35999
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.09625
 Mean Absolute Percentage Error: 0.65901
 Training time:  0.24425
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.63304
 Mean Absolute Percentage Error: 0.19574
 Training time:  0.44453
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79546
 Mean Absolute Percentage Error: 0.23034
 Training time:  0.24229
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.66188
 Mean Absolute Percentage Error: 0.27976
 Training time:  0.61815
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85027
 Mean Absolute Percentage Error: 0.33096
 Training time:  0.23894
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74231
 Mean Absolute Percentage Error: 0.23064
 Training time:  0.69582
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70250
 Mean Absolute Percentage Error: 0.18852
 Training time:  0.23878
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71333
 Mean Absolute Percentage Error: 0.30248
 Training time:  2.92519
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74912
 Mean Absolute Percentage Error: 0.29928
 Training time:  0.30489
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22549
  MAPE on 10 nodes subset: 0.02577

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.33541
  MAPE on 12 nodes subset: 0.27042

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13284
  MAPE on 15 nodes subset: 0.01673

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39095
  MAPE on 20 nodes subset: 0.09186

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19462
  MAPE on 25 nodes subset: 0.02457

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.595385 0.437094       0.407236                           xgboost_model_10.pkl       35
       10             Circuit            50           5          4 0.762453 0.395286       0.238953                   xgboost_model_10_Circuit.pkl       35
       12            Q_values            50          78          4 1.014379 0.687913       0.359992                           xgboost_model_12.pkl       35
       12             Circuit            50           5          4 1.096255 0.659014       0.244249                   xgboost_model_12_Circuit.pkl       35
       15            Q_values            50         120          4 0.633041 0.195740       0.444534                           xgboost_model_15.pkl       35
       15             Circuit            50           5          4 0.795456 0.230344       0.242295                   xgboost_model_15_Circuit.pkl       35
       20            Q_values            50         210          4 0.661880 0.279755       0.618153                           xgboost_model_20.pkl       35
       20             Circuit            50           5          4 0.850266 0.330959       0.238940                   xgboost_model_20_Circuit.pkl       35
       25            Q_values            50         325          4 0.742313 0.230639       0.695821                           xgboost_model_25.pkl       35
       25             Circuit            50           5          4 0.702499 0.188516       0.238783                   xgboost_model_25_Circuit.pkl       35
     full            Q_values           250         325          4 0.713325 0.302484       2.925190                         xgboost_model_full.pkl       35
     full             Circuit           250           5          4 0.749121 0.299279       0.304894                 xgboost_model_full_Circuit.pkl       35
       10 Q_values_full_model            50         325          4 0.225489 0.025774       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       12 Q_values_full_model            50         325          4 0.335413 0.270422       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       15 Q_values_full_model            50         325          4 0.132837 0.016726       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       20 Q_values_full_model            50         325          4 0.390947 0.091857       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       25 Q_values_full_model            50         325          4 0.194622 0.024565       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.9398
Epoch 002, Loss: 0.5867
Epoch 003, Loss: 0.6209
Epoch 004, Loss: 0.5629
Epoch 005, Loss: 0.5831
Epoch 006, Loss: 0.6237
Epoch 007, Loss: 0.6648
Epoch 008, Loss: 0.5815
Epoch 009, Loss: 0.5533
Epoch 010, Loss: 0.5910
Epoch 011, Loss: 0.5769
Epoch 012, Loss: 0.6079
Epoch 013, Loss: 0.6029
Epoch 014, Loss: 0.5762
Epoch 015, Loss: 0.5609
Epoch 016, Loss: 0.5935
Epoch 017, Loss: 0.5620
Epoch 018, Loss: 0.5736
Epoch 019, Loss: 0.5846
Epoch 020, Loss: 0.5537
Epoch 021, Loss: 0.5554
Epoch 022, Loss: 0.5952
Epoch 023, Loss: 0.5978
Epoch 024, Loss: 0.5953
Epoch 025, Loss: 0.5586
Epoch 026, Loss: 0.5619
Epoch 027, Loss: 0.5212
Epoch 028, Loss: 0.5406
Epoch 029, Loss: 0.5486
Epoch 030, Loss: 0.5940
Epoch 031, Loss: 0.5298
Epoch 032, Loss: 0.5218
Epoch 033, Loss: 0.5636
Epoch 034, Loss: 0.5484
Epoch 035, Loss: 0.5059
Epoch 036, Loss: 0.5144
Epoch 037, Loss: 0.5513
Epoch 038, Loss: 0.5121
Epoch 039, Loss: 0.5052
Epoch 040, Loss: 0.5082
Epoch 041, Loss: 0.4870
Epoch 042, Loss: 0.4984
Epoch 043, Loss: 0.5352
Epoch 044, Loss: 0.4946
Epoch 045, Loss: 0.5106
Epoch 046, Loss: 0.4819
Epoch 047, Loss: 0.5280
Epoch 048, Loss: 0.4875
Epoch 049, Loss: 0.5159
Epoch 050, Loss: 0.5062
Epoch 051, Loss: 0.5157
Epoch 052, Loss: 0.5194
Epoch 053, Loss: 0.4887
Epoch 054, Loss: 0.4866
Epoch 055, Loss: 0.4839
Epoch 056, Loss: 0.4751
Epoch 057, Loss: 0.4891
Epoch 058, Loss: 0.4891
Epoch 059, Loss: 0.4804
Epoch 060, Loss: 0.4598
Epoch 061, Loss: 0.4725
Epoch 062, Loss: 0.4783
Epoch 063, Loss: 0.4750
Epoch 064, Loss: 0.4851
Epoch 065, Loss: 0.4774
Epoch 066, Loss: 0.4821
Epoch 067, Loss: 0.5181
Epoch 068, Loss: 0.4862
Epoch 069, Loss: 0.4478
Epoch 070, Loss: 0.4474
Epoch 071, Loss: 0.4607
Epoch 072, Loss: 0.4462
Epoch 073, Loss: 0.4399
Epoch 074, Loss: 0.4571
Epoch 075, Loss: 0.4450
Epoch 076, Loss: 0.4835
Epoch 077, Loss: 0.4473
Epoch 078, Loss: 0.4465
Epoch 079, Loss: 0.4608
Epoch 080, Loss: 0.4335
Epoch 081, Loss: 0.4281
Epoch 082, Loss: 0.4283
Epoch 083, Loss: 0.4357
Epoch 084, Loss: 0.4399
Epoch 085, Loss: 0.4217
Epoch 086, Loss: 0.4148
Epoch 087, Loss: 0.4017
Epoch 088, Loss: 0.4045
Epoch 089, Loss: 0.4271
Epoch 090, Loss: 0.4349
Epoch 091, Loss: 0.4000
Epoch 092, Loss: 0.4361
Epoch 093, Loss: 0.4317
Epoch 094, Loss: 0.4180
Epoch 095, Loss: 0.4286
Epoch 096, Loss: 0.4054
Epoch 097, Loss: 0.4006
Epoch 098, Loss: 0.4203
Epoch 099, Loss: 0.4019
Epoch 100, Loss: 0.4006

Test RMSE: 0.6154
Test MAPE: 0.2215
Training time: 12.15 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.3460
Epoch 002, Loss: 0.9268
Epoch 003, Loss: 0.9898
Epoch 004, Loss: 0.8797
Epoch 005, Loss: 0.8788
Epoch 006, Loss: 0.9118
Epoch 007, Loss: 0.8905
Epoch 008, Loss: 0.8816
Epoch 009, Loss: 0.8762
Epoch 010, Loss: 0.8802
Epoch 011, Loss: 0.8700
Epoch 012, Loss: 0.8625
Epoch 013, Loss: 0.8352
Epoch 014, Loss: 0.8871
Epoch 015, Loss: 0.8977
Epoch 016, Loss: 0.9157
Epoch 017, Loss: 0.8478
Epoch 018, Loss: 0.8520
Epoch 019, Loss: 0.8428
Epoch 020, Loss: 0.8370
Epoch 021, Loss: 0.8504
Epoch 022, Loss: 0.8290
Epoch 023, Loss: 0.8691
Epoch 024, Loss: 0.7762
Epoch 025, Loss: 0.8089
Epoch 026, Loss: 0.8759
Epoch 027, Loss: 0.8716
Epoch 028, Loss: 0.8290
Epoch 029, Loss: 0.8602
Epoch 030, Loss: 0.8155
Epoch 031, Loss: 0.8304
Epoch 032, Loss: 0.8924
Epoch 033, Loss: 0.9821
Epoch 034, Loss: 0.8196
Epoch 035, Loss: 0.8997
Epoch 036, Loss: 0.8508
Epoch 037, Loss: 0.8747
Epoch 038, Loss: 0.8740
Epoch 039, Loss: 0.8335
Epoch 040, Loss: 0.8020
Epoch 041, Loss: 0.8459
Epoch 042, Loss: 0.8595
Epoch 043, Loss: 0.8216
Epoch 044, Loss: 0.8391
Epoch 045, Loss: 0.8342
Epoch 046, Loss: 0.8817
Epoch 047, Loss: 0.7883
Epoch 048, Loss: 0.8503
Epoch 049, Loss: 0.8000
Epoch 050, Loss: 0.7866
Epoch 051, Loss: 0.8412
Epoch 052, Loss: 0.8316
Epoch 053, Loss: 0.8147
Epoch 054, Loss: 0.8172
Epoch 055, Loss: 0.8343
Epoch 056, Loss: 0.8117
Epoch 057, Loss: 0.8342
Epoch 058, Loss: 0.8173
Epoch 059, Loss: 0.8049
Epoch 060, Loss: 0.7888
Epoch 061, Loss: 0.7825
Epoch 062, Loss: 0.7632
Epoch 063, Loss: 0.8098
Epoch 064, Loss: 0.8554
Epoch 065, Loss: 0.7795
Epoch 066, Loss: 0.8229
Epoch 067, Loss: 0.7962
Epoch 068, Loss: 0.7539
Epoch 069, Loss: 0.7555
Epoch 070, Loss: 0.7336
Epoch 071, Loss: 0.7520
Epoch 072, Loss: 0.7297
Epoch 073, Loss: 0.7325
Epoch 074, Loss: 0.7248
Epoch 075, Loss: 0.7161
Epoch 076, Loss: 0.7209
Epoch 077, Loss: 0.7210
Epoch 078, Loss: 0.7067
Epoch 079, Loss: 0.7799
Epoch 080, Loss: 0.7363
Epoch 081, Loss: 0.7087
Epoch 082, Loss: 0.6680
Epoch 083, Loss: 0.6819
Epoch 084, Loss: 0.6717
Epoch 085, Loss: 0.6958
Epoch 086, Loss: 0.6746
Epoch 087, Loss: 0.6744
Epoch 088, Loss: 0.6731
Epoch 089, Loss: 0.6560
Epoch 090, Loss: 0.6829
Epoch 091, Loss: 0.6548
Epoch 092, Loss: 0.6658
Epoch 093, Loss: 0.6374
Epoch 094, Loss: 0.6346
Epoch 095, Loss: 0.6410
Epoch 096, Loss: 0.6133
Epoch 097, Loss: 0.6541
Epoch 098, Loss: 0.6014
Epoch 099, Loss: 0.6419
Epoch 100, Loss: 0.6382

Test RMSE: 0.6297
Test MAPE: 0.2004
Training time: 12.03 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 5.0929
Epoch 002, Loss: 1.1622
Epoch 003, Loss: 1.0791
Epoch 004, Loss: 0.9999
Epoch 005, Loss: 1.0189
Epoch 006, Loss: 0.9456
Epoch 007, Loss: 0.9668
Epoch 008, Loss: 0.9239
Epoch 009, Loss: 0.9429
Epoch 010, Loss: 0.9146
Epoch 011, Loss: 0.9527
Epoch 012, Loss: 0.9373
Epoch 013, Loss: 0.9550
Epoch 014, Loss: 0.9251
Epoch 015, Loss: 0.9049
Epoch 016, Loss: 0.9147
Epoch 017, Loss: 0.9333
Epoch 018, Loss: 0.9140
Epoch 019, Loss: 0.9597
Epoch 020, Loss: 0.9037
Epoch 021, Loss: 0.8637
Epoch 022, Loss: 1.0023
Epoch 023, Loss: 0.9155
Epoch 024, Loss: 0.8929
Epoch 025, Loss: 0.9222
Epoch 026, Loss: 0.9555
Epoch 027, Loss: 0.9170
Epoch 028, Loss: 0.9357
Epoch 029, Loss: 0.9086
Epoch 030, Loss: 0.8744
Epoch 031, Loss: 0.9468
Epoch 032, Loss: 0.9271
Epoch 033, Loss: 0.9296
Epoch 034, Loss: 0.9068
Epoch 035, Loss: 0.8945
Epoch 036, Loss: 0.9763
Epoch 037, Loss: 0.9741
Epoch 038, Loss: 0.9013
Epoch 039, Loss: 0.8673
Epoch 040, Loss: 0.9570
Epoch 041, Loss: 0.8855
Epoch 042, Loss: 0.8675
Epoch 043, Loss: 0.8659
Epoch 044, Loss: 0.9469
Epoch 045, Loss: 0.8845
Epoch 046, Loss: 0.9214
Epoch 047, Loss: 0.9330
Epoch 048, Loss: 0.9132
Epoch 049, Loss: 0.8926
Epoch 050, Loss: 0.8608
Epoch 051, Loss: 0.8638
Epoch 052, Loss: 0.8443
Epoch 053, Loss: 0.9296
Epoch 054, Loss: 0.8656
Epoch 055, Loss: 0.9152
Epoch 056, Loss: 0.8975
Epoch 057, Loss: 0.8543
Epoch 058, Loss: 0.8395
Epoch 059, Loss: 0.8299
Epoch 060, Loss: 0.7969
Epoch 061, Loss: 0.7878
Epoch 062, Loss: 0.8129
Epoch 063, Loss: 0.7861
Epoch 064, Loss: 0.8377
Epoch 065, Loss: 0.8133
Epoch 066, Loss: 0.8674
Epoch 067, Loss: 0.8091
Epoch 068, Loss: 0.7837
Epoch 069, Loss: 0.7519
Epoch 070, Loss: 0.8168
Epoch 071, Loss: 0.7625
Epoch 072, Loss: 0.7042
Epoch 073, Loss: 0.7856
Epoch 074, Loss: 0.7038
Epoch 075, Loss: 0.7346
Epoch 076, Loss: 0.7257
Epoch 077, Loss: 0.6646
Epoch 078, Loss: 0.6708
Epoch 079, Loss: 0.7463
Epoch 080, Loss: 0.8563
Epoch 081, Loss: 0.6657
Epoch 082, Loss: 0.7033
Epoch 083, Loss: 0.6826
Epoch 084, Loss: 0.6795
Epoch 085, Loss: 0.6224
Epoch 086, Loss: 0.6848
Epoch 087, Loss: 0.7440
Epoch 088, Loss: 0.6412
Epoch 089, Loss: 0.6135
Epoch 090, Loss: 0.6451
Epoch 091, Loss: 0.6304
Epoch 092, Loss: 0.6254
Epoch 093, Loss: 0.6352
Epoch 094, Loss: 0.5761
Epoch 095, Loss: 0.6460
Epoch 096, Loss: 0.5752
Epoch 097, Loss: 0.5977
Epoch 098, Loss: 0.6005
Epoch 099, Loss: 0.5799
Epoch 100, Loss: 0.5777

Test RMSE: 0.8969
Test MAPE: 0.1993
Training time: 12.21 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.9234
Epoch 002, Loss: 1.4359
Epoch 003, Loss: 1.2520
Epoch 004, Loss: 1.2684
Epoch 005, Loss: 1.3947
Epoch 006, Loss: 1.2793
Epoch 007, Loss: 1.2268
Epoch 008, Loss: 1.4150
Epoch 009, Loss: 1.2755
Epoch 010, Loss: 1.3363
Epoch 011, Loss: 1.3452
Epoch 012, Loss: 1.1586
Epoch 013, Loss: 1.2174
Epoch 014, Loss: 1.2224
Epoch 015, Loss: 1.2892
Epoch 016, Loss: 1.3879
Epoch 017, Loss: 1.1706
Epoch 018, Loss: 1.2159
Epoch 019, Loss: 1.2158
Epoch 020, Loss: 1.1406
Epoch 021, Loss: 1.1846
Epoch 022, Loss: 1.1629
Epoch 023, Loss: 1.0774
Epoch 024, Loss: 1.0939
Epoch 025, Loss: 0.9648
Epoch 026, Loss: 1.1252
Epoch 027, Loss: 1.0021
Epoch 028, Loss: 0.9929
Epoch 029, Loss: 1.2237
Epoch 030, Loss: 1.1649
Epoch 031, Loss: 0.8890
Epoch 032, Loss: 0.8870
Epoch 033, Loss: 0.8423
Epoch 034, Loss: 0.8306
Epoch 035, Loss: 0.8159
Epoch 036, Loss: 0.8991
Epoch 037, Loss: 0.8054
Epoch 038, Loss: 0.7812
Epoch 039, Loss: 0.8504
Epoch 040, Loss: 0.7424
Epoch 041, Loss: 0.7101
Epoch 042, Loss: 0.7324
Epoch 043, Loss: 0.7462
Epoch 044, Loss: 0.7115
Epoch 045, Loss: 0.7117
Epoch 046, Loss: 0.6332
Epoch 047, Loss: 0.7071
Epoch 048, Loss: 0.6733
Epoch 049, Loss: 0.6528
Epoch 050, Loss: 0.7720
Epoch 051, Loss: 0.6728
Epoch 052, Loss: 0.5737
Epoch 053, Loss: 0.6284
Epoch 054, Loss: 0.6559
Epoch 055, Loss: 0.6546
Epoch 056, Loss: 0.6187
Epoch 057, Loss: 0.6133
Epoch 058, Loss: 0.6410
Epoch 059, Loss: 0.5776
Epoch 060, Loss: 0.6618
Epoch 061, Loss: 0.5374
Epoch 062, Loss: 0.5596
Epoch 063, Loss: 0.5845
Epoch 064, Loss: 0.6468
Epoch 065, Loss: 0.5047
Epoch 066, Loss: 0.6350
Epoch 067, Loss: 0.6957
Epoch 068, Loss: 0.5908
Epoch 069, Loss: 0.5510
Epoch 070, Loss: 0.5409
Epoch 071, Loss: 0.5357
Epoch 072, Loss: 0.5609
Epoch 073, Loss: 0.5222
Epoch 074, Loss: 0.5677
Epoch 075, Loss: 0.5275
Epoch 076, Loss: 0.5599
Epoch 077, Loss: 0.5928
Epoch 078, Loss: 0.6130
Epoch 079, Loss: 0.5223
Epoch 080, Loss: 0.5197
Epoch 081, Loss: 0.4961
Epoch 082, Loss: 0.5137
Epoch 083, Loss: 0.4701
Epoch 084, Loss: 0.5456
Epoch 085, Loss: 0.4568
Epoch 086, Loss: 0.5034
Epoch 087, Loss: 0.4757
Epoch 088, Loss: 0.5269
Epoch 089, Loss: 0.4883
Epoch 090, Loss: 0.4719
Epoch 091, Loss: 0.5725
Epoch 092, Loss: 0.5280
Epoch 093, Loss: 0.4582
Epoch 094, Loss: 0.5220
Epoch 095, Loss: 0.5084
Epoch 096, Loss: 0.4580
Epoch 097, Loss: 0.4724
Epoch 098, Loss: 0.4808
Epoch 099, Loss: 0.4544
Epoch 100, Loss: 0.5229

Test RMSE: 1.0291
Test MAPE: 0.2680
Training time: 12.66 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 8.3544
Epoch 002, Loss: 1.6958
Epoch 003, Loss: 1.5550
Epoch 004, Loss: 1.5860
Epoch 005, Loss: 1.7824
Epoch 006, Loss: 2.0291
Epoch 007, Loss: 1.7936
Epoch 008, Loss: 1.6040
Epoch 009, Loss: 1.7432
Epoch 010, Loss: 1.7443
Epoch 011, Loss: 1.8039
Epoch 012, Loss: 1.6602
Epoch 013, Loss: 1.8362
Epoch 014, Loss: 1.5158
Epoch 015, Loss: 1.6911
Epoch 016, Loss: 1.5761
Epoch 017, Loss: 1.7545
Epoch 018, Loss: 1.5787
Epoch 019, Loss: 1.7096
Epoch 020, Loss: 1.7070
Epoch 021, Loss: 1.5099
Epoch 022, Loss: 1.6444
Epoch 023, Loss: 1.6370
Epoch 024, Loss: 1.6524
Epoch 025, Loss: 1.6006
Epoch 026, Loss: 1.5072
Epoch 027, Loss: 1.5230
Epoch 028, Loss: 1.7402
Epoch 029, Loss: 1.5024
Epoch 030, Loss: 1.4909
Epoch 031, Loss: 1.7505
Epoch 032, Loss: 1.7096
Epoch 033, Loss: 1.5880
Epoch 034, Loss: 1.5547
Epoch 035, Loss: 1.7470
Epoch 036, Loss: 1.6063
Epoch 037, Loss: 1.5283
Epoch 038, Loss: 1.4783
Epoch 039, Loss: 1.4772
Epoch 040, Loss: 1.8951
Epoch 041, Loss: 1.6645
Epoch 042, Loss: 1.4191
Epoch 043, Loss: 1.5037
Epoch 044, Loss: 1.5152
Epoch 045, Loss: 1.9002
Epoch 046, Loss: 1.5651
Epoch 047, Loss: 1.5470
Epoch 048, Loss: 1.6166
Epoch 049, Loss: 1.5113
Epoch 050, Loss: 1.8042
Epoch 051, Loss: 1.5582
Epoch 052, Loss: 1.4678
Epoch 053, Loss: 1.4259
Epoch 054, Loss: 1.5164
Epoch 055, Loss: 1.9041
Epoch 056, Loss: 1.8650
Epoch 057, Loss: 1.4319
Epoch 058, Loss: 1.4004
Epoch 059, Loss: 1.7580
Epoch 060, Loss: 1.4687
Epoch 061, Loss: 1.5648
Epoch 062, Loss: 1.5603
Epoch 063, Loss: 1.4522
Epoch 064, Loss: 1.3762
Epoch 065, Loss: 1.5160
Epoch 066, Loss: 1.5215
Epoch 067, Loss: 1.5897
Epoch 068, Loss: 1.4863
Epoch 069, Loss: 1.4408
Epoch 070, Loss: 1.4821
Epoch 071, Loss: 1.5305
Epoch 072, Loss: 1.7455
Epoch 073, Loss: 1.3855
Epoch 074, Loss: 1.6050
Epoch 075, Loss: 1.4469
Epoch 076, Loss: 1.4283
Epoch 077, Loss: 1.4911
Epoch 078, Loss: 1.5793
Epoch 079, Loss: 1.5507
Epoch 080, Loss: 1.4392
Epoch 081, Loss: 1.3919
Epoch 082, Loss: 1.5911
Epoch 083, Loss: 1.4877
Epoch 084, Loss: 1.8818
Epoch 085, Loss: 1.4210
Epoch 086, Loss: 1.4298
Epoch 087, Loss: 1.5561
Epoch 088, Loss: 1.5772
Epoch 089, Loss: 1.5044
Epoch 090, Loss: 1.4236
Epoch 091, Loss: 1.3517
Epoch 092, Loss: 1.5519
Epoch 093, Loss: 1.4046
Epoch 094, Loss: 1.3616
Epoch 095, Loss: 1.4105
Epoch 096, Loss: 1.3323
Epoch 097, Loss: 1.3088
Epoch 098, Loss: 1.2635
Epoch 099, Loss: 1.2622
Epoch 100, Loss: 1.4047

Test RMSE: 1.4327
Test MAPE: 0.2107
Training time: 12.81 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7576
Epoch 002, Loss: 3.3293
Epoch 003, Loss: 3.2084
Epoch 004, Loss: 3.1944
Epoch 005, Loss: 3.0805
Epoch 006, Loss: 3.0835
Epoch 007, Loss: 2.4542
Epoch 008, Loss: 1.1459
Epoch 009, Loss: 0.9389
Epoch 010, Loss: 0.9078
Epoch 011, Loss: 0.8253
Epoch 012, Loss: 0.6692
Epoch 013, Loss: 0.6860
Epoch 014, Loss: 0.7287
Epoch 015, Loss: 0.6780
Epoch 016, Loss: 0.6614
Epoch 017, Loss: 0.7312
Epoch 018, Loss: 0.6511
Epoch 019, Loss: 0.6338
Epoch 020, Loss: 0.7668
Epoch 021, Loss: 0.6327
Epoch 022, Loss: 0.6215
Epoch 023, Loss: 0.7028
Epoch 024, Loss: 0.6109
Epoch 025, Loss: 0.6543
Epoch 026, Loss: 0.6566
Epoch 027, Loss: 0.6145
Epoch 028, Loss: 0.6285
Epoch 029, Loss: 0.6216
Epoch 030, Loss: 0.6633
Epoch 031, Loss: 0.5815
Epoch 032, Loss: 0.5969
Epoch 033, Loss: 0.6336
Epoch 034, Loss: 0.6131
Epoch 035, Loss: 0.6210
Epoch 036, Loss: 0.6380
Epoch 037, Loss: 0.6169
Epoch 038, Loss: 0.5979
Epoch 039, Loss: 0.5703
Epoch 040, Loss: 0.6192
Epoch 041, Loss: 0.5964
Epoch 042, Loss: 0.6143
Epoch 043, Loss: 0.5634
Epoch 044, Loss: 0.5899
Epoch 045, Loss: 0.5756
Epoch 046, Loss: 0.6148
Epoch 047, Loss: 0.5570
Epoch 048, Loss: 0.5910
Epoch 049, Loss: 0.6587
Epoch 050, Loss: 0.5595
Epoch 051, Loss: 0.5882
Epoch 052, Loss: 0.5384
Epoch 053, Loss: 0.5597
Epoch 054, Loss: 0.5544
Epoch 055, Loss: 0.5581
Epoch 056, Loss: 0.5713
Epoch 057, Loss: 0.6192
Epoch 058, Loss: 0.5364
Epoch 059, Loss: 0.5629
Epoch 060, Loss: 0.5970
Epoch 061, Loss: 0.5696
Epoch 062, Loss: 0.5525
Epoch 063, Loss: 0.5650
Epoch 064, Loss: 0.5773
Epoch 065, Loss: 0.5748
Epoch 066, Loss: 0.5464
Epoch 067, Loss: 0.5579
Epoch 068, Loss: 0.5882
Epoch 069, Loss: 0.6084
Epoch 070, Loss: 0.5187
Epoch 071, Loss: 0.5558
Epoch 072, Loss: 0.5212
Epoch 073, Loss: 0.5623
Epoch 074, Loss: 0.5472
Epoch 075, Loss: 0.5956
Epoch 076, Loss: 0.5647
Epoch 077, Loss: 0.5120
Epoch 078, Loss: 0.5517
Epoch 079, Loss: 0.5496
Epoch 080, Loss: 0.5676
Epoch 081, Loss: 0.5250
Epoch 082, Loss: 0.5615
Epoch 083, Loss: 0.5699
Epoch 084, Loss: 0.5614
Epoch 085, Loss: 0.5475
Epoch 086, Loss: 0.5814
Epoch 087, Loss: 0.5610
Epoch 088, Loss: 0.5412
Epoch 089, Loss: 0.5240
Epoch 090, Loss: 0.5444
Epoch 091, Loss: 0.5664
Epoch 092, Loss: 0.5495
Epoch 093, Loss: 0.6037
Epoch 094, Loss: 0.5100
Epoch 095, Loss: 0.5717
Epoch 096, Loss: 0.5393
Epoch 097, Loss: 0.5728
Epoch 098, Loss: 0.5257
Epoch 099, Loss: 0.5316
Epoch 100, Loss: 0.5480

Test RMSE: 0.6692
Test MAPE: 216638334959616.0000
Training time: 62.93 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.615366 2.214904e-01      12.151520   GNN_model_10.pkl
       12   Q_values        0.2 0.629736 2.004073e-01      12.029839   GNN_model_12.pkl
       15   Q_values        0.2 0.896925 1.992621e-01      12.210253   GNN_model_15.pkl
       20   Q_values        0.2 1.029143 2.679593e-01      12.655154   GNN_model_20.pkl
       25   Q_values        0.2 1.432699 2.107159e-01      12.810528   GNN_model_25.pkl
     full   Q_values        0.2 0.669217 2.166383e+14      62.932668 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 19%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 61%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 88%)
