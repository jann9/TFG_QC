
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59696
 Mean Absolute Percentage Error: 0.25500
 Training time:  0.03026
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55243
 Mean Absolute Percentage Error: 0.39785
 Training time:  0.01725
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71603
 Mean Absolute Percentage Error: 0.57863
 Training time:  0.05412
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86325
 Mean Absolute Percentage Error: 0.53938
 Training time:  0.01601
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70447
 Mean Absolute Percentage Error: 0.30318
 Training time:  0.03217
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52314
 Mean Absolute Percentage Error: 0.17716
 Training time:  0.01592
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60330
 Mean Absolute Percentage Error: 0.22561
 Training time:  0.07155
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61158
 Mean Absolute Percentage Error: 0.25937
 Training time:  0.01576
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54040
 Mean Absolute Percentage Error: 0.17922
 Training time:  0.11782
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67438
 Mean Absolute Percentage Error: 0.21844
 Training time:  0.01650
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61695
 Mean Absolute Percentage Error: 0.23952
 Training time:  0.11095
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65456
 Mean Absolute Percentage Error: 0.29628
 Training time:  0.02115
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60216
  MAPE on 10 nodes subset: 0.26785

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71034
  MAPE on 12 nodes subset: 0.57046

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68750
  MAPE on 15 nodes subset: 0.29308

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58634
  MAPE on 20 nodes subset: 0.22914

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53197
  MAPE on 25 nodes subset: 0.18499

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596964 0.254996       0.030261       True             4                       MLP_model_10.pkl       20
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552430 0.397848       0.017246       True             4               MLP_model_10_Circuit.pkl       20
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.716027 0.578627       0.054122       True             4                       MLP_model_12.pkl       20
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863251 0.539384       0.016006       True             4               MLP_model_12_Circuit.pkl       20
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704475 0.303175       0.032171       True             4                       MLP_model_15.pkl       20
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.523144 0.177163       0.015919       True             4               MLP_model_15_Circuit.pkl       20
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.603303 0.225612       0.071553       True             4                       MLP_model_20.pkl       20
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611577 0.259367       0.015755       True             4               MLP_model_20_Circuit.pkl       20
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540404 0.179216       0.117822       True             4                       MLP_model_25.pkl       20
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674377 0.218436       0.016503       True             4               MLP_model_25_Circuit.pkl       20
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616948 0.239522       0.110951       True             4                     MLP_model_full.pkl       20
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654556 0.296278       0.021147       True             4             MLP_model_full_Circuit.pkl       20
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602162 0.267847       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       20
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710340 0.570459       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       20
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.687497 0.293084       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       20
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586342 0.229137       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       20
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.531974 0.184985       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       20

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.58601
 Mean Absolute Percentage Error: 0.41912
 Training time:  0.33672
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.77650
 Mean Absolute Percentage Error: 0.40898
 Training time:  0.23522
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.97569
 Mean Absolute Percentage Error: 0.65374
 Training time:  0.35579
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.11155
 Mean Absolute Percentage Error: 0.66385
 Training time:  0.24408
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.61620
 Mean Absolute Percentage Error: 0.19165
 Training time:  0.43858
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79742
 Mean Absolute Percentage Error: 0.23176
 Training time:  0.24160
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65551
 Mean Absolute Percentage Error: 0.27797
 Training time:  0.64013
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84739
 Mean Absolute Percentage Error: 0.33066
 Training time:  0.24261
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74298
 Mean Absolute Percentage Error: 0.22973
 Training time:  0.72170
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70798
 Mean Absolute Percentage Error: 0.18879
 Training time:  0.24171
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.70877
 Mean Absolute Percentage Error: 0.29990
 Training time:  2.94078
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75269
 Mean Absolute Percentage Error: 0.29745
 Training time:  0.29989
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22470
  MAPE on 10 nodes subset: 0.02175

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.35024
  MAPE on 12 nodes subset: 0.26944

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.12519
  MAPE on 15 nodes subset: 0.01628

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.38113
  MAPE on 20 nodes subset: 0.08881

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.18369
  MAPE on 25 nodes subset: 0.02172

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.586015 0.419123       0.336719                           xgboost_model_10.pkl        5
       10             Circuit            50           5          4 0.776502 0.408980       0.235220                   xgboost_model_10_Circuit.pkl        5
       12            Q_values            50          78          4 0.975687 0.653740       0.355794                           xgboost_model_12.pkl        5
       12             Circuit            50           5          4 1.111550 0.663854       0.244084                   xgboost_model_12_Circuit.pkl        5
       15            Q_values            50         120          4 0.616201 0.191653       0.438580                           xgboost_model_15.pkl        5
       15             Circuit            50           5          4 0.797417 0.231763       0.241602                   xgboost_model_15_Circuit.pkl        5
       20            Q_values            50         210          4 0.655513 0.277968       0.640133                           xgboost_model_20.pkl        5
       20             Circuit            50           5          4 0.847386 0.330660       0.242615                   xgboost_model_20_Circuit.pkl        5
       25            Q_values            50         325          4 0.742975 0.229726       0.721704                           xgboost_model_25.pkl        5
       25             Circuit            50           5          4 0.707982 0.188791       0.241714                   xgboost_model_25_Circuit.pkl        5
     full            Q_values           250         325          4 0.708767 0.299898       2.940782                         xgboost_model_full.pkl        5
     full             Circuit           250           5          4 0.752695 0.297449       0.299887                 xgboost_model_full_Circuit.pkl        5
       10 Q_values_full_model            50         325          4 0.224700 0.021746       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl        5
       12 Q_values_full_model            50         325          4 0.350236 0.269437       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl        5
       15 Q_values_full_model            50         325          4 0.125192 0.016284       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl        5
       20 Q_values_full_model            50         325          4 0.381133 0.088805       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl        5
       25 Q_values_full_model            50         325          4 0.183688 0.021716       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl        5

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.4949
Epoch 002, Loss: 0.5728
Epoch 003, Loss: 0.6379
Epoch 004, Loss: 0.5931
Epoch 005, Loss: 0.5765
Epoch 006, Loss: 0.5906
Epoch 007, Loss: 0.5912
Epoch 008, Loss: 0.5607
Epoch 009, Loss: 0.5827
Epoch 010, Loss: 0.5975
Epoch 011, Loss: 0.5992
Epoch 012, Loss: 0.6028
Epoch 013, Loss: 0.5761
Epoch 014, Loss: 0.5583
Epoch 015, Loss: 0.5804
Epoch 016, Loss: 0.5508
Epoch 017, Loss: 0.5878
Epoch 018, Loss: 0.5599
Epoch 019, Loss: 0.5426
Epoch 020, Loss: 0.5979
Epoch 021, Loss: 0.6037
Epoch 022, Loss: 0.5458
Epoch 023, Loss: 0.5537
Epoch 024, Loss: 0.5436
Epoch 025, Loss: 0.5567
Epoch 026, Loss: 0.5807
Epoch 027, Loss: 0.5706
Epoch 028, Loss: 0.5547
Epoch 029, Loss: 0.5560
Epoch 030, Loss: 0.5772
Epoch 031, Loss: 0.5173
Epoch 032, Loss: 0.5475
Epoch 033, Loss: 0.5481
Epoch 034, Loss: 0.5444
Epoch 035, Loss: 0.5487
Epoch 036, Loss: 0.5459
Epoch 037, Loss: 0.5516
Epoch 038, Loss: 0.5544
Epoch 039, Loss: 0.5395
Epoch 040, Loss: 0.5241
Epoch 041, Loss: 0.5543
Epoch 042, Loss: 0.6412
Epoch 043, Loss: 0.5217
Epoch 044, Loss: 0.5986
Epoch 045, Loss: 0.5517
Epoch 046, Loss: 0.5339
Epoch 047, Loss: 0.5053
Epoch 048, Loss: 0.5040
Epoch 049, Loss: 0.5065
Epoch 050, Loss: 0.5190
Epoch 051, Loss: 0.5007
Epoch 052, Loss: 0.5310
Epoch 053, Loss: 0.4925
Epoch 054, Loss: 0.5364
Epoch 055, Loss: 0.5391
Epoch 056, Loss: 0.4897
Epoch 057, Loss: 0.5098
Epoch 058, Loss: 0.5104
Epoch 059, Loss: 0.5149
Epoch 060, Loss: 0.5181
Epoch 061, Loss: 0.5190
Epoch 062, Loss: 0.4972
Epoch 063, Loss: 0.4933
Epoch 064, Loss: 0.5074
Epoch 065, Loss: 0.5052
Epoch 066, Loss: 0.4741
Epoch 067, Loss: 0.4899
Epoch 068, Loss: 0.4950
Epoch 069, Loss: 0.5079
Epoch 070, Loss: 0.5290
Epoch 071, Loss: 0.5063
Epoch 072, Loss: 0.4877
Epoch 073, Loss: 0.4674
Epoch 074, Loss: 0.4743
Epoch 075, Loss: 0.4654
Epoch 076, Loss: 0.4433
Epoch 077, Loss: 0.4957
Epoch 078, Loss: 0.4810
Epoch 079, Loss: 0.4800
Epoch 080, Loss: 0.5174
Epoch 081, Loss: 0.4774
Epoch 082, Loss: 0.4600
Epoch 083, Loss: 0.4644
Epoch 084, Loss: 0.4819
Epoch 085, Loss: 0.4713
Epoch 086, Loss: 0.4398
Epoch 087, Loss: 0.5250
Epoch 088, Loss: 0.4919
Epoch 089, Loss: 0.4665
Epoch 090, Loss: 0.4587
Epoch 091, Loss: 0.4412
Epoch 092, Loss: 0.4440
Epoch 093, Loss: 0.4362
Epoch 094, Loss: 0.4429
Epoch 095, Loss: 0.4471
Epoch 096, Loss: 0.4584
Epoch 097, Loss: 0.4491
Epoch 098, Loss: 0.4633
Epoch 099, Loss: 0.4820
Epoch 100, Loss: 0.4319

Test RMSE: 0.6126
Test MAPE: 0.2265
Training time: 12.21 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.9354
Epoch 002, Loss: 0.9055
Epoch 003, Loss: 0.8827
Epoch 004, Loss: 0.8685
Epoch 005, Loss: 0.9078
Epoch 006, Loss: 1.0032
Epoch 007, Loss: 0.8696
Epoch 008, Loss: 0.8733
Epoch 009, Loss: 0.8747
Epoch 010, Loss: 0.8686
Epoch 011, Loss: 0.8319
Epoch 012, Loss: 0.8920
Epoch 013, Loss: 0.8885
Epoch 014, Loss: 0.8892
Epoch 015, Loss: 0.8666
Epoch 016, Loss: 0.8364
Epoch 017, Loss: 0.8452
Epoch 018, Loss: 0.9198
Epoch 019, Loss: 0.8906
Epoch 020, Loss: 0.8838
Epoch 021, Loss: 0.8616
Epoch 022, Loss: 0.8541
Epoch 023, Loss: 0.8281
Epoch 024, Loss: 0.8192
Epoch 025, Loss: 0.8568
Epoch 026, Loss: 0.8120
Epoch 027, Loss: 0.8202
Epoch 028, Loss: 0.7975
Epoch 029, Loss: 0.8090
Epoch 030, Loss: 0.7824
Epoch 031, Loss: 0.8029
Epoch 032, Loss: 0.7916
Epoch 033, Loss: 0.7894
Epoch 034, Loss: 0.8172
Epoch 035, Loss: 0.8061
Epoch 036, Loss: 0.8151
Epoch 037, Loss: 0.7710
Epoch 038, Loss: 0.7703
Epoch 039, Loss: 0.7479
Epoch 040, Loss: 0.7216
Epoch 041, Loss: 0.7285
Epoch 042, Loss: 0.7825
Epoch 043, Loss: 0.7532
Epoch 044, Loss: 0.7402
Epoch 045, Loss: 0.7619
Epoch 046, Loss: 0.7700
Epoch 047, Loss: 0.7296
Epoch 048, Loss: 0.6751
Epoch 049, Loss: 0.7096
Epoch 050, Loss: 0.7141
Epoch 051, Loss: 0.7419
Epoch 052, Loss: 0.7098
Epoch 053, Loss: 0.6733
Epoch 054, Loss: 0.7024
Epoch 055, Loss: 0.6732
Epoch 056, Loss: 0.6670
Epoch 057, Loss: 0.7063
Epoch 058, Loss: 0.6628
Epoch 059, Loss: 0.6680
Epoch 060, Loss: 0.6619
Epoch 061, Loss: 0.6448
Epoch 062, Loss: 0.6520
Epoch 063, Loss: 0.6269
Epoch 064, Loss: 0.6150
Epoch 065, Loss: 0.6306
Epoch 066, Loss: 0.6156
Epoch 067, Loss: 0.6057
Epoch 068, Loss: 0.6382
Epoch 069, Loss: 0.6339
Epoch 070, Loss: 0.6000
Epoch 071, Loss: 0.6118
Epoch 072, Loss: 0.5965
Epoch 073, Loss: 0.5826
Epoch 074, Loss: 0.6101
Epoch 075, Loss: 0.6289
Epoch 076, Loss: 0.6191
Epoch 077, Loss: 0.5933
Epoch 078, Loss: 0.5786
Epoch 079, Loss: 0.5823
Epoch 080, Loss: 0.5881
Epoch 081, Loss: 0.6136
Epoch 082, Loss: 0.6027
Epoch 083, Loss: 0.5825
Epoch 084, Loss: 0.6086
Epoch 085, Loss: 0.5740
Epoch 086, Loss: 0.5823
Epoch 087, Loss: 0.5830
Epoch 088, Loss: 0.6109
Epoch 089, Loss: 0.5733
Epoch 090, Loss: 0.5587
Epoch 091, Loss: 0.5635
Epoch 092, Loss: 0.5769
Epoch 093, Loss: 0.5742
Epoch 094, Loss: 0.5630
Epoch 095, Loss: 0.5539
Epoch 096, Loss: 0.5820
Epoch 097, Loss: 0.5778
Epoch 098, Loss: 0.5738
Epoch 099, Loss: 0.5560
Epoch 100, Loss: 0.5703

Test RMSE: 0.7204
Test MAPE: 0.2127
Training time: 12.18 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 6.1826
Epoch 002, Loss: 0.9737
Epoch 003, Loss: 0.9549
Epoch 004, Loss: 0.9408
Epoch 005, Loss: 0.9635
Epoch 006, Loss: 0.8947
Epoch 007, Loss: 0.9076
Epoch 008, Loss: 1.0923
Epoch 009, Loss: 0.9141
Epoch 010, Loss: 0.9624
Epoch 011, Loss: 1.0448
Epoch 012, Loss: 0.9497
Epoch 013, Loss: 0.9323
Epoch 014, Loss: 0.9147
Epoch 015, Loss: 0.9727
Epoch 016, Loss: 0.8976
Epoch 017, Loss: 0.9217
Epoch 018, Loss: 0.8870
Epoch 019, Loss: 0.9523
Epoch 020, Loss: 0.8894
Epoch 021, Loss: 0.8723
Epoch 022, Loss: 0.8752
Epoch 023, Loss: 0.8984
Epoch 024, Loss: 0.8639
Epoch 025, Loss: 0.8392
Epoch 026, Loss: 0.8896
Epoch 027, Loss: 0.9855
Epoch 028, Loss: 0.8786
Epoch 029, Loss: 0.8729
Epoch 030, Loss: 0.8547
Epoch 031, Loss: 0.8306
Epoch 032, Loss: 0.8831
Epoch 033, Loss: 0.8049
Epoch 034, Loss: 0.9360
Epoch 035, Loss: 0.9049
Epoch 036, Loss: 0.8362
Epoch 037, Loss: 0.8383
Epoch 038, Loss: 0.8494
Epoch 039, Loss: 0.9306
Epoch 040, Loss: 0.9415
Epoch 041, Loss: 0.8423
Epoch 042, Loss: 0.8121
Epoch 043, Loss: 0.8256
Epoch 044, Loss: 0.7639
Epoch 045, Loss: 0.7745
Epoch 046, Loss: 0.7785
Epoch 047, Loss: 0.8457
Epoch 048, Loss: 0.7989
Epoch 049, Loss: 0.7526
Epoch 050, Loss: 0.7952
Epoch 051, Loss: 0.7861
Epoch 052, Loss: 0.8098
Epoch 053, Loss: 0.7505
Epoch 054, Loss: 0.7037
Epoch 055, Loss: 0.7738
Epoch 056, Loss: 0.7811
Epoch 057, Loss: 0.7183
Epoch 058, Loss: 0.8763
Epoch 059, Loss: 0.7087
Epoch 060, Loss: 0.7779
Epoch 061, Loss: 0.7264
Epoch 062, Loss: 0.6987
Epoch 063, Loss: 0.6598
Epoch 064, Loss: 0.8514
Epoch 065, Loss: 0.7224
Epoch 066, Loss: 0.6897
Epoch 067, Loss: 0.6470
Epoch 068, Loss: 0.6916
Epoch 069, Loss: 0.6696
Epoch 070, Loss: 0.6538
Epoch 071, Loss: 0.6574
Epoch 072, Loss: 0.6442
Epoch 073, Loss: 0.6214
Epoch 074, Loss: 0.6759
Epoch 075, Loss: 0.6204
Epoch 076, Loss: 0.7013
Epoch 077, Loss: 0.7588
Epoch 078, Loss: 0.7140
Epoch 079, Loss: 0.7053
Epoch 080, Loss: 0.7023
Epoch 081, Loss: 0.6185
Epoch 082, Loss: 0.6362
Epoch 083, Loss: 0.6419
Epoch 084, Loss: 0.6045
Epoch 085, Loss: 0.6805
Epoch 086, Loss: 0.6073
Epoch 087, Loss: 0.6307
Epoch 088, Loss: 0.6176
Epoch 089, Loss: 0.6011
Epoch 090, Loss: 0.5924
Epoch 091, Loss: 0.5947
Epoch 092, Loss: 0.6059
Epoch 093, Loss: 0.6472
Epoch 094, Loss: 0.7444
Epoch 095, Loss: 0.5826
Epoch 096, Loss: 0.6007
Epoch 097, Loss: 0.5915
Epoch 098, Loss: 0.6230
Epoch 099, Loss: 0.6315
Epoch 100, Loss: 0.6598

Test RMSE: 0.8010
Test MAPE: 0.2274
Training time: 12.56 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.0593
Epoch 002, Loss: 1.3219
Epoch 003, Loss: 1.2887
Epoch 004, Loss: 1.2937
Epoch 005, Loss: 1.5186
Epoch 006, Loss: 1.1617
Epoch 007, Loss: 1.3648
Epoch 008, Loss: 1.3294
Epoch 009, Loss: 1.3839
Epoch 010, Loss: 1.2557
Epoch 011, Loss: 1.2293
Epoch 012, Loss: 1.3452
Epoch 013, Loss: 1.2459
Epoch 014, Loss: 1.3467
Epoch 015, Loss: 1.2150
Epoch 016, Loss: 1.2791
Epoch 017, Loss: 1.2405
Epoch 018, Loss: 1.2638
Epoch 019, Loss: 1.2389
Epoch 020, Loss: 1.1974
Epoch 021, Loss: 1.2874
Epoch 022, Loss: 1.2121
Epoch 023, Loss: 1.1400
Epoch 024, Loss: 1.2303
Epoch 025, Loss: 1.2358
Epoch 026, Loss: 1.2165
Epoch 027, Loss: 1.2626
Epoch 028, Loss: 1.1697
Epoch 029, Loss: 1.2562
Epoch 030, Loss: 1.1901
Epoch 031, Loss: 1.3261
Epoch 032, Loss: 1.2768
Epoch 033, Loss: 1.2731
Epoch 034, Loss: 1.2574
Epoch 035, Loss: 1.1253
Epoch 036, Loss: 1.3427
Epoch 037, Loss: 1.1872
Epoch 038, Loss: 1.1378
Epoch 039, Loss: 1.3117
Epoch 040, Loss: 1.2564
Epoch 041, Loss: 1.2771
Epoch 042, Loss: 1.2665
Epoch 043, Loss: 1.1557
Epoch 044, Loss: 1.1957
Epoch 045, Loss: 1.0934
Epoch 046, Loss: 1.1352
Epoch 047, Loss: 1.1111
Epoch 048, Loss: 1.0054
Epoch 049, Loss: 0.9907
Epoch 050, Loss: 0.9757
Epoch 051, Loss: 1.0156
Epoch 052, Loss: 0.9712
Epoch 053, Loss: 0.9544
Epoch 054, Loss: 0.8383
Epoch 055, Loss: 0.8524
Epoch 056, Loss: 0.9219
Epoch 057, Loss: 0.7726
Epoch 058, Loss: 0.8098
Epoch 059, Loss: 0.7541
Epoch 060, Loss: 0.9374
Epoch 061, Loss: 0.9270
Epoch 062, Loss: 0.7616
Epoch 063, Loss: 0.7564
Epoch 064, Loss: 0.6609
Epoch 065, Loss: 0.6272
Epoch 066, Loss: 0.6693
Epoch 067, Loss: 0.7346
Epoch 068, Loss: 0.6854
Epoch 069, Loss: 0.7297
Epoch 070, Loss: 0.6292
Epoch 071, Loss: 0.6398
Epoch 072, Loss: 0.6995
Epoch 073, Loss: 0.6365
Epoch 074, Loss: 0.6190
Epoch 075, Loss: 0.6017
Epoch 076, Loss: 0.5698
Epoch 077, Loss: 0.6017
Epoch 078, Loss: 0.6000
Epoch 079, Loss: 0.5393
Epoch 080, Loss: 0.5839
Epoch 081, Loss: 0.6202
Epoch 082, Loss: 0.6468
Epoch 083, Loss: 0.6231
Epoch 084, Loss: 0.6226
Epoch 085, Loss: 0.5507
Epoch 086, Loss: 0.5795
Epoch 087, Loss: 0.5488
Epoch 088, Loss: 0.5503
Epoch 089, Loss: 0.5457
Epoch 090, Loss: 0.6492
Epoch 091, Loss: 0.6252
Epoch 092, Loss: 0.5728
Epoch 093, Loss: 0.5479
Epoch 094, Loss: 0.5680
Epoch 095, Loss: 0.5065
Epoch 096, Loss: 0.5219
Epoch 097, Loss: 0.5139
Epoch 098, Loss: 0.4981
Epoch 099, Loss: 0.5140
Epoch 100, Loss: 0.5516

Test RMSE: 0.9348
Test MAPE: 0.2579
Training time: 12.92 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.7879
Epoch 002, Loss: 1.9390
Epoch 003, Loss: 2.0605
Epoch 004, Loss: 1.8538
Epoch 005, Loss: 1.5826
Epoch 006, Loss: 1.5074
Epoch 007, Loss: 1.7100
Epoch 008, Loss: 1.7832
Epoch 009, Loss: 1.7921
Epoch 010, Loss: 1.5354
Epoch 011, Loss: 1.6598
Epoch 012, Loss: 1.5455
Epoch 013, Loss: 1.5164
Epoch 014, Loss: 1.6191
Epoch 015, Loss: 1.4803
Epoch 016, Loss: 1.5818
Epoch 017, Loss: 1.7023
Epoch 018, Loss: 1.5806
Epoch 019, Loss: 1.6290
Epoch 020, Loss: 1.9625
Epoch 021, Loss: 1.7962
Epoch 022, Loss: 1.5797
Epoch 023, Loss: 1.5582
Epoch 024, Loss: 1.4997
Epoch 025, Loss: 1.4594
Epoch 026, Loss: 1.5381
Epoch 027, Loss: 1.5498
Epoch 028, Loss: 1.6747
Epoch 029, Loss: 1.4107
Epoch 030, Loss: 1.6422
Epoch 031, Loss: 1.5462
Epoch 032, Loss: 1.5800
Epoch 033, Loss: 1.3423
Epoch 034, Loss: 1.3355
Epoch 035, Loss: 1.4020
Epoch 036, Loss: 1.2725
Epoch 037, Loss: 1.3202
Epoch 038, Loss: 1.1932
Epoch 039, Loss: 1.2575
Epoch 040, Loss: 1.1383
Epoch 041, Loss: 1.2627
Epoch 042, Loss: 1.1333
Epoch 043, Loss: 1.1665
Epoch 044, Loss: 1.2502
Epoch 045, Loss: 1.1339
Epoch 046, Loss: 1.0843
Epoch 047, Loss: 1.3489
Epoch 048, Loss: 1.2411
Epoch 049, Loss: 1.0192
Epoch 050, Loss: 1.3320
Epoch 051, Loss: 1.2764
Epoch 052, Loss: 1.0605
Epoch 053, Loss: 1.0192
Epoch 054, Loss: 1.0791
Epoch 055, Loss: 1.0107
Epoch 056, Loss: 1.1667
Epoch 057, Loss: 0.9645
Epoch 058, Loss: 1.0420
Epoch 059, Loss: 0.9824
Epoch 060, Loss: 1.0983
Epoch 061, Loss: 1.0008
Epoch 062, Loss: 1.0579
Epoch 063, Loss: 0.9434
Epoch 064, Loss: 0.8985
Epoch 065, Loss: 0.9288
Epoch 066, Loss: 0.9456
Epoch 067, Loss: 0.9040
Epoch 068, Loss: 0.9535
Epoch 069, Loss: 0.8928
Epoch 070, Loss: 0.9262
Epoch 071, Loss: 0.8694
Epoch 072, Loss: 0.9426
Epoch 073, Loss: 0.9222
Epoch 074, Loss: 0.9350
Epoch 075, Loss: 0.9911
Epoch 076, Loss: 0.8989
Epoch 077, Loss: 0.8968
Epoch 078, Loss: 0.9292
Epoch 079, Loss: 0.9382
Epoch 080, Loss: 0.9884
Epoch 081, Loss: 0.9131
Epoch 082, Loss: 0.8924
Epoch 083, Loss: 0.8494
Epoch 084, Loss: 0.9183
Epoch 085, Loss: 0.9405
Epoch 086, Loss: 0.8897
Epoch 087, Loss: 0.9118
Epoch 088, Loss: 0.8174
Epoch 089, Loss: 0.8956
Epoch 090, Loss: 0.8286
Epoch 091, Loss: 0.8998
Epoch 092, Loss: 0.8311
Epoch 093, Loss: 0.7665
Epoch 094, Loss: 0.8254
Epoch 095, Loss: 0.8417
Epoch 096, Loss: 0.8859
Epoch 097, Loss: 0.8507
Epoch 098, Loss: 0.8574
Epoch 099, Loss: 0.8064
Epoch 100, Loss: 0.7881

Test RMSE: 1.4502
Test MAPE: 0.2215
Training time: 13.19 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.9101
Epoch 002, Loss: 3.2931
Epoch 003, Loss: 2.6583
Epoch 004, Loss: 1.1258
Epoch 005, Loss: 0.8204
Epoch 006, Loss: 0.7328
Epoch 007, Loss: 0.7951
Epoch 008, Loss: 0.7934
Epoch 009, Loss: 0.7130
Epoch 010, Loss: 0.6773
Epoch 011, Loss: 0.7455
Epoch 012, Loss: 0.6855
Epoch 013, Loss: 0.6306
Epoch 014, Loss: 0.6935
Epoch 015, Loss: 0.6287
Epoch 016, Loss: 0.6945
Epoch 017, Loss: 0.8070
Epoch 018, Loss: 0.6282
Epoch 019, Loss: 0.6211
Epoch 020, Loss: 0.5886
Epoch 021, Loss: 0.6189
Epoch 022, Loss: 0.5565
Epoch 023, Loss: 0.5968
Epoch 024, Loss: 0.6627
Epoch 025, Loss: 0.6283
Epoch 026, Loss: 0.6105
Epoch 027, Loss: 0.5793
Epoch 028, Loss: 0.5861
Epoch 029, Loss: 0.6818
Epoch 030, Loss: 0.6550
Epoch 031, Loss: 0.5896
Epoch 032, Loss: 0.5868
Epoch 033, Loss: 0.6359
Epoch 034, Loss: 0.6227
Epoch 035, Loss: 0.5731
Epoch 036, Loss: 0.6049
Epoch 037, Loss: 0.5778
Epoch 038, Loss: 0.5736
Epoch 039, Loss: 0.5923
Epoch 040, Loss: 0.5617
Epoch 041, Loss: 0.5813
Epoch 042, Loss: 0.5779
Epoch 043, Loss: 0.5735
Epoch 044, Loss: 0.5621
Epoch 045, Loss: 0.5855
Epoch 046, Loss: 0.5581
Epoch 047, Loss: 0.5577
Epoch 048, Loss: 0.6327
Epoch 049, Loss: 0.5365
Epoch 050, Loss: 0.5547
Epoch 051, Loss: 0.5340
Epoch 052, Loss: 0.5882
Epoch 053, Loss: 0.6038
Epoch 054, Loss: 0.5919
Epoch 055, Loss: 0.5360
Epoch 056, Loss: 0.5525
Epoch 057, Loss: 0.5658
Epoch 058, Loss: 0.5578
Epoch 059, Loss: 0.5447
Epoch 060, Loss: 0.5467
Epoch 061, Loss: 0.5628
Epoch 062, Loss: 0.5389
Epoch 063, Loss: 0.5208
Epoch 064, Loss: 0.5205
Epoch 065, Loss: 0.5864
Epoch 066, Loss: 0.5305
Epoch 067, Loss: 0.5364
Epoch 068, Loss: 0.5427
Epoch 069, Loss: 0.5608
Epoch 070, Loss: 0.5235
Epoch 071, Loss: 0.5227
Epoch 072, Loss: 0.5426
Epoch 073, Loss: 0.5069
Epoch 074, Loss: 0.5280
Epoch 075, Loss: 0.5000
Epoch 076, Loss: 0.5140
Epoch 077, Loss: 0.5392
Epoch 078, Loss: 0.5213
Epoch 079, Loss: 0.5284
Epoch 080, Loss: 0.5017
Epoch 081, Loss: 0.4987
Epoch 082, Loss: 0.5168
Epoch 083, Loss: 0.5167
Epoch 084, Loss: 0.5444
Epoch 085, Loss: 0.5379
Epoch 086, Loss: 0.5038
Epoch 087, Loss: 0.5443
Epoch 088, Loss: 0.5588
Epoch 089, Loss: 0.5165
Epoch 090, Loss: 0.5072
Epoch 091, Loss: 0.4951
Epoch 092, Loss: 0.5047
Epoch 093, Loss: 0.5133
Epoch 094, Loss: 0.5109
Epoch 095, Loss: 0.5146
Epoch 096, Loss: 0.5156
Epoch 097, Loss: 0.5209
Epoch 098, Loss: 0.4947
Epoch 099, Loss: 0.5278
Epoch 100, Loss: 0.5294

Test RMSE: 0.6964
Test MAPE: 504023337664512.0000
Training time: 64.31 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.612644 2.264940e-01      12.212445   GNN_model_10.pkl
       12   Q_values        0.2 0.720378 2.127070e-01      12.182838   GNN_model_12.pkl
       15   Q_values        0.2 0.800986 2.273512e-01      12.555861   GNN_model_15.pkl
       20   Q_values        0.2 0.934792 2.578732e-01      12.918058   GNN_model_20.pkl
       25   Q_values        0.2 1.450245 2.215399e-01      13.189473   GNN_model_25.pkl
     full   Q_values        0.2 0.696393 5.040233e+14      64.309095 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 61%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 51%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 23%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
