
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59683
 Mean Absolute Percentage Error: 0.25453
 Training time:  0.05293
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55253
 Mean Absolute Percentage Error: 0.39635
 Training time:  0.01845
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71587
 Mean Absolute Percentage Error: 0.57650
 Training time:  0.06384
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86121
 Mean Absolute Percentage Error: 0.53731
 Training time:  0.01779
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69224
 Mean Absolute Percentage Error: 0.29209
 Training time:  0.03378
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52216
 Mean Absolute Percentage Error: 0.17590
 Training time:  0.01750
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60469
 Mean Absolute Percentage Error: 0.22746
 Training time:  0.08572
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61097
 Mean Absolute Percentage Error: 0.25818
 Training time:  0.01749
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54014
 Mean Absolute Percentage Error: 0.17925
 Training time:  0.17614
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67733
 Mean Absolute Percentage Error: 0.21839
 Training time:  0.03364
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61667
 Mean Absolute Percentage Error: 0.23955
 Training time:  0.19984
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65617
 Mean Absolute Percentage Error: 0.29548
 Training time:  0.04623
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60243
  MAPE on 10 nodes subset: 0.26879

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71061
  MAPE on 12 nodes subset: 0.57206

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68802
  MAPE on 15 nodes subset: 0.29333

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58611
  MAPE on 20 nodes subset: 0.22957

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52784
  MAPE on 25 nodes subset: 0.18211

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596825 0.254529       0.052926       True             4                       MLP_model_10.pkl       33
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552533 0.396347       0.018449       True             4               MLP_model_10_Circuit.pkl       33
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715867 0.576503       0.063844       True             4                       MLP_model_12.pkl       33
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861212 0.537306       0.017787       True             4               MLP_model_12_Circuit.pkl       33
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692237 0.292091       0.033785       True             3                       MLP_model_15.pkl       33
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522163 0.175898       0.017496       True             4               MLP_model_15_Circuit.pkl       33
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604692 0.227465       0.085722       True             4                       MLP_model_20.pkl       33
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.610972 0.258177       0.017492       True             4               MLP_model_20_Circuit.pkl       33
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540139 0.179253       0.176144       True             4                       MLP_model_25.pkl       33
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677333 0.218386       0.033644       True             4               MLP_model_25_Circuit.pkl       33
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616675 0.239554       0.199841       True             4                     MLP_model_full.pkl       33
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.656171 0.295485       0.046235       True             4             MLP_model_full_Circuit.pkl       33
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602425 0.268791       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710613 0.572056       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.688015 0.293328       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586115 0.229571       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.527844 0.182108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.63618
 Mean Absolute Percentage Error: 0.44976
 Training time:  0.42080
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75713
 Mean Absolute Percentage Error: 0.40234
 Training time:  0.33153
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98029
 Mean Absolute Percentage Error: 0.66205
 Training time:  0.44890
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10290
 Mean Absolute Percentage Error: 0.66083
 Training time:  0.33344
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.60385
 Mean Absolute Percentage Error: 0.18575
 Training time:  0.53046
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80731
 Mean Absolute Percentage Error: 0.23726
 Training time:  0.33645
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65470
 Mean Absolute Percentage Error: 0.28160
 Training time:  0.76244
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84920
 Mean Absolute Percentage Error: 0.33015
 Training time:  0.33408
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73000
 Mean Absolute Percentage Error: 0.22534
 Training time:  0.85542
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.68819
 Mean Absolute Percentage Error: 0.18211
 Training time:  0.33069
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72217
 Mean Absolute Percentage Error: 0.31039
 Training time:  3.52868
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75554
 Mean Absolute Percentage Error: 0.30080
 Training time:  0.40746
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.23172
  MAPE on 10 nodes subset: 0.02534

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.37290
  MAPE on 12 nodes subset: 0.28669

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.18991
  MAPE on 15 nodes subset: 0.02196

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.37217
  MAPE on 20 nodes subset: 0.09108

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.18474
  MAPE on 25 nodes subset: 0.02590

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.636176 0.449757       0.420798                           xgboost_model_10.pkl       97
       10             Circuit            50           5          4 0.757128 0.402338       0.331529                   xgboost_model_10_Circuit.pkl       97
       12            Q_values            50          78          4 0.980289 0.662050       0.448900                           xgboost_model_12.pkl       97
       12             Circuit            50           5          4 1.102905 0.660834       0.333443                   xgboost_model_12_Circuit.pkl       97
       15            Q_values            50         120          4 0.603853 0.185751       0.530461                           xgboost_model_15.pkl       97
       15             Circuit            50           5          4 0.807313 0.237258       0.336447                   xgboost_model_15_Circuit.pkl       97
       20            Q_values            50         210          4 0.654697 0.281602       0.762443                           xgboost_model_20.pkl       97
       20             Circuit            50           5          4 0.849202 0.330150       0.334077                   xgboost_model_20_Circuit.pkl       97
       25            Q_values            50         325          4 0.729997 0.225344       0.855416                           xgboost_model_25.pkl       97
       25             Circuit            50           5          4 0.688191 0.182110       0.330695                   xgboost_model_25_Circuit.pkl       97
     full            Q_values           250         325          4 0.722165 0.310389       3.528679                         xgboost_model_full.pkl       97
     full             Circuit           250           5          4 0.755539 0.300800       0.407462                 xgboost_model_full_Circuit.pkl       97
       10 Q_values_full_model            50         325          4 0.231724 0.025337       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       97
       12 Q_values_full_model            50         325          4 0.372904 0.286694       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       97
       15 Q_values_full_model            50         325          4 0.189911 0.021965       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       97
       20 Q_values_full_model            50         325          4 0.372166 0.091083       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       97
       25 Q_values_full_model            50         325          4 0.184740 0.025902       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       97

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 3.3012
Epoch 002, Loss: 0.5939
Epoch 003, Loss: 0.5554
Epoch 004, Loss: 0.6507
Epoch 005, Loss: 0.6041
Epoch 006, Loss: 0.5868
Epoch 007, Loss: 0.5843
Epoch 008, Loss: 0.6354
Epoch 009, Loss: 0.5500
Epoch 010, Loss: 0.5619
Epoch 011, Loss: 0.6627
Epoch 012, Loss: 0.6928
Epoch 013, Loss: 0.6616
Epoch 014, Loss: 0.5566
Epoch 015, Loss: 0.5536
Epoch 016, Loss: 0.5642
Epoch 017, Loss: 0.6031
Epoch 018, Loss: 0.5926
Epoch 019, Loss: 0.5612
Epoch 020, Loss: 0.6468
Epoch 021, Loss: 0.6207
Epoch 022, Loss: 0.5615
Epoch 023, Loss: 0.6170
Epoch 024, Loss: 0.5600
Epoch 025, Loss: 0.5755
Epoch 026, Loss: 0.5359
Epoch 027, Loss: 0.5536
Epoch 028, Loss: 0.5890
Epoch 029, Loss: 0.5915
Epoch 030, Loss: 0.5446
Epoch 031, Loss: 0.5509
Epoch 032, Loss: 0.5866
Epoch 033, Loss: 0.5591
Epoch 034, Loss: 0.5448
Epoch 035, Loss: 0.5544
Epoch 036, Loss: 0.5330
Epoch 037, Loss: 0.5240
Epoch 038, Loss: 0.5803
Epoch 039, Loss: 0.5914
Epoch 040, Loss: 0.6115
Epoch 041, Loss: 0.5459
Epoch 042, Loss: 0.5470
Epoch 043, Loss: 0.5363
Epoch 044, Loss: 0.5707
Epoch 045, Loss: 0.5400
Epoch 046, Loss: 0.5448
Epoch 047, Loss: 0.5662
Epoch 048, Loss: 0.5476
Epoch 049, Loss: 0.5446
Epoch 050, Loss: 0.5481
Epoch 051, Loss: 0.5363
Epoch 052, Loss: 0.5653
Epoch 053, Loss: 0.5259
Epoch 054, Loss: 0.5533
Epoch 055, Loss: 0.5906
Epoch 056, Loss: 0.5902
Epoch 057, Loss: 0.5198
Epoch 058, Loss: 0.5367
Epoch 059, Loss: 0.5090
Epoch 060, Loss: 0.5358
Epoch 061, Loss: 0.5749
Epoch 062, Loss: 0.5041
Epoch 063, Loss: 0.5062
Epoch 064, Loss: 0.5449
Epoch 065, Loss: 0.5208
Epoch 066, Loss: 0.5106
Epoch 067, Loss: 0.5647
Epoch 068, Loss: 0.5156
Epoch 069, Loss: 0.5250
Epoch 070, Loss: 0.4864
Epoch 071, Loss: 0.4934
Epoch 072, Loss: 0.5406
Epoch 073, Loss: 0.5287
Epoch 074, Loss: 0.4926
Epoch 075, Loss: 0.4873
Epoch 076, Loss: 0.4708
Epoch 077, Loss: 0.4840
Epoch 078, Loss: 0.4802
Epoch 079, Loss: 0.4853
Epoch 080, Loss: 0.4756
Epoch 081, Loss: 0.4727
Epoch 082, Loss: 0.4780
Epoch 083, Loss: 0.4781
Epoch 084, Loss: 0.4797
Epoch 085, Loss: 0.4771
Epoch 086, Loss: 0.4804
Epoch 087, Loss: 0.4640
Epoch 088, Loss: 0.4598
Epoch 089, Loss: 0.4694
Epoch 090, Loss: 0.4567
Epoch 091, Loss: 0.4443
Epoch 092, Loss: 0.4467
Epoch 093, Loss: 0.4779
Epoch 094, Loss: 0.4459
Epoch 095, Loss: 0.4686
Epoch 096, Loss: 0.4567
Epoch 097, Loss: 0.4466
Epoch 098, Loss: 0.4411
Epoch 099, Loss: 0.4335
Epoch 100, Loss: 0.4493

Test RMSE: 0.6467
Test MAPE: 0.2543
Training time: 16.30 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.5298
Epoch 002, Loss: 0.9126
Epoch 003, Loss: 0.9245
Epoch 004, Loss: 0.9721
Epoch 005, Loss: 0.8274
Epoch 006, Loss: 0.8689
Epoch 007, Loss: 0.8650
Epoch 008, Loss: 0.8897
Epoch 009, Loss: 0.8864
Epoch 010, Loss: 0.9024
Epoch 011, Loss: 0.8479
Epoch 012, Loss: 0.8405
Epoch 013, Loss: 0.8885
Epoch 014, Loss: 0.8534
Epoch 015, Loss: 0.9773
Epoch 016, Loss: 0.9460
Epoch 017, Loss: 0.8409
Epoch 018, Loss: 0.8684
Epoch 019, Loss: 0.8448
Epoch 020, Loss: 0.8570
Epoch 021, Loss: 0.8135
Epoch 022, Loss: 0.8746
Epoch 023, Loss: 0.8754
Epoch 024, Loss: 0.8546
Epoch 025, Loss: 0.8645
Epoch 026, Loss: 0.8316
Epoch 027, Loss: 0.8568
Epoch 028, Loss: 0.8299
Epoch 029, Loss: 0.7996
Epoch 030, Loss: 0.8518
Epoch 031, Loss: 0.8276
Epoch 032, Loss: 0.8139
Epoch 033, Loss: 0.8085
Epoch 034, Loss: 0.7758
Epoch 035, Loss: 0.7813
Epoch 036, Loss: 0.8249
Epoch 037, Loss: 0.7775
Epoch 038, Loss: 0.7669
Epoch 039, Loss: 0.7640
Epoch 040, Loss: 0.8549
Epoch 041, Loss: 0.7709
Epoch 042, Loss: 0.8037
Epoch 043, Loss: 0.7964
Epoch 044, Loss: 0.7622
Epoch 045, Loss: 0.7376
Epoch 046, Loss: 0.7786
Epoch 047, Loss: 0.7251
Epoch 048, Loss: 0.7068
Epoch 049, Loss: 0.7995
Epoch 050, Loss: 0.7345
Epoch 051, Loss: 0.7018
Epoch 052, Loss: 0.7185
Epoch 053, Loss: 0.6917
Epoch 054, Loss: 0.7506
Epoch 055, Loss: 0.8196
Epoch 056, Loss: 0.7440
Epoch 057, Loss: 0.6927
Epoch 058, Loss: 0.6742
Epoch 059, Loss: 0.7048
Epoch 060, Loss: 0.6941
Epoch 061, Loss: 0.6586
Epoch 062, Loss: 0.6854
Epoch 063, Loss: 0.6599
Epoch 064, Loss: 0.6940
Epoch 065, Loss: 0.6728
Epoch 066, Loss: 0.6620
Epoch 067, Loss: 0.6432
Epoch 068, Loss: 0.6861
Epoch 069, Loss: 0.6518
Epoch 070, Loss: 0.6830
Epoch 071, Loss: 0.6988
Epoch 072, Loss: 0.6751
Epoch 073, Loss: 0.6471
Epoch 074, Loss: 0.6686
Epoch 075, Loss: 0.6481
Epoch 076, Loss: 0.6331
Epoch 077, Loss: 0.6465
Epoch 078, Loss: 0.6554
Epoch 079, Loss: 0.7131
Epoch 080, Loss: 0.6465
Epoch 081, Loss: 0.6538
Epoch 082, Loss: 0.6177
Epoch 083, Loss: 0.6232
Epoch 084, Loss: 0.6350
Epoch 085, Loss: 0.6110
Epoch 086, Loss: 0.6282
Epoch 087, Loss: 0.6125
Epoch 088, Loss: 0.5912
Epoch 089, Loss: 0.6083
Epoch 090, Loss: 0.6159
Epoch 091, Loss: 0.6248
Epoch 092, Loss: 0.5905
Epoch 093, Loss: 0.5909
Epoch 094, Loss: 0.6017
Epoch 095, Loss: 0.6033
Epoch 096, Loss: 0.5942
Epoch 097, Loss: 0.5945
Epoch 098, Loss: 0.6423
Epoch 099, Loss: 0.6117
Epoch 100, Loss: 0.5918

Test RMSE: 0.6817
Test MAPE: 0.2316
Training time: 16.43 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 5.4283
Epoch 002, Loss: 0.9852
Epoch 003, Loss: 0.9885
Epoch 004, Loss: 1.1073
Epoch 005, Loss: 0.9701
Epoch 006, Loss: 0.9768
Epoch 007, Loss: 0.8487
Epoch 008, Loss: 0.9743
Epoch 009, Loss: 0.9217
Epoch 010, Loss: 0.9518
Epoch 011, Loss: 1.0257
Epoch 012, Loss: 0.9864
Epoch 013, Loss: 0.9513
Epoch 014, Loss: 0.8922
Epoch 015, Loss: 0.8928
Epoch 016, Loss: 1.0485
Epoch 017, Loss: 0.9236
Epoch 018, Loss: 0.9031
Epoch 019, Loss: 0.8728
Epoch 020, Loss: 0.9049
Epoch 021, Loss: 0.9055
Epoch 022, Loss: 0.9121
Epoch 023, Loss: 0.9394
Epoch 024, Loss: 0.9941
Epoch 025, Loss: 1.0073
Epoch 026, Loss: 0.9326
Epoch 027, Loss: 0.8674
Epoch 028, Loss: 0.8687
Epoch 029, Loss: 0.9507
Epoch 030, Loss: 0.8654
Epoch 031, Loss: 0.8782
Epoch 032, Loss: 0.8501
Epoch 033, Loss: 0.8494
Epoch 034, Loss: 0.9653
Epoch 035, Loss: 0.9453
Epoch 036, Loss: 0.8744
Epoch 037, Loss: 0.8978
Epoch 038, Loss: 0.8447
Epoch 039, Loss: 0.8534
Epoch 040, Loss: 0.8132
Epoch 041, Loss: 0.8171
Epoch 042, Loss: 0.8724
Epoch 043, Loss: 0.8553
Epoch 044, Loss: 0.8082
Epoch 045, Loss: 0.8275
Epoch 046, Loss: 0.8548
Epoch 047, Loss: 0.8182
Epoch 048, Loss: 0.7988
Epoch 049, Loss: 0.8319
Epoch 050, Loss: 0.8371
Epoch 051, Loss: 0.7711
Epoch 052, Loss: 0.8062
Epoch 053, Loss: 0.7725
Epoch 054, Loss: 0.7681
Epoch 055, Loss: 0.8243
Epoch 056, Loss: 0.7473
Epoch 057, Loss: 0.7596
Epoch 058, Loss: 0.7213
Epoch 059, Loss: 0.7606
Epoch 060, Loss: 0.7279
Epoch 061, Loss: 0.7556
Epoch 062, Loss: 0.7397
Epoch 063, Loss: 0.7286
Epoch 064, Loss: 0.7110
Epoch 065, Loss: 0.6818
Epoch 066, Loss: 0.7058
Epoch 067, Loss: 0.7034
Epoch 068, Loss: 0.6796
Epoch 069, Loss: 0.6520
Epoch 070, Loss: 0.6918
Epoch 071, Loss: 0.7114
Epoch 072, Loss: 0.6608
Epoch 073, Loss: 0.6562
Epoch 074, Loss: 0.6957
Epoch 075, Loss: 0.6703
Epoch 076, Loss: 0.6866
Epoch 077, Loss: 0.6882
Epoch 078, Loss: 0.6245
Epoch 079, Loss: 0.6359
Epoch 080, Loss: 0.6106
Epoch 081, Loss: 0.6122
Epoch 082, Loss: 0.6084
Epoch 083, Loss: 0.6294
Epoch 084, Loss: 0.6392
Epoch 085, Loss: 0.6020
Epoch 086, Loss: 0.5615
Epoch 087, Loss: 0.6423
Epoch 088, Loss: 0.5965
Epoch 089, Loss: 0.6129
Epoch 090, Loss: 0.6127
Epoch 091, Loss: 0.5325
Epoch 092, Loss: 0.6235
Epoch 093, Loss: 0.6981
Epoch 094, Loss: 0.5972
Epoch 095, Loss: 0.5634
Epoch 096, Loss: 0.6586
Epoch 097, Loss: 0.6224
Epoch 098, Loss: 0.5741
Epoch 099, Loss: 0.6120
Epoch 100, Loss: 0.5352

Test RMSE: 0.8391
Test MAPE: 0.2072
Training time: 16.63 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 8.2339
Epoch 002, Loss: 1.3215
Epoch 003, Loss: 1.3022
Epoch 004, Loss: 1.2297
Epoch 005, Loss: 1.2689
Epoch 006, Loss: 1.2724
Epoch 007, Loss: 1.2816
Epoch 008, Loss: 1.3362
Epoch 009, Loss: 1.7299
Epoch 010, Loss: 1.5755
Epoch 011, Loss: 1.2079
Epoch 012, Loss: 1.3824
Epoch 013, Loss: 1.4005
Epoch 014, Loss: 1.3551
Epoch 015, Loss: 1.2872
Epoch 016, Loss: 1.2445
Epoch 017, Loss: 1.2610
Epoch 018, Loss: 1.1405
Epoch 019, Loss: 1.3453
Epoch 020, Loss: 1.2044
Epoch 021, Loss: 1.2582
Epoch 022, Loss: 1.4070
Epoch 023, Loss: 1.2731
Epoch 024, Loss: 1.2500
Epoch 025, Loss: 1.4442
Epoch 026, Loss: 1.4258
Epoch 027, Loss: 1.3112
Epoch 028, Loss: 1.2342
Epoch 029, Loss: 1.1937
Epoch 030, Loss: 1.2216
Epoch 031, Loss: 1.1341
Epoch 032, Loss: 1.1716
Epoch 033, Loss: 1.1336
Epoch 034, Loss: 1.3233
Epoch 035, Loss: 1.2267
Epoch 036, Loss: 1.1434
Epoch 037, Loss: 1.1364
Epoch 038, Loss: 1.1909
Epoch 039, Loss: 1.2359
Epoch 040, Loss: 1.2182
Epoch 041, Loss: 1.1766
Epoch 042, Loss: 1.1380
Epoch 043, Loss: 1.1318
Epoch 044, Loss: 1.2387
Epoch 045, Loss: 1.1449
Epoch 046, Loss: 1.0728
Epoch 047, Loss: 1.1914
Epoch 048, Loss: 1.1247
Epoch 049, Loss: 1.3053
Epoch 050, Loss: 1.3239
Epoch 051, Loss: 1.1474
Epoch 052, Loss: 1.0010
Epoch 053, Loss: 1.0262
Epoch 054, Loss: 1.1151
Epoch 055, Loss: 1.0103
Epoch 056, Loss: 0.8896
Epoch 057, Loss: 0.9107
Epoch 058, Loss: 0.9145
Epoch 059, Loss: 0.9130
Epoch 060, Loss: 0.8845
Epoch 061, Loss: 0.8424
Epoch 062, Loss: 0.8644
Epoch 063, Loss: 0.8959
Epoch 064, Loss: 0.8215
Epoch 065, Loss: 0.9227
Epoch 066, Loss: 0.7408
Epoch 067, Loss: 0.7549
Epoch 068, Loss: 0.7742
Epoch 069, Loss: 0.7204
Epoch 070, Loss: 0.7419
Epoch 071, Loss: 0.7757
Epoch 072, Loss: 0.7406
Epoch 073, Loss: 0.7478
Epoch 074, Loss: 0.7168
Epoch 075, Loss: 0.6993
Epoch 076, Loss: 0.6885
Epoch 077, Loss: 0.6722
Epoch 078, Loss: 0.6444
Epoch 079, Loss: 0.6964
Epoch 080, Loss: 0.7176
Epoch 081, Loss: 0.6734
Epoch 082, Loss: 0.6795
Epoch 083, Loss: 0.6518
Epoch 084, Loss: 0.5622
Epoch 085, Loss: 0.6498
Epoch 086, Loss: 0.7063
Epoch 087, Loss: 0.6082
Epoch 088, Loss: 0.6096
Epoch 089, Loss: 0.6378
Epoch 090, Loss: 0.6584
Epoch 091, Loss: 0.5887
Epoch 092, Loss: 0.6432
Epoch 093, Loss: 0.6945
Epoch 094, Loss: 0.6484
Epoch 095, Loss: 0.6589
Epoch 096, Loss: 0.6163
Epoch 097, Loss: 0.5743
Epoch 098, Loss: 0.6228
Epoch 099, Loss: 0.6044
Epoch 100, Loss: 0.5980

Test RMSE: 1.0780
Test MAPE: 0.2905
Training time: 17.11 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 13.6878
Epoch 002, Loss: 1.7188
Epoch 003, Loss: 1.4949
Epoch 004, Loss: 1.6405
Epoch 005, Loss: 1.5628
Epoch 006, Loss: 1.5251
Epoch 007, Loss: 1.5463
Epoch 008, Loss: 1.7661
Epoch 009, Loss: 1.7665
Epoch 010, Loss: 1.5832
Epoch 011, Loss: 1.5104
Epoch 012, Loss: 1.6510
Epoch 013, Loss: 1.7089
Epoch 014, Loss: 1.6005
Epoch 015, Loss: 1.8316
Epoch 016, Loss: 1.5092
Epoch 017, Loss: 1.4368
Epoch 018, Loss: 1.6557
Epoch 019, Loss: 1.4873
Epoch 020, Loss: 1.6677
Epoch 021, Loss: 1.4760
Epoch 022, Loss: 1.6171
Epoch 023, Loss: 1.5391
Epoch 024, Loss: 1.7627
Epoch 025, Loss: 1.6852
Epoch 026, Loss: 1.4656
Epoch 027, Loss: 1.5868
Epoch 028, Loss: 1.4532
Epoch 029, Loss: 1.5058
Epoch 030, Loss: 1.5476
Epoch 031, Loss: 1.5246
Epoch 032, Loss: 1.4335
Epoch 033, Loss: 1.4933
Epoch 034, Loss: 1.5437
Epoch 035, Loss: 1.4389
Epoch 036, Loss: 1.4880
Epoch 037, Loss: 1.7642
Epoch 038, Loss: 1.6579
Epoch 039, Loss: 1.6203
Epoch 040, Loss: 1.5223
Epoch 041, Loss: 1.6669
Epoch 042, Loss: 1.6025
Epoch 043, Loss: 1.4747
Epoch 044, Loss: 1.5637
Epoch 045, Loss: 1.5399
Epoch 046, Loss: 1.6729
Epoch 047, Loss: 1.3843
Epoch 048, Loss: 1.4756
Epoch 049, Loss: 1.4604
Epoch 050, Loss: 1.4345
Epoch 051, Loss: 1.4224
Epoch 052, Loss: 1.4621
Epoch 053, Loss: 1.4480
Epoch 054, Loss: 1.4508
Epoch 055, Loss: 1.4148
Epoch 056, Loss: 1.4848
Epoch 057, Loss: 1.4487
Epoch 058, Loss: 1.3605
Epoch 059, Loss: 1.5941
Epoch 060, Loss: 1.4265
Epoch 061, Loss: 1.4742
Epoch 062, Loss: 1.7594
Epoch 063, Loss: 1.5021
Epoch 064, Loss: 1.7082
Epoch 065, Loss: 1.3163
Epoch 066, Loss: 1.2687
Epoch 067, Loss: 1.2692
Epoch 068, Loss: 1.2701
Epoch 069, Loss: 1.2828
Epoch 070, Loss: 1.4093
Epoch 071, Loss: 1.2659
Epoch 072, Loss: 1.3384
Epoch 073, Loss: 1.1113
Epoch 074, Loss: 1.2215
Epoch 075, Loss: 1.1072
Epoch 076, Loss: 1.2034
Epoch 077, Loss: 1.0348
Epoch 078, Loss: 0.9616
Epoch 079, Loss: 1.0979
Epoch 080, Loss: 0.9610
Epoch 081, Loss: 0.9909
Epoch 082, Loss: 1.0752
Epoch 083, Loss: 1.0322
Epoch 084, Loss: 1.0114
Epoch 085, Loss: 0.8762
Epoch 086, Loss: 1.2864
Epoch 087, Loss: 1.0028
Epoch 088, Loss: 1.0018
Epoch 089, Loss: 0.8640
Epoch 090, Loss: 0.8351
Epoch 091, Loss: 0.9203
Epoch 092, Loss: 0.8862
Epoch 093, Loss: 0.9165
Epoch 094, Loss: 0.9890
Epoch 095, Loss: 1.0236
Epoch 096, Loss: 0.7808
Epoch 097, Loss: 0.8441
Epoch 098, Loss: 0.7821
Epoch 099, Loss: 0.8333
Epoch 100, Loss: 0.8002

Test RMSE: 1.5401
Test MAPE: 0.2381
Training time: 17.55 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7446
Epoch 002, Loss: 3.3039
Epoch 003, Loss: 2.9072
Epoch 004, Loss: 1.1614
Epoch 005, Loss: 0.7889
Epoch 006, Loss: 0.7451
Epoch 007, Loss: 0.7939
Epoch 008, Loss: 0.6988
Epoch 009, Loss: 0.7016
Epoch 010, Loss: 0.7168
Epoch 011, Loss: 0.6822
Epoch 012, Loss: 0.7238
Epoch 013, Loss: 0.6474
Epoch 014, Loss: 0.6677
Epoch 015, Loss: 0.6990
Epoch 016, Loss: 0.7098
Epoch 017, Loss: 0.6594
Epoch 018, Loss: 0.6846
Epoch 019, Loss: 0.6512
Epoch 020, Loss: 0.6630
Epoch 021, Loss: 0.6037
Epoch 022, Loss: 0.6353
Epoch 023, Loss: 0.6081
Epoch 024, Loss: 0.7104
Epoch 025, Loss: 0.6068
Epoch 026, Loss: 0.6581
Epoch 027, Loss: 0.6927
Epoch 028, Loss: 0.5952
Epoch 029, Loss: 0.6059
Epoch 030, Loss: 0.5772
Epoch 031, Loss: 0.6429
Epoch 032, Loss: 0.6398
Epoch 033, Loss: 0.6083
Epoch 034, Loss: 0.5929
Epoch 035, Loss: 0.5915
Epoch 036, Loss: 0.5975
Epoch 037, Loss: 0.5504
Epoch 038, Loss: 0.5694
Epoch 039, Loss: 0.6659
Epoch 040, Loss: 0.5542
Epoch 041, Loss: 0.5805
Epoch 042, Loss: 0.5920
Epoch 043, Loss: 0.5844
Epoch 044, Loss: 0.5663
Epoch 045, Loss: 0.5769
Epoch 046, Loss: 0.5433
Epoch 047, Loss: 0.5620
Epoch 048, Loss: 0.5430
Epoch 049, Loss: 0.5743
Epoch 050, Loss: 0.5562
Epoch 051, Loss: 0.5587
Epoch 052, Loss: 0.5582
Epoch 053, Loss: 0.6064
Epoch 054, Loss: 0.6349
Epoch 055, Loss: 0.5654
Epoch 056, Loss: 0.5140
Epoch 057, Loss: 0.5382
Epoch 058, Loss: 0.6221
Epoch 059, Loss: 0.5496
Epoch 060, Loss: 0.5719
Epoch 061, Loss: 0.5795
Epoch 062, Loss: 0.5568
Epoch 063, Loss: 0.5500
Epoch 064, Loss: 0.5651
Epoch 065, Loss: 0.5479
Epoch 066, Loss: 0.5537
Epoch 067, Loss: 0.5809
Epoch 068, Loss: 0.5031
Epoch 069, Loss: 0.5846
Epoch 070, Loss: 0.5197
Epoch 071, Loss: 0.5659
Epoch 072, Loss: 0.5307
Epoch 073, Loss: 0.5048
Epoch 074, Loss: 0.5138
Epoch 075, Loss: 0.5180
Epoch 076, Loss: 0.5359
Epoch 077, Loss: 0.5346
Epoch 078, Loss: 0.5355
Epoch 079, Loss: 0.5104
Epoch 080, Loss: 0.5498
Epoch 081, Loss: 0.5018
Epoch 082, Loss: 0.5137
Epoch 083, Loss: 0.5358
Epoch 084, Loss: 0.5229
Epoch 085, Loss: 0.5414
Epoch 086, Loss: 0.5637
Epoch 087, Loss: 0.4822
Epoch 088, Loss: 0.5184
Epoch 089, Loss: 0.5123
Epoch 090, Loss: 0.5292
Epoch 091, Loss: 0.5456
Epoch 092, Loss: 0.5411
Epoch 093, Loss: 0.4933
Epoch 094, Loss: 0.5474
Epoch 095, Loss: 0.5468
Epoch 096, Loss: 0.5139
Epoch 097, Loss: 0.5371
Epoch 098, Loss: 0.4768
Epoch 099, Loss: 0.4992
Epoch 100, Loss: 0.5067

Test RMSE: 1.0904
Test MAPE: 958158348484608.0000
Training time: 84.88 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.646662 2.542747e-01      16.295648   GNN_model_10.pkl
       12   Q_values        0.2 0.681652 2.316248e-01      16.434365   GNN_model_12.pkl
       15   Q_values        0.2 0.839137 2.072496e-01      16.626195   GNN_model_15.pkl
       20   Q_values        0.2 1.078029 2.905329e-01      17.114940   GNN_model_20.pkl
       25   Q_values        0.2 1.540095 2.381039e-01      17.549138   GNN_model_25.pkl
     full   Q_values        0.2 1.090444 9.581583e+14      84.881067 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 51%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 23%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
