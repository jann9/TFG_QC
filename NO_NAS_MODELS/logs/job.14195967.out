
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59791
 Mean Absolute Percentage Error: 0.25549
 Training time:  0.03092
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.54865
 Mean Absolute Percentage Error: 0.38352
 Training time:  0.01600
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71588
 Mean Absolute Percentage Error: 0.57632
 Training time:  0.05422
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86361
 Mean Absolute Percentage Error: 0.54066
 Training time:  0.01573
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70684
 Mean Absolute Percentage Error: 0.30455
 Training time:  0.03201
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52108
 Mean Absolute Percentage Error: 0.17754
 Training time:  0.01563
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60888
 Mean Absolute Percentage Error: 0.21787
 Training time:  0.06969
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61112
 Mean Absolute Percentage Error: 0.24807
 Training time:  0.01459
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53931
 Mean Absolute Percentage Error: 0.17774
 Training time:  0.11892
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69229
 Mean Absolute Percentage Error: 0.21487
 Training time:  0.01527
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61708
 Mean Absolute Percentage Error: 0.23955
 Training time:  0.11105
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65456
 Mean Absolute Percentage Error: 0.29732
 Training time:  0.02328
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60270
  MAPE on 10 nodes subset: 0.26839

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70947
  MAPE on 12 nodes subset: 0.56967

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68641
  MAPE on 15 nodes subset: 0.29059

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58553
  MAPE on 20 nodes subset: 0.22643

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53359
  MAPE on 25 nodes subset: 0.18681

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597909 0.255491       0.030921       True             4                       MLP_model_10.pkl        2
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.548654 0.383523       0.016004       True             3               MLP_model_10_Circuit.pkl        2
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715875 0.576319       0.054216       True             4                       MLP_model_12.pkl        2
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863606 0.540665       0.015725       True             4               MLP_model_12_Circuit.pkl        2
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.706842 0.304552       0.032007       True             4                       MLP_model_15.pkl        2
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521084 0.177536       0.015628       True             4               MLP_model_15_Circuit.pkl        2
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.608881 0.217871       0.069687       True             3                       MLP_model_20.pkl        2
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611124 0.248067       0.014589       True             3               MLP_model_20_Circuit.pkl        2
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.539313 0.177738       0.118917       True             4                       MLP_model_25.pkl        2
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692294 0.214866       0.015265       True             3               MLP_model_25_Circuit.pkl        2
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617084 0.239554       0.111052       True             4                     MLP_model_full.pkl        2
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654556 0.297322       0.023284       True             4             MLP_model_full_Circuit.pkl        2
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602698 0.268393       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl        2
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709469 0.569668       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl        2
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686412 0.290586       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl        2
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585535 0.226426       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl        2
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.533588 0.186808       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl        2

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61193
 Mean Absolute Percentage Error: 0.42491
 Training time:  0.32516
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75234
 Mean Absolute Percentage Error: 0.39962
 Training time:  0.23273
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.97971
 Mean Absolute Percentage Error: 0.65879
 Training time:  0.36254
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10234
 Mean Absolute Percentage Error: 0.66384
 Training time:  0.24276
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62833
 Mean Absolute Percentage Error: 0.19423
 Training time:  0.43854
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80189
 Mean Absolute Percentage Error: 0.23139
 Training time:  0.23812
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.68170
 Mean Absolute Percentage Error: 0.28635
 Training time:  0.62944
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84492
 Mean Absolute Percentage Error: 0.32918
 Training time:  0.23928
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.76242
 Mean Absolute Percentage Error: 0.22614
 Training time:  0.70717
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69991
 Mean Absolute Percentage Error: 0.18750
 Training time:  0.23538
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71777
 Mean Absolute Percentage Error: 0.30670
 Training time:  2.94964
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75253
 Mean Absolute Percentage Error: 0.29784
 Training time:  0.30160
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.21967
  MAPE on 10 nodes subset: 0.02344

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.32563
  MAPE on 12 nodes subset: 0.27209

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13738
  MAPE on 15 nodes subset: 0.01562

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.41527
  MAPE on 20 nodes subset: 0.09632

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.20757
  MAPE on 25 nodes subset: 0.02735

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.611926 0.424912       0.325163                           xgboost_model_10.pkl       74
       10             Circuit            50           5          4 0.752336 0.399616       0.232726                   xgboost_model_10_Circuit.pkl       74
       12            Q_values            50          78          4 0.979713 0.658789       0.362537                           xgboost_model_12.pkl       74
       12             Circuit            50           5          4 1.102341 0.663841       0.242758                   xgboost_model_12_Circuit.pkl       74
       15            Q_values            50         120          4 0.628329 0.194233       0.438543                           xgboost_model_15.pkl       74
       15             Circuit            50           5          4 0.801888 0.231394       0.238122                   xgboost_model_15_Circuit.pkl       74
       20            Q_values            50         210          4 0.681705 0.286345       0.629441                           xgboost_model_20.pkl       74
       20             Circuit            50           5          4 0.844917 0.329182       0.239280                   xgboost_model_20_Circuit.pkl       74
       25            Q_values            50         325          4 0.762416 0.226144       0.707174                           xgboost_model_25.pkl       74
       25             Circuit            50           5          4 0.699910 0.187498       0.235384                   xgboost_model_25_Circuit.pkl       74
     full            Q_values           250         325          4 0.717766 0.306698       2.949644                         xgboost_model_full.pkl       74
     full             Circuit           250           5          4 0.752529 0.297843       0.301598                 xgboost_model_full_Circuit.pkl       74
       10 Q_values_full_model            50         325          4 0.219668 0.023442       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       74
       12 Q_values_full_model            50         325          4 0.325634 0.272087       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       74
       15 Q_values_full_model            50         325          4 0.137380 0.015625       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       74
       20 Q_values_full_model            50         325          4 0.415275 0.096322       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       74
       25 Q_values_full_model            50         325          4 0.207572 0.027355       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       74

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 3.0092
Epoch 002, Loss: 0.5849
Epoch 003, Loss: 0.5786
Epoch 004, Loss: 0.5761
Epoch 005, Loss: 0.6045
Epoch 006, Loss: 0.6191
Epoch 007, Loss: 0.5985
Epoch 008, Loss: 0.6011
Epoch 009, Loss: 0.6094
Epoch 010, Loss: 0.5630
Epoch 011, Loss: 0.5485
Epoch 012, Loss: 0.5985
Epoch 013, Loss: 0.5586
Epoch 014, Loss: 0.5899
Epoch 015, Loss: 0.5741
Epoch 016, Loss: 0.6249
Epoch 017, Loss: 0.5584
Epoch 018, Loss: 0.5588
Epoch 019, Loss: 0.5981
Epoch 020, Loss: 0.5662
Epoch 021, Loss: 0.5334
Epoch 022, Loss: 0.5777
Epoch 023, Loss: 0.5781
Epoch 024, Loss: 0.5469
Epoch 025, Loss: 0.5700
Epoch 026, Loss: 0.5507
Epoch 027, Loss: 0.6163
Epoch 028, Loss: 0.5321
Epoch 029, Loss: 0.5210
Epoch 030, Loss: 0.5481
Epoch 031, Loss: 0.5714
Epoch 032, Loss: 0.5472
Epoch 033, Loss: 0.5646
Epoch 034, Loss: 0.5458
Epoch 035, Loss: 0.5544
Epoch 036, Loss: 0.5626
Epoch 037, Loss: 0.5603
Epoch 038, Loss: 0.6280
Epoch 039, Loss: 0.6105
Epoch 040, Loss: 0.5604
Epoch 041, Loss: 0.5313
Epoch 042, Loss: 0.6443
Epoch 043, Loss: 0.5498
Epoch 044, Loss: 0.5277
Epoch 045, Loss: 0.5341
Epoch 046, Loss: 0.5389
Epoch 047, Loss: 0.5145
Epoch 048, Loss: 0.5146
Epoch 049, Loss: 0.5294
Epoch 050, Loss: 0.5437
Epoch 051, Loss: 0.5368
Epoch 052, Loss: 0.5431
Epoch 053, Loss: 0.5286
Epoch 054, Loss: 0.5236
Epoch 055, Loss: 0.5536
Epoch 056, Loss: 0.5082
Epoch 057, Loss: 0.5598
Epoch 058, Loss: 0.5289
Epoch 059, Loss: 0.5232
Epoch 060, Loss: 0.5091
Epoch 061, Loss: 0.5018
Epoch 062, Loss: 0.4891
Epoch 063, Loss: 0.5275
Epoch 064, Loss: 0.5282
Epoch 065, Loss: 0.5283
Epoch 066, Loss: 0.5109
Epoch 067, Loss: 0.4895
Epoch 068, Loss: 0.5064
Epoch 069, Loss: 0.5582
Epoch 070, Loss: 0.5063
Epoch 071, Loss: 0.4999
Epoch 072, Loss: 0.5099
Epoch 073, Loss: 0.5176
Epoch 074, Loss: 0.4941
Epoch 075, Loss: 0.5037
Epoch 076, Loss: 0.5008
Epoch 077, Loss: 0.4911
Epoch 078, Loss: 0.4876
Epoch 079, Loss: 0.4972
Epoch 080, Loss: 0.4756
Epoch 081, Loss: 0.4883
Epoch 082, Loss: 0.4781
Epoch 083, Loss: 0.5076
Epoch 084, Loss: 0.4885
Epoch 085, Loss: 0.4911
Epoch 086, Loss: 0.4841
Epoch 087, Loss: 0.4856
Epoch 088, Loss: 0.4686
Epoch 089, Loss: 0.4888
Epoch 090, Loss: 0.4662
Epoch 091, Loss: 0.4786
Epoch 092, Loss: 0.4820
Epoch 093, Loss: 0.4972
Epoch 094, Loss: 0.4632
Epoch 095, Loss: 0.4697
Epoch 096, Loss: 0.4969
Epoch 097, Loss: 0.4617
Epoch 098, Loss: 0.4714
Epoch 099, Loss: 0.4689
Epoch 100, Loss: 0.4543

Test RMSE: 0.6193
Test MAPE: 0.2136
Training time: 12.23 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.3765
Epoch 002, Loss: 0.9006
Epoch 003, Loss: 0.9075
Epoch 004, Loss: 0.8649
Epoch 005, Loss: 0.8437
Epoch 006, Loss: 0.9067
Epoch 007, Loss: 0.8653
Epoch 008, Loss: 0.8119
Epoch 009, Loss: 0.9703
Epoch 010, Loss: 0.8340
Epoch 011, Loss: 0.8481
Epoch 012, Loss: 0.8794
Epoch 013, Loss: 1.0379
Epoch 014, Loss: 0.8254
Epoch 015, Loss: 0.8488
Epoch 016, Loss: 0.8143
Epoch 017, Loss: 0.8266
Epoch 018, Loss: 0.8558
Epoch 019, Loss: 0.8865
Epoch 020, Loss: 0.8844
Epoch 021, Loss: 0.9227
Epoch 022, Loss: 0.8301
Epoch 023, Loss: 0.8783
Epoch 024, Loss: 0.8187
Epoch 025, Loss: 0.7972
Epoch 026, Loss: 0.7999
Epoch 027, Loss: 0.8655
Epoch 028, Loss: 0.8634
Epoch 029, Loss: 0.7981
Epoch 030, Loss: 0.7809
Epoch 031, Loss: 0.7300
Epoch 032, Loss: 0.8771
Epoch 033, Loss: 0.8314
Epoch 034, Loss: 0.8489
Epoch 035, Loss: 0.7711
Epoch 036, Loss: 0.7488
Epoch 037, Loss: 0.7941
Epoch 038, Loss: 0.7995
Epoch 039, Loss: 0.7599
Epoch 040, Loss: 0.7555
Epoch 041, Loss: 0.7506
Epoch 042, Loss: 0.7578
Epoch 043, Loss: 0.7243
Epoch 044, Loss: 0.7211
Epoch 045, Loss: 0.7276
Epoch 046, Loss: 0.7837
Epoch 047, Loss: 0.7238
Epoch 048, Loss: 0.7510
Epoch 049, Loss: 0.7141
Epoch 050, Loss: 0.7189
Epoch 051, Loss: 0.7876
Epoch 052, Loss: 0.7493
Epoch 053, Loss: 0.7446
Epoch 054, Loss: 0.7185
Epoch 055, Loss: 0.6889
Epoch 056, Loss: 0.7053
Epoch 057, Loss: 0.7056
Epoch 058, Loss: 0.6761
Epoch 059, Loss: 0.7001
Epoch 060, Loss: 0.6768
Epoch 061, Loss: 0.6654
Epoch 062, Loss: 0.6783
Epoch 063, Loss: 0.6967
Epoch 064, Loss: 0.6558
Epoch 065, Loss: 0.6716
Epoch 066, Loss: 0.6832
Epoch 067, Loss: 0.7235
Epoch 068, Loss: 0.6492
Epoch 069, Loss: 0.6407
Epoch 070, Loss: 0.6673
Epoch 071, Loss: 0.6675
Epoch 072, Loss: 0.6244
Epoch 073, Loss: 0.6268
Epoch 074, Loss: 0.7132
Epoch 075, Loss: 0.6069
Epoch 076, Loss: 0.6159
Epoch 077, Loss: 0.5886
Epoch 078, Loss: 0.6245
Epoch 079, Loss: 0.6289
Epoch 080, Loss: 0.6483
Epoch 081, Loss: 0.6112
Epoch 082, Loss: 0.5865
Epoch 083, Loss: 0.6082
Epoch 084, Loss: 0.5888
Epoch 085, Loss: 0.5863
Epoch 086, Loss: 0.5808
Epoch 087, Loss: 0.5974
Epoch 088, Loss: 0.5835
Epoch 089, Loss: 0.5801
Epoch 090, Loss: 0.5743
Epoch 091, Loss: 0.5966
Epoch 092, Loss: 0.5745
Epoch 093, Loss: 0.5684
Epoch 094, Loss: 0.5726
Epoch 095, Loss: 0.5893
Epoch 096, Loss: 0.5588
Epoch 097, Loss: 0.5485
Epoch 098, Loss: 0.5554
Epoch 099, Loss: 0.5591
Epoch 100, Loss: 0.5486

Test RMSE: 0.6822
Test MAPE: 0.1996
Training time: 12.25 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.8991
Epoch 002, Loss: 0.8980
Epoch 003, Loss: 0.8903
Epoch 004, Loss: 1.0338
Epoch 005, Loss: 1.0172
Epoch 006, Loss: 0.9999
Epoch 007, Loss: 1.0105
Epoch 008, Loss: 0.9062
Epoch 009, Loss: 0.8960
Epoch 010, Loss: 0.9469
Epoch 011, Loss: 0.8880
Epoch 012, Loss: 1.1294
Epoch 013, Loss: 0.9455
Epoch 014, Loss: 0.9603
Epoch 015, Loss: 0.9450
Epoch 016, Loss: 1.0504
Epoch 017, Loss: 1.0152
Epoch 018, Loss: 0.9304
Epoch 019, Loss: 0.9619
Epoch 020, Loss: 0.9296
Epoch 021, Loss: 0.8858
Epoch 022, Loss: 0.8499
Epoch 023, Loss: 0.9553
Epoch 024, Loss: 0.9041
Epoch 025, Loss: 0.8967
Epoch 026, Loss: 0.9985
Epoch 027, Loss: 0.8456
Epoch 028, Loss: 0.8263
Epoch 029, Loss: 0.8878
Epoch 030, Loss: 0.9262
Epoch 031, Loss: 0.8613
Epoch 032, Loss: 0.8393
Epoch 033, Loss: 0.8613
Epoch 034, Loss: 0.9054
Epoch 035, Loss: 0.7787
Epoch 036, Loss: 0.7872
Epoch 037, Loss: 0.8422
Epoch 038, Loss: 0.8165
Epoch 039, Loss: 0.7785
Epoch 040, Loss: 0.8035
Epoch 041, Loss: 0.7428
Epoch 042, Loss: 0.7550
Epoch 043, Loss: 0.7799
Epoch 044, Loss: 0.7021
Epoch 045, Loss: 0.7431
Epoch 046, Loss: 0.7945
Epoch 047, Loss: 0.7698
Epoch 048, Loss: 0.8309
Epoch 049, Loss: 0.7169
Epoch 050, Loss: 0.6793
Epoch 051, Loss: 0.8013
Epoch 052, Loss: 0.7132
Epoch 053, Loss: 0.6882
Epoch 054, Loss: 0.6861
Epoch 055, Loss: 0.7278
Epoch 056, Loss: 0.6979
Epoch 057, Loss: 0.7221
Epoch 058, Loss: 0.7305
Epoch 059, Loss: 0.6884
Epoch 060, Loss: 0.7125
Epoch 061, Loss: 0.6757
Epoch 062, Loss: 0.6748
Epoch 063, Loss: 0.7110
Epoch 064, Loss: 0.7496
Epoch 065, Loss: 0.6729
Epoch 066, Loss: 0.6855
Epoch 067, Loss: 0.7152
Epoch 068, Loss: 0.6721
Epoch 069, Loss: 0.6128
Epoch 070, Loss: 0.6548
Epoch 071, Loss: 0.6758
Epoch 072, Loss: 0.6079
Epoch 073, Loss: 0.6177
Epoch 074, Loss: 0.5951
Epoch 075, Loss: 0.6042
Epoch 076, Loss: 0.6119
Epoch 077, Loss: 0.6093
Epoch 078, Loss: 0.6527
Epoch 079, Loss: 0.6289
Epoch 080, Loss: 0.6505
Epoch 081, Loss: 0.6233
Epoch 082, Loss: 0.6229
Epoch 083, Loss: 0.5951
Epoch 084, Loss: 0.6699
Epoch 085, Loss: 0.5843
Epoch 086, Loss: 0.6172
Epoch 087, Loss: 0.6076
Epoch 088, Loss: 0.6066
Epoch 089, Loss: 0.5679
Epoch 090, Loss: 0.6321
Epoch 091, Loss: 0.5963
Epoch 092, Loss: 0.5620
Epoch 093, Loss: 0.7310
Epoch 094, Loss: 0.6155
Epoch 095, Loss: 0.6358
Epoch 096, Loss: 0.5883
Epoch 097, Loss: 0.5826
Epoch 098, Loss: 0.6539
Epoch 099, Loss: 0.5925
Epoch 100, Loss: 0.5978

Test RMSE: 0.7830
Test MAPE: 0.1966
Training time: 12.52 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 8.1972
Epoch 002, Loss: 1.4302
Epoch 003, Loss: 1.2207
Epoch 004, Loss: 1.4468
Epoch 005, Loss: 1.5049
Epoch 006, Loss: 1.2017
Epoch 007, Loss: 1.2143
Epoch 008, Loss: 1.2194
Epoch 009, Loss: 1.4246
Epoch 010, Loss: 1.2769
Epoch 011, Loss: 1.1656
Epoch 012, Loss: 1.3344
Epoch 013, Loss: 1.2946
Epoch 014, Loss: 1.2264
Epoch 015, Loss: 1.2624
Epoch 016, Loss: 1.1942
Epoch 017, Loss: 1.2427
Epoch 018, Loss: 1.2607
Epoch 019, Loss: 1.3762
Epoch 020, Loss: 1.1837
Epoch 021, Loss: 1.1838
Epoch 022, Loss: 1.2071
Epoch 023, Loss: 1.1509
Epoch 024, Loss: 1.2154
Epoch 025, Loss: 1.0796
Epoch 026, Loss: 1.5315
Epoch 027, Loss: 1.2007
Epoch 028, Loss: 1.2344
Epoch 029, Loss: 1.2569
Epoch 030, Loss: 1.1054
Epoch 031, Loss: 1.1772
Epoch 032, Loss: 1.3495
Epoch 033, Loss: 1.2538
Epoch 034, Loss: 1.4072
Epoch 035, Loss: 1.0426
Epoch 036, Loss: 1.0289
Epoch 037, Loss: 1.0967
Epoch 038, Loss: 1.2179
Epoch 039, Loss: 1.0254
Epoch 040, Loss: 1.0313
Epoch 041, Loss: 0.9602
Epoch 042, Loss: 0.9641
Epoch 043, Loss: 1.0155
Epoch 044, Loss: 1.0203
Epoch 045, Loss: 0.9967
Epoch 046, Loss: 1.0427
Epoch 047, Loss: 0.9171
Epoch 048, Loss: 0.9759
Epoch 049, Loss: 0.9245
Epoch 050, Loss: 0.9153
Epoch 051, Loss: 0.9205
Epoch 052, Loss: 0.8485
Epoch 053, Loss: 0.8770
Epoch 054, Loss: 0.9766
Epoch 055, Loss: 0.9218
Epoch 056, Loss: 0.8385
Epoch 057, Loss: 0.9992
Epoch 058, Loss: 0.9020
Epoch 059, Loss: 0.9486
Epoch 060, Loss: 0.8414
Epoch 061, Loss: 0.7790
Epoch 062, Loss: 0.9484
Epoch 063, Loss: 0.7868
Epoch 064, Loss: 0.7650
Epoch 065, Loss: 0.7725
Epoch 066, Loss: 0.7971
Epoch 067, Loss: 0.9191
Epoch 068, Loss: 0.7885
Epoch 069, Loss: 0.7511
Epoch 070, Loss: 0.7618
Epoch 071, Loss: 0.7532
Epoch 072, Loss: 0.7283
Epoch 073, Loss: 0.7428
Epoch 074, Loss: 0.8031
Epoch 075, Loss: 0.7682
Epoch 076, Loss: 0.7638
Epoch 077, Loss: 0.7541
Epoch 078, Loss: 0.7424
Epoch 079, Loss: 0.7055
Epoch 080, Loss: 0.6478
Epoch 081, Loss: 0.7199
Epoch 082, Loss: 0.6747
Epoch 083, Loss: 0.8301
Epoch 084, Loss: 0.7122
Epoch 085, Loss: 0.6956
Epoch 086, Loss: 0.7420
Epoch 087, Loss: 0.7614
Epoch 088, Loss: 0.7992
Epoch 089, Loss: 0.6657
Epoch 090, Loss: 0.7445
Epoch 091, Loss: 0.8698
Epoch 092, Loss: 0.7095
Epoch 093, Loss: 0.6259
Epoch 094, Loss: 0.7053
Epoch 095, Loss: 0.6925
Epoch 096, Loss: 0.6412
Epoch 097, Loss: 0.7004
Epoch 098, Loss: 0.6629
Epoch 099, Loss: 0.8039
Epoch 100, Loss: 0.7274

Test RMSE: 0.8259
Test MAPE: 0.2604
Training time: 12.81 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.0252
Epoch 002, Loss: 1.7885
Epoch 003, Loss: 1.7529
Epoch 004, Loss: 1.6338
Epoch 005, Loss: 1.7220
Epoch 006, Loss: 1.6103
Epoch 007, Loss: 1.6755
Epoch 008, Loss: 1.6274
Epoch 009, Loss: 1.5292
Epoch 010, Loss: 1.4854
Epoch 011, Loss: 1.4758
Epoch 012, Loss: 1.6306
Epoch 013, Loss: 1.7578
Epoch 014, Loss: 1.6837
Epoch 015, Loss: 1.5295
Epoch 016, Loss: 1.6736
Epoch 017, Loss: 1.7435
Epoch 018, Loss: 1.6302
Epoch 019, Loss: 1.5767
Epoch 020, Loss: 1.7412
Epoch 021, Loss: 1.6827
Epoch 022, Loss: 1.6017
Epoch 023, Loss: 1.4925
Epoch 024, Loss: 1.6395
Epoch 025, Loss: 1.8403
Epoch 026, Loss: 1.5015
Epoch 027, Loss: 1.6581
Epoch 028, Loss: 1.5638
Epoch 029, Loss: 1.6393
Epoch 030, Loss: 1.4240
Epoch 031, Loss: 1.6396
Epoch 032, Loss: 1.5423
Epoch 033, Loss: 1.6721
Epoch 034, Loss: 1.5364
Epoch 035, Loss: 1.4747
Epoch 036, Loss: 1.4968
Epoch 037, Loss: 1.4930
Epoch 038, Loss: 1.5896
Epoch 039, Loss: 1.5045
Epoch 040, Loss: 1.5868
Epoch 041, Loss: 1.7888
Epoch 042, Loss: 1.6413
Epoch 043, Loss: 1.4032
Epoch 044, Loss: 1.5428
Epoch 045, Loss: 1.5067
Epoch 046, Loss: 1.4662
Epoch 047, Loss: 1.6360
Epoch 048, Loss: 1.4844
Epoch 049, Loss: 1.4438
Epoch 050, Loss: 1.5330
Epoch 051, Loss: 1.5195
Epoch 052, Loss: 1.6949
Epoch 053, Loss: 1.5522
Epoch 054, Loss: 1.5904
Epoch 055, Loss: 1.5565
Epoch 056, Loss: 1.5660
Epoch 057, Loss: 1.3834
Epoch 058, Loss: 1.6098
Epoch 059, Loss: 1.6200
Epoch 060, Loss: 1.7768
Epoch 061, Loss: 1.5236
Epoch 062, Loss: 1.3792
Epoch 063, Loss: 1.4740
Epoch 064, Loss: 1.5529
Epoch 065, Loss: 1.5860
Epoch 066, Loss: 1.4075
Epoch 067, Loss: 1.4574
Epoch 068, Loss: 1.4115
Epoch 069, Loss: 1.5368
Epoch 070, Loss: 1.4764
Epoch 071, Loss: 1.4517
Epoch 072, Loss: 1.6047
Epoch 073, Loss: 1.6550
Epoch 074, Loss: 1.6805
Epoch 075, Loss: 1.5941
Epoch 076, Loss: 1.4051
Epoch 077, Loss: 1.4789
Epoch 078, Loss: 1.7997
Epoch 079, Loss: 1.4097
Epoch 080, Loss: 1.8162
Epoch 081, Loss: 1.5489
Epoch 082, Loss: 1.5241
Epoch 083, Loss: 1.3454
Epoch 084, Loss: 1.5378
Epoch 085, Loss: 1.4014
Epoch 086, Loss: 1.3655
Epoch 087, Loss: 1.4766
Epoch 088, Loss: 1.4108
Epoch 089, Loss: 1.4250
Epoch 090, Loss: 1.3541
Epoch 091, Loss: 1.3438
Epoch 092, Loss: 1.6522
Epoch 093, Loss: 1.3770
Epoch 094, Loss: 1.4323
Epoch 095, Loss: 1.3744
Epoch 096, Loss: 1.5005
Epoch 097, Loss: 1.4596
Epoch 098, Loss: 1.3357
Epoch 099, Loss: 1.4404
Epoch 100, Loss: 1.4061

Test RMSE: 1.4616
Test MAPE: 0.2104
Training time: 13.35 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8485
Epoch 002, Loss: 3.3316
Epoch 003, Loss: 3.3445
Epoch 004, Loss: 3.0678
Epoch 005, Loss: 2.1014
Epoch 006, Loss: 1.1241
Epoch 007, Loss: 0.8238
Epoch 008, Loss: 0.7311
Epoch 009, Loss: 0.7290
Epoch 010, Loss: 0.6583
Epoch 011, Loss: 0.6848
Epoch 012, Loss: 0.6366
Epoch 013, Loss: 0.6805
Epoch 014, Loss: 0.6737
Epoch 015, Loss: 0.6377
Epoch 016, Loss: 0.6348
Epoch 017, Loss: 0.6227
Epoch 018, Loss: 0.6408
Epoch 019, Loss: 0.6454
Epoch 020, Loss: 0.6623
Epoch 021, Loss: 0.6169
Epoch 022, Loss: 0.5961
Epoch 023, Loss: 0.5917
Epoch 024, Loss: 0.6597
Epoch 025, Loss: 0.6370
Epoch 026, Loss: 0.6131
Epoch 027, Loss: 0.5993
Epoch 028, Loss: 0.6256
Epoch 029, Loss: 0.5879
Epoch 030, Loss: 0.6577
Epoch 031, Loss: 0.5671
Epoch 032, Loss: 0.6506
Epoch 033, Loss: 0.6058
Epoch 034, Loss: 0.5973
Epoch 035, Loss: 0.5801
Epoch 036, Loss: 0.5946
Epoch 037, Loss: 0.5492
Epoch 038, Loss: 0.6208
Epoch 039, Loss: 0.5876
Epoch 040, Loss: 0.5763
Epoch 041, Loss: 0.5517
Epoch 042, Loss: 0.5418
Epoch 043, Loss: 0.5895
Epoch 044, Loss: 0.6426
Epoch 045, Loss: 0.5758
Epoch 046, Loss: 0.5860
Epoch 047, Loss: 0.5639
Epoch 048, Loss: 0.5941
Epoch 049, Loss: 0.5811
Epoch 050, Loss: 0.5508
Epoch 051, Loss: 0.5619
Epoch 052, Loss: 0.5563
Epoch 053, Loss: 0.5443
Epoch 054, Loss: 0.5900
Epoch 055, Loss: 0.5705
Epoch 056, Loss: 0.5779
Epoch 057, Loss: 0.5628
Epoch 058, Loss: 0.5476
Epoch 059, Loss: 0.5456
Epoch 060, Loss: 0.5260
Epoch 061, Loss: 0.5382
Epoch 062, Loss: 0.5350
Epoch 063, Loss: 0.5753
Epoch 064, Loss: 0.5530
Epoch 065, Loss: 0.5418
Epoch 066, Loss: 0.5388
Epoch 067, Loss: 0.5777
Epoch 068, Loss: 0.5329
Epoch 069, Loss: 0.5436
Epoch 070, Loss: 0.5543
Epoch 071, Loss: 0.5639
Epoch 072, Loss: 0.5207
Epoch 073, Loss: 0.5166
Epoch 074, Loss: 0.4973
Epoch 075, Loss: 0.5441
Epoch 076, Loss: 0.5420
Epoch 077, Loss: 0.4945
Epoch 078, Loss: 0.5304
Epoch 079, Loss: 0.5205
Epoch 080, Loss: 0.5187
Epoch 081, Loss: 0.5743
Epoch 082, Loss: 0.5093
Epoch 083, Loss: 0.5142
Epoch 084, Loss: 0.5170
Epoch 085, Loss: 0.5164
Epoch 086, Loss: 0.5317
Epoch 087, Loss: 0.5244
Epoch 088, Loss: 0.5252
Epoch 089, Loss: 0.5225
Epoch 090, Loss: 0.5455
Epoch 091, Loss: 0.5184
Epoch 092, Loss: 0.4897
Epoch 093, Loss: 0.4834
Epoch 094, Loss: 0.5361
Epoch 095, Loss: 0.5568
Epoch 096, Loss: 0.5150
Epoch 097, Loss: 0.5228
Epoch 098, Loss: 0.6171
Epoch 099, Loss: 0.5130
Epoch 100, Loss: 0.5261

Test RMSE: 0.8758
Test MAPE: 416870935035904.0000
Training time: 64.62 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.619282 2.136139e-01      12.234327   GNN_model_10.pkl
       12   Q_values        0.2 0.682198 1.996498e-01      12.248876   GNN_model_12.pkl
       15   Q_values        0.2 0.783000 1.965896e-01      12.520423   GNN_model_15.pkl
       20   Q_values        0.2 0.825870 2.604118e-01      12.808800   GNN_model_20.pkl
       25   Q_values        0.2 1.461604 2.103738e-01      13.351596   GNN_model_25.pkl
     full   Q_values        0.2 0.875783 4.168709e+14      64.622418 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
