
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59727
 Mean Absolute Percentage Error: 0.25452
 Training time:  0.03111
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55235
 Mean Absolute Percentage Error: 0.39673
 Training time:  0.01722
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71445
 Mean Absolute Percentage Error: 0.57760
 Training time:  0.05407
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86126
 Mean Absolute Percentage Error: 0.53895
 Training time:  0.01584
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69237
 Mean Absolute Percentage Error: 0.29086
 Training time:  0.03026
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52176
 Mean Absolute Percentage Error: 0.17629
 Training time:  0.01564
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60582
 Mean Absolute Percentage Error: 0.22110
 Training time:  0.06947
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61135
 Mean Absolute Percentage Error: 0.25857
 Training time:  0.01580
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53989
 Mean Absolute Percentage Error: 0.17827
 Training time:  0.11819
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67734
 Mean Absolute Percentage Error: 0.21866
 Training time:  0.01648
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61642
 Mean Absolute Percentage Error: 0.23903
 Training time:  0.11117
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65662
 Mean Absolute Percentage Error: 0.29634
 Training time:  0.02124
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60173
  MAPE on 10 nodes subset: 0.26716

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70923
  MAPE on 12 nodes subset: 0.57073

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68614
  MAPE on 15 nodes subset: 0.28992

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58575
  MAPE on 20 nodes subset: 0.22903

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53013
  MAPE on 25 nodes subset: 0.18435

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597267 0.254519       0.031115       True             4                       MLP_model_10.pkl       73
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552346 0.396728       0.017220       True             4               MLP_model_10_Circuit.pkl       73
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.714450 0.577601       0.054066       True             4                       MLP_model_12.pkl       73
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861263 0.538951       0.015842       True             4               MLP_model_12_Circuit.pkl       73
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692365 0.290865       0.030256       True             3                       MLP_model_15.pkl       73
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521759 0.176289       0.015645       True             4               MLP_model_15_Circuit.pkl       73
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.605820 0.221097       0.069467       True             3                       MLP_model_20.pkl       73
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611354 0.258569       0.015798       True             4               MLP_model_20_Circuit.pkl       73
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.539889 0.178272       0.118194       True             4                       MLP_model_25.pkl       73
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677339 0.218661       0.016477       True             4               MLP_model_25_Circuit.pkl       73
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616415 0.239027       0.111169       True             4                     MLP_model_full.pkl       73
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.656617 0.296339       0.021237       True             4             MLP_model_full_Circuit.pkl       73
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601731 0.267162       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       73
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709233 0.570733       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       73
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686143 0.289922       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       73
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585751 0.229028       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       73
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.530131 0.184352       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       73

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.62163
 Mean Absolute Percentage Error: 0.44942
 Training time:  0.33247
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76159
 Mean Absolute Percentage Error: 0.39985
 Training time:  0.23922
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.01613
 Mean Absolute Percentage Error: 0.68039
 Training time:  0.36169
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10809
 Mean Absolute Percentage Error: 0.66075
 Training time:  0.24661
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62842
 Mean Absolute Percentage Error: 0.19493
 Training time:  0.44574
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80543
 Mean Absolute Percentage Error: 0.23109
 Training time:  0.24290
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.64778
 Mean Absolute Percentage Error: 0.28266
 Training time:  0.63269
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84920
 Mean Absolute Percentage Error: 0.32861
 Training time:  0.24610
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74726
 Mean Absolute Percentage Error: 0.22498
 Training time:  0.71719
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69869
 Mean Absolute Percentage Error: 0.18673
 Training time:  0.24939
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71895
 Mean Absolute Percentage Error: 0.30565
 Training time:  3.15745
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75259
 Mean Absolute Percentage Error: 0.30074
 Training time:  0.28082
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24468
  MAPE on 10 nodes subset: 0.02410

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34574
  MAPE on 12 nodes subset: 0.27766

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.14326
  MAPE on 15 nodes subset: 0.01609

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40588
  MAPE on 20 nodes subset: 0.09659

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.18373
  MAPE on 25 nodes subset: 0.02403

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.621634 0.449421       0.332469                           xgboost_model_10.pkl       28
       10             Circuit            50           5          4 0.761589 0.399852       0.239221                   xgboost_model_10_Circuit.pkl       28
       12            Q_values            50          78          4 1.016129 0.680388       0.361689                           xgboost_model_12.pkl       28
       12             Circuit            50           5          4 1.108086 0.660755       0.246614                   xgboost_model_12_Circuit.pkl       28
       15            Q_values            50         120          4 0.628422 0.194932       0.445740                           xgboost_model_15.pkl       28
       15             Circuit            50           5          4 0.805432 0.231086       0.242904                   xgboost_model_15_Circuit.pkl       28
       20            Q_values            50         210          4 0.647776 0.282661       0.632688                           xgboost_model_20.pkl       28
       20             Circuit            50           5          4 0.849200 0.328607       0.246096                   xgboost_model_20_Circuit.pkl       28
       25            Q_values            50         325          4 0.747259 0.224982       0.717185                           xgboost_model_25.pkl       28
       25             Circuit            50           5          4 0.698685 0.186735       0.249386                   xgboost_model_25_Circuit.pkl       28
     full            Q_values           250         325          4 0.718947 0.305652       3.157447                         xgboost_model_full.pkl       28
     full             Circuit           250           5          4 0.752590 0.300742       0.280818                 xgboost_model_full_Circuit.pkl       28
       10 Q_values_full_model            50         325          4 0.244683 0.024101       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       12 Q_values_full_model            50         325          4 0.345745 0.277660       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       15 Q_values_full_model            50         325          4 0.143263 0.016093       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       20 Q_values_full_model            50         325          4 0.405882 0.096586       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       25 Q_values_full_model            50         325          4 0.183734 0.024031       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.2995
Epoch 002, Loss: 0.5881
Epoch 003, Loss: 0.5654
Epoch 004, Loss: 0.6734
Epoch 005, Loss: 0.6053
Epoch 006, Loss: 0.5922
Epoch 007, Loss: 0.6269
Epoch 008, Loss: 0.5635
Epoch 009, Loss: 0.5632
Epoch 010, Loss: 0.6120
Epoch 011, Loss: 0.5906
Epoch 012, Loss: 0.5857
Epoch 013, Loss: 0.6453
Epoch 014, Loss: 0.6476
Epoch 015, Loss: 0.5889
Epoch 016, Loss: 0.6429
Epoch 017, Loss: 0.5766
Epoch 018, Loss: 0.5599
Epoch 019, Loss: 0.6255
Epoch 020, Loss: 0.5501
Epoch 021, Loss: 0.6089
Epoch 022, Loss: 0.5810
Epoch 023, Loss: 0.5478
Epoch 024, Loss: 0.5438
Epoch 025, Loss: 0.5749
Epoch 026, Loss: 0.5870
Epoch 027, Loss: 0.6034
Epoch 028, Loss: 0.5595
Epoch 029, Loss: 0.5544
Epoch 030, Loss: 0.5401
Epoch 031, Loss: 0.5301
Epoch 032, Loss: 0.5735
Epoch 033, Loss: 0.6058
Epoch 034, Loss: 0.5334
Epoch 035, Loss: 0.5813
Epoch 036, Loss: 0.5367
Epoch 037, Loss: 0.5358
Epoch 038, Loss: 0.5540
Epoch 039, Loss: 0.5576
Epoch 040, Loss: 0.5701
Epoch 041, Loss: 0.5646
Epoch 042, Loss: 0.5526
Epoch 043, Loss: 0.5642
Epoch 044, Loss: 0.5383
Epoch 045, Loss: 0.5467
Epoch 046, Loss: 0.5250
Epoch 047, Loss: 0.5327
Epoch 048, Loss: 0.5278
Epoch 049, Loss: 0.5298
Epoch 050, Loss: 0.5288
Epoch 051, Loss: 0.5102
Epoch 052, Loss: 0.5052
Epoch 053, Loss: 0.5427
Epoch 054, Loss: 0.5225
Epoch 055, Loss: 0.5168
Epoch 056, Loss: 0.5125
Epoch 057, Loss: 0.5052
Epoch 058, Loss: 0.5193
Epoch 059, Loss: 0.5275
Epoch 060, Loss: 0.5354
Epoch 061, Loss: 0.5322
Epoch 062, Loss: 0.5025
Epoch 063, Loss: 0.5099
Epoch 064, Loss: 0.5065
Epoch 065, Loss: 0.5202
Epoch 066, Loss: 0.5041
Epoch 067, Loss: 0.5039
Epoch 068, Loss: 0.5103
Epoch 069, Loss: 0.4874
Epoch 070, Loss: 0.5005
Epoch 071, Loss: 0.4773
Epoch 072, Loss: 0.4791
Epoch 073, Loss: 0.4923
Epoch 074, Loss: 0.4912
Epoch 075, Loss: 0.4733
Epoch 076, Loss: 0.4935
Epoch 077, Loss: 0.4731
Epoch 078, Loss: 0.4761
Epoch 079, Loss: 0.4675
Epoch 080, Loss: 0.4719
Epoch 081, Loss: 0.4586
Epoch 082, Loss: 0.4576
Epoch 083, Loss: 0.4766
Epoch 084, Loss: 0.4607
Epoch 085, Loss: 0.4831
Epoch 086, Loss: 0.4477
Epoch 087, Loss: 0.4454
Epoch 088, Loss: 0.4697
Epoch 089, Loss: 0.4789
Epoch 090, Loss: 0.4437
Epoch 091, Loss: 0.4825
Epoch 092, Loss: 0.4643
Epoch 093, Loss: 0.4516
Epoch 094, Loss: 0.4479
Epoch 095, Loss: 0.4432
Epoch 096, Loss: 0.4436
Epoch 097, Loss: 0.4554
Epoch 098, Loss: 0.4284
Epoch 099, Loss: 0.4222
Epoch 100, Loss: 0.4355

Test RMSE: 0.6591
Test MAPE: 0.2182
Training time: 12.12 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.2964
Epoch 002, Loss: 0.8611
Epoch 003, Loss: 0.8726
Epoch 004, Loss: 0.9299
Epoch 005, Loss: 0.8349
Epoch 006, Loss: 0.9588
Epoch 007, Loss: 0.8636
Epoch 008, Loss: 0.9300
Epoch 009, Loss: 0.8876
Epoch 010, Loss: 0.8493
Epoch 011, Loss: 0.8561
Epoch 012, Loss: 0.9935
Epoch 013, Loss: 0.8397
Epoch 014, Loss: 1.0132
Epoch 015, Loss: 0.9083
Epoch 016, Loss: 0.8988
Epoch 017, Loss: 0.8390
Epoch 018, Loss: 0.8596
Epoch 019, Loss: 0.8605
Epoch 020, Loss: 0.8876
Epoch 021, Loss: 0.8670
Epoch 022, Loss: 0.8727
Epoch 023, Loss: 0.8154
Epoch 024, Loss: 0.8562
Epoch 025, Loss: 0.8335
Epoch 026, Loss: 0.8225
Epoch 027, Loss: 0.8267
Epoch 028, Loss: 0.8335
Epoch 029, Loss: 0.8767
Epoch 030, Loss: 0.9002
Epoch 031, Loss: 0.8437
Epoch 032, Loss: 0.8532
Epoch 033, Loss: 0.8167
Epoch 034, Loss: 0.8870
Epoch 035, Loss: 0.8768
Epoch 036, Loss: 0.8746
Epoch 037, Loss: 0.8465
Epoch 038, Loss: 0.7906
Epoch 039, Loss: 0.8165
Epoch 040, Loss: 0.8974
Epoch 041, Loss: 0.8190
Epoch 042, Loss: 0.8467
Epoch 043, Loss: 0.8514
Epoch 044, Loss: 0.8770
Epoch 045, Loss: 0.8489
Epoch 046, Loss: 0.8230
Epoch 047, Loss: 0.8212
Epoch 048, Loss: 0.8374
Epoch 049, Loss: 0.8533
Epoch 050, Loss: 0.7701
Epoch 051, Loss: 0.8207
Epoch 052, Loss: 0.7889
Epoch 053, Loss: 0.8414
Epoch 054, Loss: 0.8177
Epoch 055, Loss: 0.8251
Epoch 056, Loss: 0.8174
Epoch 057, Loss: 0.7722
Epoch 058, Loss: 0.7746
Epoch 059, Loss: 0.8175
Epoch 060, Loss: 0.7812
Epoch 061, Loss: 0.7899
Epoch 062, Loss: 0.7625
Epoch 063, Loss: 0.7623
Epoch 064, Loss: 0.7526
Epoch 065, Loss: 0.7336
Epoch 066, Loss: 0.7364
Epoch 067, Loss: 0.7703
Epoch 068, Loss: 0.7478
Epoch 069, Loss: 0.7521
Epoch 070, Loss: 0.7166
Epoch 071, Loss: 0.7311
Epoch 072, Loss: 0.7149
Epoch 073, Loss: 0.7150
Epoch 074, Loss: 0.7571
Epoch 075, Loss: 0.7500
Epoch 076, Loss: 0.7126
Epoch 077, Loss: 0.7210
Epoch 078, Loss: 0.6856
Epoch 079, Loss: 0.7119
Epoch 080, Loss: 0.6828
Epoch 081, Loss: 0.6868
Epoch 082, Loss: 0.6577
Epoch 083, Loss: 0.6481
Epoch 084, Loss: 0.6391
Epoch 085, Loss: 0.6313
Epoch 086, Loss: 0.6738
Epoch 087, Loss: 0.6022
Epoch 088, Loss: 0.6656
Epoch 089, Loss: 0.6413
Epoch 090, Loss: 0.6092
Epoch 091, Loss: 0.6246
Epoch 092, Loss: 0.5844
Epoch 093, Loss: 0.6113
Epoch 094, Loss: 0.6270
Epoch 095, Loss: 0.6387
Epoch 096, Loss: 0.6125
Epoch 097, Loss: 0.6272
Epoch 098, Loss: 0.6099
Epoch 099, Loss: 0.5816
Epoch 100, Loss: 0.5975

Test RMSE: 0.6854
Test MAPE: 0.2038
Training time: 12.07 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.0602
Epoch 002, Loss: 1.0516
Epoch 003, Loss: 0.9655
Epoch 004, Loss: 0.8943
Epoch 005, Loss: 1.0034
Epoch 006, Loss: 1.1379
Epoch 007, Loss: 0.8930
Epoch 008, Loss: 0.9594
Epoch 009, Loss: 0.9459
Epoch 010, Loss: 0.9222
Epoch 011, Loss: 0.9333
Epoch 012, Loss: 0.9558
Epoch 013, Loss: 0.8988
Epoch 014, Loss: 1.0023
Epoch 015, Loss: 0.9157
Epoch 016, Loss: 0.9531
Epoch 017, Loss: 1.0485
Epoch 018, Loss: 0.9335
Epoch 019, Loss: 0.8872
Epoch 020, Loss: 0.9565
Epoch 021, Loss: 0.9190
Epoch 022, Loss: 0.9120
Epoch 023, Loss: 0.9422
Epoch 024, Loss: 0.9261
Epoch 025, Loss: 0.8683
Epoch 026, Loss: 0.8113
Epoch 027, Loss: 0.9153
Epoch 028, Loss: 0.9085
Epoch 029, Loss: 1.0049
Epoch 030, Loss: 0.8491
Epoch 031, Loss: 0.9302
Epoch 032, Loss: 0.8630
Epoch 033, Loss: 0.8278
Epoch 034, Loss: 0.8894
Epoch 035, Loss: 0.9164
Epoch 036, Loss: 0.8376
Epoch 037, Loss: 0.8789
Epoch 038, Loss: 0.9919
Epoch 039, Loss: 0.8333
Epoch 040, Loss: 0.7950
Epoch 041, Loss: 0.8192
Epoch 042, Loss: 0.7869
Epoch 043, Loss: 0.8176
Epoch 044, Loss: 0.8162
Epoch 045, Loss: 0.8122
Epoch 046, Loss: 0.7596
Epoch 047, Loss: 0.7824
Epoch 048, Loss: 0.7870
Epoch 049, Loss: 0.7911
Epoch 050, Loss: 0.7793
Epoch 051, Loss: 0.7879
Epoch 052, Loss: 0.7141
Epoch 053, Loss: 0.7656
Epoch 054, Loss: 0.7304
Epoch 055, Loss: 0.6997
Epoch 056, Loss: 0.7062
Epoch 057, Loss: 0.8821
Epoch 058, Loss: 0.7144
Epoch 059, Loss: 0.7253
Epoch 060, Loss: 0.7855
Epoch 061, Loss: 0.7019
Epoch 062, Loss: 0.7239
Epoch 063, Loss: 0.6774
Epoch 064, Loss: 0.6538
Epoch 065, Loss: 0.7095
Epoch 066, Loss: 0.7329
Epoch 067, Loss: 0.6879
Epoch 068, Loss: 0.6433
Epoch 069, Loss: 0.7425
Epoch 070, Loss: 0.6089
Epoch 071, Loss: 0.6285
Epoch 072, Loss: 0.6653
Epoch 073, Loss: 0.6509
Epoch 074, Loss: 0.6203
Epoch 075, Loss: 0.6215
Epoch 076, Loss: 0.6146
Epoch 077, Loss: 0.6976
Epoch 078, Loss: 0.5936
Epoch 079, Loss: 0.6115
Epoch 080, Loss: 0.6307
Epoch 081, Loss: 0.6385
Epoch 082, Loss: 0.5891
Epoch 083, Loss: 0.5899
Epoch 084, Loss: 0.6465
Epoch 085, Loss: 0.6119
Epoch 086, Loss: 0.6228
Epoch 087, Loss: 0.6159
Epoch 088, Loss: 0.5809
Epoch 089, Loss: 0.5997
Epoch 090, Loss: 0.6429
Epoch 091, Loss: 0.6066
Epoch 092, Loss: 0.6293
Epoch 093, Loss: 0.6690
Epoch 094, Loss: 0.6092
Epoch 095, Loss: 0.6575
Epoch 096, Loss: 0.5921
Epoch 097, Loss: 0.6005
Epoch 098, Loss: 0.6008
Epoch 099, Loss: 0.5847
Epoch 100, Loss: 0.6002

Test RMSE: 0.8296
Test MAPE: 0.2165
Training time: 12.41 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 6.1022
Epoch 002, Loss: 1.3317
Epoch 003, Loss: 1.4528
Epoch 004, Loss: 1.3035
Epoch 005, Loss: 1.3035
Epoch 006, Loss: 1.2098
Epoch 007, Loss: 1.3369
Epoch 008, Loss: 1.5242
Epoch 009, Loss: 1.3682
Epoch 010, Loss: 1.2992
Epoch 011, Loss: 1.4610
Epoch 012, Loss: 1.3620
Epoch 013, Loss: 1.2752
Epoch 014, Loss: 1.2696
Epoch 015, Loss: 1.5577
Epoch 016, Loss: 1.2019
Epoch 017, Loss: 1.3551
Epoch 018, Loss: 1.4321
Epoch 019, Loss: 1.5044
Epoch 020, Loss: 1.5023
Epoch 021, Loss: 1.2356
Epoch 022, Loss: 1.1874
Epoch 023, Loss: 1.2602
Epoch 024, Loss: 1.3183
Epoch 025, Loss: 1.2184
Epoch 026, Loss: 1.1364
Epoch 027, Loss: 1.2264
Epoch 028, Loss: 1.2415
Epoch 029, Loss: 1.2700
Epoch 030, Loss: 1.2826
Epoch 031, Loss: 1.1749
Epoch 032, Loss: 1.2901
Epoch 033, Loss: 1.2902
Epoch 034, Loss: 1.2255
Epoch 035, Loss: 1.2747
Epoch 036, Loss: 1.2562
Epoch 037, Loss: 1.1084
Epoch 038, Loss: 1.2165
Epoch 039, Loss: 1.1294
Epoch 040, Loss: 1.2945
Epoch 041, Loss: 1.2266
Epoch 042, Loss: 1.1347
Epoch 043, Loss: 1.2468
Epoch 044, Loss: 1.1520
Epoch 045, Loss: 1.2965
Epoch 046, Loss: 1.1559
Epoch 047, Loss: 1.1606
Epoch 048, Loss: 1.1150
Epoch 049, Loss: 1.1645
Epoch 050, Loss: 1.1261
Epoch 051, Loss: 1.1447
Epoch 052, Loss: 1.1447
Epoch 053, Loss: 1.1132
Epoch 054, Loss: 1.0555
Epoch 055, Loss: 0.9219
Epoch 056, Loss: 1.0123
Epoch 057, Loss: 1.0074
Epoch 058, Loss: 1.0376
Epoch 059, Loss: 0.9903
Epoch 060, Loss: 0.8845
Epoch 061, Loss: 0.8522
Epoch 062, Loss: 1.0642
Epoch 063, Loss: 0.8605
Epoch 064, Loss: 0.8261
Epoch 065, Loss: 0.7701
Epoch 066, Loss: 0.8140
Epoch 067, Loss: 0.7661
Epoch 068, Loss: 0.8017
Epoch 069, Loss: 0.6999
Epoch 070, Loss: 0.8800
Epoch 071, Loss: 0.7214
Epoch 072, Loss: 0.6893
Epoch 073, Loss: 0.7918
Epoch 074, Loss: 0.6585
Epoch 075, Loss: 0.6629
Epoch 076, Loss: 0.5923
Epoch 077, Loss: 0.6541
Epoch 078, Loss: 0.6196
Epoch 079, Loss: 0.7158
Epoch 080, Loss: 0.6362
Epoch 081, Loss: 0.6477
Epoch 082, Loss: 0.6500
Epoch 083, Loss: 0.6171
Epoch 084, Loss: 0.7619
Epoch 085, Loss: 0.6101
Epoch 086, Loss: 0.5877
Epoch 087, Loss: 0.5987
Epoch 088, Loss: 0.6297
Epoch 089, Loss: 0.5668
Epoch 090, Loss: 0.5603
Epoch 091, Loss: 0.5846
Epoch 092, Loss: 0.5791
Epoch 093, Loss: 0.6788
Epoch 094, Loss: 0.5389
Epoch 095, Loss: 0.5507
Epoch 096, Loss: 0.5672
Epoch 097, Loss: 0.5959
Epoch 098, Loss: 0.5493
Epoch 099, Loss: 0.5473
Epoch 100, Loss: 0.5953

Test RMSE: 0.8580
Test MAPE: 0.2469
Training time: 12.68 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.6209
Epoch 002, Loss: 1.7224
Epoch 003, Loss: 1.5483
Epoch 004, Loss: 1.8541
Epoch 005, Loss: 1.6139
Epoch 006, Loss: 1.4930
Epoch 007, Loss: 1.5716
Epoch 008, Loss: 1.6125
Epoch 009, Loss: 1.8642
Epoch 010, Loss: 1.5926
Epoch 011, Loss: 1.5732
Epoch 012, Loss: 1.7873
Epoch 013, Loss: 1.5105
Epoch 014, Loss: 1.4488
Epoch 015, Loss: 1.5491
Epoch 016, Loss: 1.4671
Epoch 017, Loss: 1.5626
Epoch 018, Loss: 1.6312
Epoch 019, Loss: 1.5342
Epoch 020, Loss: 1.5167
Epoch 021, Loss: 1.6471
Epoch 022, Loss: 1.6530
Epoch 023, Loss: 1.8797
Epoch 024, Loss: 1.6176
Epoch 025, Loss: 1.4876
Epoch 026, Loss: 1.8279
Epoch 027, Loss: 1.4541
Epoch 028, Loss: 1.6887
Epoch 029, Loss: 1.4104
Epoch 030, Loss: 1.7585
Epoch 031, Loss: 1.4524
Epoch 032, Loss: 1.6111
Epoch 033, Loss: 1.7202
Epoch 034, Loss: 1.8451
Epoch 035, Loss: 1.6002
Epoch 036, Loss: 1.4756
Epoch 037, Loss: 1.4805
Epoch 038, Loss: 1.6027
Epoch 039, Loss: 1.4651
Epoch 040, Loss: 1.5609
Epoch 041, Loss: 1.5441
Epoch 042, Loss: 1.4387
Epoch 043, Loss: 1.6364
Epoch 044, Loss: 1.3936
Epoch 045, Loss: 1.5869
Epoch 046, Loss: 1.4502
Epoch 047, Loss: 1.3963
Epoch 048, Loss: 1.7734
Epoch 049, Loss: 1.3397
Epoch 050, Loss: 1.6222
Epoch 051, Loss: 1.4929
Epoch 052, Loss: 1.4411
Epoch 053, Loss: 1.4936
Epoch 054, Loss: 1.8971
Epoch 055, Loss: 1.5086
Epoch 056, Loss: 1.4050
Epoch 057, Loss: 1.3702
Epoch 058, Loss: 1.3969
Epoch 059, Loss: 1.3725
Epoch 060, Loss: 1.3546
Epoch 061, Loss: 1.2650
Epoch 062, Loss: 1.2318
Epoch 063, Loss: 1.1708
Epoch 064, Loss: 1.0891
Epoch 065, Loss: 1.1984
Epoch 066, Loss: 1.1435
Epoch 067, Loss: 1.0797
Epoch 068, Loss: 0.9960
Epoch 069, Loss: 1.0389
Epoch 070, Loss: 1.0058
Epoch 071, Loss: 0.9748
Epoch 072, Loss: 0.9302
Epoch 073, Loss: 1.0220
Epoch 074, Loss: 1.0191
Epoch 075, Loss: 1.0403
Epoch 076, Loss: 0.9311
Epoch 077, Loss: 0.8551
Epoch 078, Loss: 0.9033
Epoch 079, Loss: 1.0266
Epoch 080, Loss: 0.9389
Epoch 081, Loss: 1.0454
Epoch 082, Loss: 0.8589
Epoch 083, Loss: 0.9336
Epoch 084, Loss: 0.8666
Epoch 085, Loss: 0.8650
Epoch 086, Loss: 0.9163
Epoch 087, Loss: 0.8766
Epoch 088, Loss: 0.8616
Epoch 089, Loss: 0.8400
Epoch 090, Loss: 0.9729
Epoch 091, Loss: 0.7962
Epoch 092, Loss: 0.7753
Epoch 093, Loss: 0.7508
Epoch 094, Loss: 0.7858
Epoch 095, Loss: 0.7574
Epoch 096, Loss: 0.7131
Epoch 097, Loss: 0.7698
Epoch 098, Loss: 0.9051
Epoch 099, Loss: 0.7897
Epoch 100, Loss: 0.6965

Test RMSE: 1.6675
Test MAPE: 0.2664
Training time: 13.11 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7486
Epoch 002, Loss: 3.3723
Epoch 003, Loss: 3.0275
Epoch 004, Loss: 1.8242
Epoch 005, Loss: 0.9532
Epoch 006, Loss: 0.7257
Epoch 007, Loss: 0.8069
Epoch 008, Loss: 0.7126
Epoch 009, Loss: 0.7007
Epoch 010, Loss: 0.7641
Epoch 011, Loss: 0.6424
Epoch 012, Loss: 0.6689
Epoch 013, Loss: 0.6431
Epoch 014, Loss: 0.6763
Epoch 015, Loss: 0.6578
Epoch 016, Loss: 0.6559
Epoch 017, Loss: 0.6899
Epoch 018, Loss: 0.6648
Epoch 019, Loss: 0.6188
Epoch 020, Loss: 0.6379
Epoch 021, Loss: 0.5994
Epoch 022, Loss: 0.6587
Epoch 023, Loss: 0.6369
Epoch 024, Loss: 0.6078
Epoch 025, Loss: 0.6401
Epoch 026, Loss: 0.6275
Epoch 027, Loss: 0.6084
Epoch 028, Loss: 0.6250
Epoch 029, Loss: 0.6419
Epoch 030, Loss: 0.5815
Epoch 031, Loss: 0.5913
Epoch 032, Loss: 0.5960
Epoch 033, Loss: 0.5803
Epoch 034, Loss: 0.6525
Epoch 035, Loss: 0.5947
Epoch 036, Loss: 0.5822
Epoch 037, Loss: 0.5610
Epoch 038, Loss: 0.6557
Epoch 039, Loss: 0.6017
Epoch 040, Loss: 0.6069
Epoch 041, Loss: 0.5949
Epoch 042, Loss: 0.5556
Epoch 043, Loss: 0.5657
Epoch 044, Loss: 0.5603
Epoch 045, Loss: 0.5851
Epoch 046, Loss: 0.6248
Epoch 047, Loss: 0.6577
Epoch 048, Loss: 0.5628
Epoch 049, Loss: 0.5306
Epoch 050, Loss: 0.5678
Epoch 051, Loss: 0.7073
Epoch 052, Loss: 0.5776
Epoch 053, Loss: 0.5944
Epoch 054, Loss: 0.6039
Epoch 055, Loss: 0.5980
Epoch 056, Loss: 0.6163
Epoch 057, Loss: 0.5873
Epoch 058, Loss: 0.5606
Epoch 059, Loss: 0.5335
Epoch 060, Loss: 0.5694
Epoch 061, Loss: 0.5349
Epoch 062, Loss: 0.5948
Epoch 063, Loss: 0.5225
Epoch 064, Loss: 0.5212
Epoch 065, Loss: 0.5942
Epoch 066, Loss: 0.5701
Epoch 067, Loss: 0.5741
Epoch 068, Loss: 0.5475
Epoch 069, Loss: 0.5794
Epoch 070, Loss: 0.5322
Epoch 071, Loss: 0.5438
Epoch 072, Loss: 0.5246
Epoch 073, Loss: 0.5577
Epoch 074, Loss: 0.5787
Epoch 075, Loss: 0.5931
Epoch 076, Loss: 0.5479
Epoch 077, Loss: 0.5323
Epoch 078, Loss: 0.5157
Epoch 079, Loss: 0.5346
Epoch 080, Loss: 0.5440
Epoch 081, Loss: 0.5575
Epoch 082, Loss: 0.6245
Epoch 083, Loss: 0.5446
Epoch 084, Loss: 0.5754
Epoch 085, Loss: 0.5111
Epoch 086, Loss: 0.5632
Epoch 087, Loss: 0.5521
Epoch 088, Loss: 0.5373
Epoch 089, Loss: 0.5375
Epoch 090, Loss: 0.5850
Epoch 091, Loss: 0.5520
Epoch 092, Loss: 0.5136
Epoch 093, Loss: 0.5262
Epoch 094, Loss: 0.5457
Epoch 095, Loss: 0.5452
Epoch 096, Loss: 0.5253
Epoch 097, Loss: 0.5451
Epoch 098, Loss: 0.5297
Epoch 099, Loss: 0.5421
Epoch 100, Loss: 0.5262

Test RMSE: 0.7652
Test MAPE: 248901407866880.0000
Training time: 63.82 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.659058 2.182500e-01      12.115340   GNN_model_10.pkl
       12   Q_values        0.2 0.685436 2.037804e-01      12.065632   GNN_model_12.pkl
       15   Q_values        0.2 0.829621 2.164876e-01      12.412519   GNN_model_15.pkl
       20   Q_values        0.2 0.857998 2.469417e-01      12.684502   GNN_model_20.pkl
       25   Q_values        0.2 1.667528 2.664404e-01      13.108047   GNN_model_25.pkl
     full   Q_values        0.2 0.765195 2.489014e+14      63.819125 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
