
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59152
 Mean Absolute Percentage Error: 0.24733
 Training time:  0.03105
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55302
 Mean Absolute Percentage Error: 0.39838
 Training time:  0.01763
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71591
 Mean Absolute Percentage Error: 0.57473
 Training time:  0.05974
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86326
 Mean Absolute Percentage Error: 0.53986
 Training time:  0.01710
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70582
 Mean Absolute Percentage Error: 0.30386
 Training time:  0.03422
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52212
 Mean Absolute Percentage Error: 0.17742
 Training time:  0.01662
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60996
 Mean Absolute Percentage Error: 0.21878
 Training time:  0.07543
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61142
 Mean Absolute Percentage Error: 0.25970
 Training time:  0.01651
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53963
 Mean Absolute Percentage Error: 0.17870
 Training time:  0.14908
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67443
 Mean Absolute Percentage Error: 0.21878
 Training time:  0.03309
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61747
 Mean Absolute Percentage Error: 0.23958
 Training time:  0.18441
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65450
 Mean Absolute Percentage Error: 0.29681
 Training time:  0.04758
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60171
  MAPE on 10 nodes subset: 0.26784

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70950
  MAPE on 12 nodes subset: 0.56861

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68696
  MAPE on 15 nodes subset: 0.29118

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58456
  MAPE on 20 nodes subset: 0.22624

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53423
  MAPE on 25 nodes subset: 0.18751

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.591520 0.247331       0.031052       True             3                       MLP_model_10.pkl       25
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553024 0.398377       0.017626       True             4               MLP_model_10_Circuit.pkl       25
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715909 0.574731       0.059744       True             4                       MLP_model_12.pkl       25
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863259 0.539860       0.017105       True             4               MLP_model_12_Circuit.pkl       25
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705824 0.303862       0.034215       True             4                       MLP_model_15.pkl       25
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522123 0.177422       0.016625       True             4               MLP_model_15_Circuit.pkl       25
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.609962 0.218781       0.075426       True             3                       MLP_model_20.pkl       25
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611424 0.259701       0.016506       True             4               MLP_model_20_Circuit.pkl       25
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.539625 0.178698       0.149081       True             4                       MLP_model_25.pkl       25
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674428 0.218776       0.033090       True             4               MLP_model_25_Circuit.pkl       25
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617473 0.239581       0.184412       True             4                     MLP_model_full.pkl       25
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654502 0.296810       0.047584       True             4             MLP_model_full_Circuit.pkl       25
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601706 0.267841       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       25
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709498 0.568615       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       25
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686955 0.291179       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       25
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.584561 0.226241       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       25
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534228 0.187513       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       25

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.62622
 Mean Absolute Percentage Error: 0.45537
 Training time:  0.35737
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76569
 Mean Absolute Percentage Error: 0.40060
 Training time:  0.24776
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98144
 Mean Absolute Percentage Error: 0.65482
 Training time:  0.37134
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10500
 Mean Absolute Percentage Error: 0.66202
 Training time:  0.26041
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62615
 Mean Absolute Percentage Error: 0.19136
 Training time:  0.45823
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79753
 Mean Absolute Percentage Error: 0.22948
 Training time:  0.25404
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65196
 Mean Absolute Percentage Error: 0.27267
 Training time:  0.63950
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85160
 Mean Absolute Percentage Error: 0.33010
 Training time:  0.26142
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74215
 Mean Absolute Percentage Error: 0.22294
 Training time:  0.72302
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70276
 Mean Absolute Percentage Error: 0.19210
 Training time:  0.24698
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72498
 Mean Absolute Percentage Error: 0.31263
 Training time:  2.98758
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75326
 Mean Absolute Percentage Error: 0.30342
 Training time:  0.31080
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24555
  MAPE on 10 nodes subset: 0.02775

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.36852
  MAPE on 12 nodes subset: 0.29008

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.17345
  MAPE on 15 nodes subset: 0.01901

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39858
  MAPE on 20 nodes subset: 0.09250

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19506
  MAPE on 25 nodes subset: 0.02732

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.626220 0.455369       0.357366                           xgboost_model_10.pkl       77
       10             Circuit            50           5          4 0.765695 0.400601       0.247756                   xgboost_model_10_Circuit.pkl       77
       12            Q_values            50          78          4 0.981435 0.654823       0.371337                           xgboost_model_12.pkl       77
       12             Circuit            50           5          4 1.105001 0.662018       0.260409                   xgboost_model_12_Circuit.pkl       77
       15            Q_values            50         120          4 0.626149 0.191365       0.458226                           xgboost_model_15.pkl       77
       15             Circuit            50           5          4 0.797527 0.229484       0.254045                   xgboost_model_15_Circuit.pkl       77
       20            Q_values            50         210          4 0.651963 0.272668       0.639505                           xgboost_model_20.pkl       77
       20             Circuit            50           5          4 0.851603 0.330103       0.261422                   xgboost_model_20_Circuit.pkl       77
       25            Q_values            50         325          4 0.742147 0.222939       0.723017                           xgboost_model_25.pkl       77
       25             Circuit            50           5          4 0.702758 0.192103       0.246977                   xgboost_model_25_Circuit.pkl       77
     full            Q_values           250         325          4 0.724984 0.312633       2.987577                         xgboost_model_full.pkl       77
     full             Circuit           250           5          4 0.753261 0.303421       0.310798                 xgboost_model_full_Circuit.pkl       77
       10 Q_values_full_model            50         325          4 0.245547 0.027753       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       77
       12 Q_values_full_model            50         325          4 0.368523 0.290076       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       77
       15 Q_values_full_model            50         325          4 0.173453 0.019011       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       77
       20 Q_values_full_model            50         325          4 0.398576 0.092499       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       77
       25 Q_values_full_model            50         325          4 0.195064 0.027319       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       77

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.6589
Epoch 002, Loss: 0.6116
Epoch 003, Loss: 0.6212
Epoch 004, Loss: 0.5696
Epoch 005, Loss: 0.6044
Epoch 006, Loss: 0.5949
Epoch 007, Loss: 0.6008
Epoch 008, Loss: 0.6384
Epoch 009, Loss: 0.6008
Epoch 010, Loss: 0.5854
Epoch 011, Loss: 0.5477
Epoch 012, Loss: 0.5470
Epoch 013, Loss: 0.5959
Epoch 014, Loss: 0.5730
Epoch 015, Loss: 0.6034
Epoch 016, Loss: 0.6194
Epoch 017, Loss: 0.5726
Epoch 018, Loss: 0.6151
Epoch 019, Loss: 0.5898
Epoch 020, Loss: 0.5426
Epoch 021, Loss: 0.5862
Epoch 022, Loss: 0.5759
Epoch 023, Loss: 0.5561
Epoch 024, Loss: 0.5475
Epoch 025, Loss: 0.5354
Epoch 026, Loss: 0.5601
Epoch 027, Loss: 0.5638
Epoch 028, Loss: 0.5524
Epoch 029, Loss: 0.5331
Epoch 030, Loss: 0.5911
Epoch 031, Loss: 0.5499
Epoch 032, Loss: 0.5535
Epoch 033, Loss: 0.5247
Epoch 034, Loss: 0.5456
Epoch 035, Loss: 0.5878
Epoch 036, Loss: 0.5379
Epoch 037, Loss: 0.6069
Epoch 038, Loss: 0.5435
Epoch 039, Loss: 0.5154
Epoch 040, Loss: 0.5383
Epoch 041, Loss: 0.5200
Epoch 042, Loss: 0.4970
Epoch 043, Loss: 0.5115
Epoch 044, Loss: 0.5387
Epoch 045, Loss: 0.5433
Epoch 046, Loss: 0.4920
Epoch 047, Loss: 0.5130
Epoch 048, Loss: 0.5131
Epoch 049, Loss: 0.5378
Epoch 050, Loss: 0.5408
Epoch 051, Loss: 0.4923
Epoch 052, Loss: 0.4918
Epoch 053, Loss: 0.4940
Epoch 054, Loss: 0.5018
Epoch 055, Loss: 0.4883
Epoch 056, Loss: 0.4861
Epoch 057, Loss: 0.5196
Epoch 058, Loss: 0.4832
Epoch 059, Loss: 0.5076
Epoch 060, Loss: 0.4799
Epoch 061, Loss: 0.5011
Epoch 062, Loss: 0.4911
Epoch 063, Loss: 0.5136
Epoch 064, Loss: 0.4949
Epoch 065, Loss: 0.4751
Epoch 066, Loss: 0.4969
Epoch 067, Loss: 0.5319
Epoch 068, Loss: 0.5007
Epoch 069, Loss: 0.4606
Epoch 070, Loss: 0.4938
Epoch 071, Loss: 0.4945
Epoch 072, Loss: 0.4842
Epoch 073, Loss: 0.4719
Epoch 074, Loss: 0.5016
Epoch 075, Loss: 0.4888
Epoch 076, Loss: 0.4528
Epoch 077, Loss: 0.4801
Epoch 078, Loss: 0.4653
Epoch 079, Loss: 0.4647
Epoch 080, Loss: 0.4606
Epoch 081, Loss: 0.4733
Epoch 082, Loss: 0.4393
Epoch 083, Loss: 0.4476
Epoch 084, Loss: 0.4418
Epoch 085, Loss: 0.4420
Epoch 086, Loss: 0.4572
Epoch 087, Loss: 0.4785
Epoch 088, Loss: 0.4444
Epoch 089, Loss: 0.4322
Epoch 090, Loss: 0.4228
Epoch 091, Loss: 0.4241
Epoch 092, Loss: 0.4580
Epoch 093, Loss: 0.4357
Epoch 094, Loss: 0.4371
Epoch 095, Loss: 0.4116
Epoch 096, Loss: 0.4207
Epoch 097, Loss: 0.4208
Epoch 098, Loss: 0.4336
Epoch 099, Loss: 0.4459
Epoch 100, Loss: 0.4167

Test RMSE: 0.5996
Test MAPE: 0.2148
Training time: 12.12 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 4.3082
Epoch 002, Loss: 0.8948
Epoch 003, Loss: 0.8615
Epoch 004, Loss: 0.8722
Epoch 005, Loss: 0.8355
Epoch 006, Loss: 0.8713
Epoch 007, Loss: 0.8152
Epoch 008, Loss: 0.8737
Epoch 009, Loss: 0.8079
Epoch 010, Loss: 0.9066
Epoch 011, Loss: 0.8301
Epoch 012, Loss: 0.8152
Epoch 013, Loss: 0.8527
Epoch 014, Loss: 0.8119
Epoch 015, Loss: 0.8583
Epoch 016, Loss: 0.8262
Epoch 017, Loss: 0.8674
Epoch 018, Loss: 0.8558
Epoch 019, Loss: 0.8430
Epoch 020, Loss: 0.7990
Epoch 021, Loss: 0.8759
Epoch 022, Loss: 0.8462
Epoch 023, Loss: 0.8046
Epoch 024, Loss: 0.8195
Epoch 025, Loss: 0.8497
Epoch 026, Loss: 0.8088
Epoch 027, Loss: 0.9297
Epoch 028, Loss: 0.8730
Epoch 029, Loss: 0.7991
Epoch 030, Loss: 0.8425
Epoch 031, Loss: 0.8084
Epoch 032, Loss: 0.7795
Epoch 033, Loss: 0.7918
Epoch 034, Loss: 0.8231
Epoch 035, Loss: 0.8016
Epoch 036, Loss: 0.7871
Epoch 037, Loss: 0.7931
Epoch 038, Loss: 0.8526
Epoch 039, Loss: 0.7874
Epoch 040, Loss: 0.8149
Epoch 041, Loss: 0.8093
Epoch 042, Loss: 0.8088
Epoch 043, Loss: 0.8027
Epoch 044, Loss: 0.7673
Epoch 045, Loss: 0.8353
Epoch 046, Loss: 0.7671
Epoch 047, Loss: 0.7739
Epoch 048, Loss: 0.7578
Epoch 049, Loss: 0.7704
Epoch 050, Loss: 0.7467
Epoch 051, Loss: 0.7560
Epoch 052, Loss: 0.7532
Epoch 053, Loss: 0.7908
Epoch 054, Loss: 0.7533
Epoch 055, Loss: 0.7283
Epoch 056, Loss: 0.7640
Epoch 057, Loss: 0.7479
Epoch 058, Loss: 0.7784
Epoch 059, Loss: 0.7245
Epoch 060, Loss: 0.7407
Epoch 061, Loss: 0.7923
Epoch 062, Loss: 0.7756
Epoch 063, Loss: 0.7866
Epoch 064, Loss: 0.6969
Epoch 065, Loss: 0.7331
Epoch 066, Loss: 0.7474
Epoch 067, Loss: 0.7544
Epoch 068, Loss: 0.7188
Epoch 069, Loss: 0.7309
Epoch 070, Loss: 0.6871
Epoch 071, Loss: 0.6906
Epoch 072, Loss: 0.7262
Epoch 073, Loss: 0.7433
Epoch 074, Loss: 0.7007
Epoch 075, Loss: 0.7219
Epoch 076, Loss: 0.6842
Epoch 077, Loss: 0.7349
Epoch 078, Loss: 0.7010
Epoch 079, Loss: 0.6777
Epoch 080, Loss: 0.7199
Epoch 081, Loss: 0.6833
Epoch 082, Loss: 0.6885
Epoch 083, Loss: 0.6995
Epoch 084, Loss: 0.6689
Epoch 085, Loss: 0.6888
Epoch 086, Loss: 0.6844
Epoch 087, Loss: 0.6570
Epoch 088, Loss: 0.6727
Epoch 089, Loss: 0.6691
Epoch 090, Loss: 0.6718
Epoch 091, Loss: 0.6620
Epoch 092, Loss: 0.6813
Epoch 093, Loss: 0.6672
Epoch 094, Loss: 0.6434
Epoch 095, Loss: 0.6611
Epoch 096, Loss: 0.6098
Epoch 097, Loss: 0.7156
Epoch 098, Loss: 0.6533
Epoch 099, Loss: 0.6386
Epoch 100, Loss: 0.6637

Test RMSE: 0.6982
Test MAPE: 0.2293
Training time: 12.28 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 5.5996
Epoch 002, Loss: 0.9087
Epoch 003, Loss: 0.9711
Epoch 004, Loss: 0.9740
Epoch 005, Loss: 0.9242
Epoch 006, Loss: 1.0373
Epoch 007, Loss: 1.0199
Epoch 008, Loss: 0.9161
Epoch 009, Loss: 1.0566
Epoch 010, Loss: 0.9636
Epoch 011, Loss: 0.9149
Epoch 012, Loss: 0.9273
Epoch 013, Loss: 0.9764
Epoch 014, Loss: 0.9956
Epoch 015, Loss: 1.0536
Epoch 016, Loss: 1.0337
Epoch 017, Loss: 0.9116
Epoch 018, Loss: 0.9294
Epoch 019, Loss: 0.9846
Epoch 020, Loss: 0.8893
Epoch 021, Loss: 0.9793
Epoch 022, Loss: 0.8769
Epoch 023, Loss: 0.9343
Epoch 024, Loss: 0.8495
Epoch 025, Loss: 0.9625
Epoch 026, Loss: 0.9061
Epoch 027, Loss: 0.9002
Epoch 028, Loss: 0.9716
Epoch 029, Loss: 0.9336
Epoch 030, Loss: 0.9041
Epoch 031, Loss: 0.9541
Epoch 032, Loss: 0.8729
Epoch 033, Loss: 0.9084
Epoch 034, Loss: 0.9379
Epoch 035, Loss: 0.9528
Epoch 036, Loss: 0.9308
Epoch 037, Loss: 0.9645
Epoch 038, Loss: 0.9220
Epoch 039, Loss: 0.8764
Epoch 040, Loss: 0.8855
Epoch 041, Loss: 0.9040
Epoch 042, Loss: 0.9053
Epoch 043, Loss: 0.8706
Epoch 044, Loss: 1.0413
Epoch 045, Loss: 0.8971
Epoch 046, Loss: 0.9469
Epoch 047, Loss: 0.9225
Epoch 048, Loss: 0.8620
Epoch 049, Loss: 0.8430
Epoch 050, Loss: 0.8942
Epoch 051, Loss: 0.8385
Epoch 052, Loss: 0.8881
Epoch 053, Loss: 0.8101
Epoch 054, Loss: 0.8407
Epoch 055, Loss: 0.8029
Epoch 056, Loss: 0.8718
Epoch 057, Loss: 0.8689
Epoch 058, Loss: 0.8213
Epoch 059, Loss: 0.8134
Epoch 060, Loss: 0.8027
Epoch 061, Loss: 0.8130
Epoch 062, Loss: 0.8332
Epoch 063, Loss: 0.7826
Epoch 064, Loss: 0.7437
Epoch 065, Loss: 0.7344
Epoch 066, Loss: 0.8372
Epoch 067, Loss: 0.7683
Epoch 068, Loss: 0.8420
Epoch 069, Loss: 0.7715
Epoch 070, Loss: 0.7963
Epoch 071, Loss: 0.7341
Epoch 072, Loss: 0.7250
Epoch 073, Loss: 0.7762
Epoch 074, Loss: 0.7053
Epoch 075, Loss: 0.7269
Epoch 076, Loss: 0.7184
Epoch 077, Loss: 0.7013
Epoch 078, Loss: 0.6607
Epoch 079, Loss: 0.6867
Epoch 080, Loss: 0.7238
Epoch 081, Loss: 0.6709
Epoch 082, Loss: 0.6957
Epoch 083, Loss: 0.6633
Epoch 084, Loss: 0.6649
Epoch 085, Loss: 0.7106
Epoch 086, Loss: 0.6569
Epoch 087, Loss: 0.6313
Epoch 088, Loss: 0.6231
Epoch 089, Loss: 0.6505
Epoch 090, Loss: 0.6447
Epoch 091, Loss: 0.6620
Epoch 092, Loss: 0.6301
Epoch 093, Loss: 0.6282
Epoch 094, Loss: 0.6392
Epoch 095, Loss: 0.6501
Epoch 096, Loss: 0.6178
Epoch 097, Loss: 0.6446
Epoch 098, Loss: 0.5987
Epoch 099, Loss: 0.6395
Epoch 100, Loss: 0.6112

Test RMSE: 0.8388
Test MAPE: 0.2018
Training time: 12.60 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.3901
Epoch 002, Loss: 1.3741
Epoch 003, Loss: 1.2602
Epoch 004, Loss: 1.2965
Epoch 005, Loss: 1.2100
Epoch 006, Loss: 1.3088
Epoch 007, Loss: 1.4862
Epoch 008, Loss: 1.2753
Epoch 009, Loss: 1.3700
Epoch 010, Loss: 1.3512
Epoch 011, Loss: 1.2973
Epoch 012, Loss: 1.2227
Epoch 013, Loss: 1.4022
Epoch 014, Loss: 1.2515
Epoch 015, Loss: 1.2161
Epoch 016, Loss: 1.2408
Epoch 017, Loss: 1.2430
Epoch 018, Loss: 1.2711
Epoch 019, Loss: 1.2034
Epoch 020, Loss: 1.3544
Epoch 021, Loss: 1.2276
Epoch 022, Loss: 1.2171
Epoch 023, Loss: 1.1492
Epoch 024, Loss: 1.1982
Epoch 025, Loss: 1.2827
Epoch 026, Loss: 1.1798
Epoch 027, Loss: 1.2244
Epoch 028, Loss: 1.2065
Epoch 029, Loss: 1.1760
Epoch 030, Loss: 1.2517
Epoch 031, Loss: 1.1624
Epoch 032, Loss: 1.1809
Epoch 033, Loss: 1.1676
Epoch 034, Loss: 1.2272
Epoch 035, Loss: 1.1936
Epoch 036, Loss: 1.2289
Epoch 037, Loss: 1.2141
Epoch 038, Loss: 1.3099
Epoch 039, Loss: 1.1349
Epoch 040, Loss: 1.2771
Epoch 041, Loss: 1.2522
Epoch 042, Loss: 1.3369
Epoch 043, Loss: 1.1856
Epoch 044, Loss: 1.1616
Epoch 045, Loss: 1.1225
Epoch 046, Loss: 1.3175
Epoch 047, Loss: 1.2423
Epoch 048, Loss: 1.1945
Epoch 049, Loss: 1.3255
Epoch 050, Loss: 1.2470
Epoch 051, Loss: 1.3497
Epoch 052, Loss: 1.0613
Epoch 053, Loss: 1.3141
Epoch 054, Loss: 1.2953
Epoch 055, Loss: 1.1863
Epoch 056, Loss: 1.1623
Epoch 057, Loss: 1.1241
Epoch 058, Loss: 1.1380
Epoch 059, Loss: 1.2156
Epoch 060, Loss: 1.2007
Epoch 061, Loss: 1.1765
Epoch 062, Loss: 1.2278
Epoch 063, Loss: 1.2172
Epoch 064, Loss: 1.1637
Epoch 065, Loss: 1.1870
Epoch 066, Loss: 1.1027
Epoch 067, Loss: 1.1507
Epoch 068, Loss: 1.3304
Epoch 069, Loss: 1.1673
Epoch 070, Loss: 1.2223
Epoch 071, Loss: 1.3307
Epoch 072, Loss: 1.1896
Epoch 073, Loss: 1.1756
Epoch 074, Loss: 1.1620
Epoch 075, Loss: 1.1420
Epoch 076, Loss: 1.1192
Epoch 077, Loss: 1.1690
Epoch 078, Loss: 1.1706
Epoch 079, Loss: 1.2063
Epoch 080, Loss: 1.1719
Epoch 081, Loss: 1.1690
Epoch 082, Loss: 1.2189
Epoch 083, Loss: 1.1763
Epoch 084, Loss: 1.0894
Epoch 085, Loss: 1.3423
Epoch 086, Loss: 1.1187
Epoch 087, Loss: 1.0711
Epoch 088, Loss: 1.1251
Epoch 089, Loss: 1.1181
Epoch 090, Loss: 1.1822
Epoch 091, Loss: 1.1099
Epoch 092, Loss: 1.1276
Epoch 093, Loss: 1.2729
Epoch 094, Loss: 1.3008
Epoch 095, Loss: 1.2180
Epoch 096, Loss: 1.2066
Epoch 097, Loss: 1.1823
Epoch 098, Loss: 1.1005
Epoch 099, Loss: 1.0733
Epoch 100, Loss: 1.1172

Test RMSE: 1.1226
Test MAPE: 0.3316
Training time: 12.96 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.7568
Epoch 002, Loss: 1.8744
Epoch 003, Loss: 1.7889
Epoch 004, Loss: 1.6264
Epoch 005, Loss: 1.6867
Epoch 006, Loss: 1.5883
Epoch 007, Loss: 1.6169
Epoch 008, Loss: 1.5902
Epoch 009, Loss: 1.6759
Epoch 010, Loss: 1.6765
Epoch 011, Loss: 1.5103
Epoch 012, Loss: 1.6696
Epoch 013, Loss: 1.6185
Epoch 014, Loss: 1.6021
Epoch 015, Loss: 1.6096
Epoch 016, Loss: 1.6129
Epoch 017, Loss: 1.7279
Epoch 018, Loss: 1.4986
Epoch 019, Loss: 1.5785
Epoch 020, Loss: 1.6334
Epoch 021, Loss: 1.6493
Epoch 022, Loss: 1.7537
Epoch 023, Loss: 1.4911
Epoch 024, Loss: 1.5191
Epoch 025, Loss: 1.4609
Epoch 026, Loss: 1.6790
Epoch 027, Loss: 1.7859
Epoch 028, Loss: 1.6748
Epoch 029, Loss: 1.4943
Epoch 030, Loss: 1.5783
Epoch 031, Loss: 1.5420
Epoch 032, Loss: 1.5893
Epoch 033, Loss: 1.4076
Epoch 034, Loss: 1.6203
Epoch 035, Loss: 1.5376
Epoch 036, Loss: 1.5487
Epoch 037, Loss: 1.4726
Epoch 038, Loss: 1.5507
Epoch 039, Loss: 1.5313
Epoch 040, Loss: 1.6804
Epoch 041, Loss: 1.7663
Epoch 042, Loss: 1.8597
Epoch 043, Loss: 1.6724
Epoch 044, Loss: 1.4852
Epoch 045, Loss: 1.2234
Epoch 046, Loss: 1.7340
Epoch 047, Loss: 1.5441
Epoch 048, Loss: 1.4747
Epoch 049, Loss: 1.6329
Epoch 050, Loss: 1.5947
Epoch 051, Loss: 1.4082
Epoch 052, Loss: 1.5213
Epoch 053, Loss: 1.3752
Epoch 054, Loss: 1.4825
Epoch 055, Loss: 1.4133
Epoch 056, Loss: 1.3009
Epoch 057, Loss: 1.9032
Epoch 058, Loss: 1.4521
Epoch 059, Loss: 1.4370
Epoch 060, Loss: 1.5551
Epoch 061, Loss: 1.8148
Epoch 062, Loss: 1.4821
Epoch 063, Loss: 1.3682
Epoch 064, Loss: 1.5164
Epoch 065, Loss: 1.5585
Epoch 066, Loss: 1.4075
Epoch 067, Loss: 1.6235
Epoch 068, Loss: 1.4935
Epoch 069, Loss: 1.3704
Epoch 070, Loss: 1.5125
Epoch 071, Loss: 1.6186
Epoch 072, Loss: 1.5588
Epoch 073, Loss: 1.4082
Epoch 074, Loss: 1.4758
Epoch 075, Loss: 1.4161
Epoch 076, Loss: 1.5096
Epoch 077, Loss: 1.5166
Epoch 078, Loss: 1.5249
Epoch 079, Loss: 1.4934
Epoch 080, Loss: 1.4391
Epoch 081, Loss: 1.5117
Epoch 082, Loss: 1.5869
Epoch 083, Loss: 1.4521
Epoch 084, Loss: 1.5194
Epoch 085, Loss: 1.4006
Epoch 086, Loss: 1.2944
Epoch 087, Loss: 1.4468
Epoch 088, Loss: 1.6554
Epoch 089, Loss: 1.4154
Epoch 090, Loss: 1.5084
Epoch 091, Loss: 1.4892
Epoch 092, Loss: 1.4039
Epoch 093, Loss: 1.4552
Epoch 094, Loss: 1.4610
Epoch 095, Loss: 1.3653
Epoch 096, Loss: 1.5380
Epoch 097, Loss: 1.3434
Epoch 098, Loss: 1.5413
Epoch 099, Loss: 1.3787
Epoch 100, Loss: 1.3415

Test RMSE: 1.5316
Test MAPE: 0.2094
Training time: 13.32 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8132
Epoch 002, Loss: 3.2693
Epoch 003, Loss: 2.1437
Epoch 004, Loss: 0.9440
Epoch 005, Loss: 0.7762
Epoch 006, Loss: 0.7706
Epoch 007, Loss: 0.7420
Epoch 008, Loss: 0.7400
Epoch 009, Loss: 0.7105
Epoch 010, Loss: 0.7392
Epoch 011, Loss: 0.6581
Epoch 012, Loss: 0.6511
Epoch 013, Loss: 0.7108
Epoch 014, Loss: 0.6675
Epoch 015, Loss: 0.6850
Epoch 016, Loss: 0.6412
Epoch 017, Loss: 0.6470
Epoch 018, Loss: 0.7025
Epoch 019, Loss: 0.6629
Epoch 020, Loss: 0.6663
Epoch 021, Loss: 0.6351
Epoch 022, Loss: 0.6234
Epoch 023, Loss: 0.5946
Epoch 024, Loss: 0.6419
Epoch 025, Loss: 0.6293
Epoch 026, Loss: 0.6121
Epoch 027, Loss: 0.6133
Epoch 028, Loss: 0.5987
Epoch 029, Loss: 0.6295
Epoch 030, Loss: 0.5793
Epoch 031, Loss: 0.6308
Epoch 032, Loss: 0.6313
Epoch 033, Loss: 0.6204
Epoch 034, Loss: 0.5853
Epoch 035, Loss: 0.6068
Epoch 036, Loss: 0.5964
Epoch 037, Loss: 0.5795
Epoch 038, Loss: 0.5805
Epoch 039, Loss: 0.5851
Epoch 040, Loss: 0.6041
Epoch 041, Loss: 0.5885
Epoch 042, Loss: 0.5599
Epoch 043, Loss: 0.5773
Epoch 044, Loss: 0.5753
Epoch 045, Loss: 0.5546
Epoch 046, Loss: 0.5478
Epoch 047, Loss: 0.5590
Epoch 048, Loss: 0.6092
Epoch 049, Loss: 0.6116
Epoch 050, Loss: 0.5324
Epoch 051, Loss: 0.5639
Epoch 052, Loss: 0.5152
Epoch 053, Loss: 0.5657
Epoch 054, Loss: 0.5443
Epoch 055, Loss: 0.5322
Epoch 056, Loss: 0.5426
Epoch 057, Loss: 0.5720
Epoch 058, Loss: 0.5674
Epoch 059, Loss: 0.5441
Epoch 060, Loss: 0.5955
Epoch 061, Loss: 0.6048
Epoch 062, Loss: 0.5664
Epoch 063, Loss: 0.5794
Epoch 064, Loss: 0.5138
Epoch 065, Loss: 0.5266
Epoch 066, Loss: 0.5293
Epoch 067, Loss: 0.5581
Epoch 068, Loss: 0.5420
Epoch 069, Loss: 0.5374
Epoch 070, Loss: 0.5300
Epoch 071, Loss: 0.5273
Epoch 072, Loss: 0.5279
Epoch 073, Loss: 0.5353
Epoch 074, Loss: 0.5124
Epoch 075, Loss: 0.5009
Epoch 076, Loss: 0.5247
Epoch 077, Loss: 0.5530
Epoch 078, Loss: 0.4998
Epoch 079, Loss: 0.4929
Epoch 080, Loss: 0.4973
Epoch 081, Loss: 0.4798
Epoch 082, Loss: 0.4778
Epoch 083, Loss: 0.4939
Epoch 084, Loss: 0.5067
Epoch 085, Loss: 0.4976
Epoch 086, Loss: 0.4956
Epoch 087, Loss: 0.5326
Epoch 088, Loss: 0.5043
Epoch 089, Loss: 0.4929
Epoch 090, Loss: 0.4758
Epoch 091, Loss: 0.5175
Epoch 092, Loss: 0.4762
Epoch 093, Loss: 0.4588
Epoch 094, Loss: 0.4978
Epoch 095, Loss: 0.4966
Epoch 096, Loss: 0.4731
Epoch 097, Loss: 0.4670
Epoch 098, Loss: 0.4568
Epoch 099, Loss: 0.4820
Epoch 100, Loss: 0.5244

Test RMSE: 0.7865
Test MAPE: 225380388569088.0000
Training time: 64.83 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.599562 2.147618e-01      12.118110   GNN_model_10.pkl
       12   Q_values        0.2 0.698185 2.293082e-01      12.278022   GNN_model_12.pkl
       15   Q_values        0.2 0.838824 2.018411e-01      12.596935   GNN_model_15.pkl
       20   Q_values        0.2 1.122561 3.315780e-01      12.957335   GNN_model_20.pkl
       25   Q_values        0.2 1.531568 2.093669e-01      13.316936   GNN_model_25.pkl
     full   Q_values        0.2 0.786546 2.253804e+14      64.831688 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 74%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
