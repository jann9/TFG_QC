
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59776
 Mean Absolute Percentage Error: 0.25504
 Training time:  0.17005
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55352
 Mean Absolute Percentage Error: 0.39903
 Training time:  0.09987
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71578
 Mean Absolute Percentage Error: 0.57806
 Training time:  0.14033
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86324
 Mean Absolute Percentage Error: 0.54118
 Training time:  0.01817
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70555
 Mean Absolute Percentage Error: 0.30435
 Training time:  0.03652
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52108
 Mean Absolute Percentage Error: 0.17750
 Training time:  0.05324
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60609
 Mean Absolute Percentage Error: 0.21865
 Training time:  0.04910
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61158
 Mean Absolute Percentage Error: 0.26016
 Training time:  0.05268
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54033
 Mean Absolute Percentage Error: 0.18012
 Training time:  0.10912
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67449
 Mean Absolute Percentage Error: 0.21911
 Training time:  0.01785
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61684
 Mean Absolute Percentage Error: 0.24004
 Training time:  0.11252
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65498
 Mean Absolute Percentage Error: 0.29757
 Training time:  0.02462
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60273
  MAPE on 10 nodes subset: 0.26847

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70995
  MAPE on 12 nodes subset: 0.57076

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68639
  MAPE on 15 nodes subset: 0.29324

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58659
  MAPE on 20 nodes subset: 0.22838

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53423
  MAPE on 25 nodes subset: 0.18748

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597756 0.255040       0.170048       True             4                       MLP_model_10.pkl       57
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553521 0.399032       0.099866       True             4               MLP_model_10_Circuit.pkl       57
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715781 0.578065       0.140326       True             4                       MLP_model_12.pkl       57
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863244 0.541182       0.018173       True             4               MLP_model_12_Circuit.pkl       57
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705550 0.304350       0.036519       True             4                       MLP_model_15.pkl       57
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521080 0.177502       0.053241       True             4               MLP_model_15_Circuit.pkl       57
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.606090 0.218646       0.049104       True             3                       MLP_model_20.pkl       57
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611579 0.260155       0.052682       True             4               MLP_model_20_Circuit.pkl       57
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540330 0.180122       0.109119       True             4                       MLP_model_25.pkl       57
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674486 0.219113       0.017852       True             4               MLP_model_25_Circuit.pkl       57
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616844 0.240042       0.112522       True             4                     MLP_model_full.pkl       57
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654984 0.297572       0.024615       True             4             MLP_model_full_Circuit.pkl       57
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602733 0.268467       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       57
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709949 0.570761       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       57
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686390 0.293241       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       57
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586589 0.228381       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       57
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534227 0.187481       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       57

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61183
 Mean Absolute Percentage Error: 0.42688
 Training time:  0.39102
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.77393
 Mean Absolute Percentage Error: 0.40798
 Training time:  0.25153
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98542
 Mean Absolute Percentage Error: 0.66534
 Training time:  0.39580
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.09762
 Mean Absolute Percentage Error: 0.66033
 Training time:  0.25312
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.63002
 Mean Absolute Percentage Error: 0.19947
 Training time:  0.47235
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80075
 Mean Absolute Percentage Error: 0.23256
 Training time:  0.25946
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.62797
 Mean Absolute Percentage Error: 0.26437
 Training time:  0.68656
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85122
 Mean Absolute Percentage Error: 0.32973
 Training time:  0.27606
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.75148
 Mean Absolute Percentage Error: 0.23823
 Training time:  0.79295
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69865
 Mean Absolute Percentage Error: 0.18869
 Training time:  0.26032
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71282
 Mean Absolute Percentage Error: 0.30580
 Training time:  3.29010
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75456
 Mean Absolute Percentage Error: 0.29976
 Training time:  0.32870
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22309
  MAPE on 10 nodes subset: 0.02678

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.32641
  MAPE on 12 nodes subset: 0.26721

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13485
  MAPE on 15 nodes subset: 0.01590

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40605
  MAPE on 20 nodes subset: 0.09309

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19719
  MAPE on 25 nodes subset: 0.02696

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.611832 0.426885       0.391017                           xgboost_model_10.pkl       42
       10             Circuit            50           5          4 0.773931 0.407978       0.251527                   xgboost_model_10_Circuit.pkl       42
       12            Q_values            50          78          4 0.985424 0.665339       0.395801                           xgboost_model_12.pkl       42
       12             Circuit            50           5          4 1.097616 0.660332       0.253124                   xgboost_model_12_Circuit.pkl       42
       15            Q_values            50         120          4 0.630019 0.199471       0.472350                           xgboost_model_15.pkl       42
       15             Circuit            50           5          4 0.800749 0.232561       0.259465                   xgboost_model_15_Circuit.pkl       42
       20            Q_values            50         210          4 0.627970 0.264373       0.686559                           xgboost_model_20.pkl       42
       20             Circuit            50           5          4 0.851224 0.329730       0.276063                   xgboost_model_20_Circuit.pkl       42
       25            Q_values            50         325          4 0.751480 0.238227       0.792946                           xgboost_model_25.pkl       42
       25             Circuit            50           5          4 0.698652 0.188693       0.260316                   xgboost_model_25_Circuit.pkl       42
     full            Q_values           250         325          4 0.712815 0.305798       3.290102                         xgboost_model_full.pkl       42
     full             Circuit           250           5          4 0.754562 0.299760       0.328701                 xgboost_model_full_Circuit.pkl       42
       10 Q_values_full_model            50         325          4 0.223086 0.026776       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       42
       12 Q_values_full_model            50         325          4 0.326409 0.267205       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       42
       15 Q_values_full_model            50         325          4 0.134851 0.015899       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       42
       20 Q_values_full_model            50         325          4 0.406049 0.093089       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       42
       25 Q_values_full_model            50         325          4 0.197187 0.026965       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       42

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.2323
Epoch 002, Loss: 0.6124
Epoch 003, Loss: 0.5749
Epoch 004, Loss: 0.5715
Epoch 005, Loss: 0.5855
Epoch 006, Loss: 0.5939
Epoch 007, Loss: 0.6257
Epoch 008, Loss: 0.5482
Epoch 009, Loss: 0.5970
Epoch 010, Loss: 0.6214
Epoch 011, Loss: 0.5957
Epoch 012, Loss: 0.5766
Epoch 013, Loss: 0.5680
Epoch 014, Loss: 0.6117
Epoch 015, Loss: 0.6081
Epoch 016, Loss: 0.5620
Epoch 017, Loss: 0.5526
Epoch 018, Loss: 0.6175
Epoch 019, Loss: 0.5725
Epoch 020, Loss: 0.5980
Epoch 021, Loss: 0.5683
Epoch 022, Loss: 0.5486
Epoch 023, Loss: 0.5947
Epoch 024, Loss: 0.5718
Epoch 025, Loss: 0.5703
Epoch 026, Loss: 0.6220
Epoch 027, Loss: 0.6124
Epoch 028, Loss: 0.5940
Epoch 029, Loss: 0.5541
Epoch 030, Loss: 0.5343
Epoch 031, Loss: 0.5574
Epoch 032, Loss: 0.5879
Epoch 033, Loss: 0.6275
Epoch 034, Loss: 0.5381
Epoch 035, Loss: 0.5626
Epoch 036, Loss: 0.5747
Epoch 037, Loss: 0.5232
Epoch 038, Loss: 0.5345
Epoch 039, Loss: 0.5447
Epoch 040, Loss: 0.5312
Epoch 041, Loss: 0.5368
Epoch 042, Loss: 0.5622
Epoch 043, Loss: 0.5212
Epoch 044, Loss: 0.5417
Epoch 045, Loss: 0.5512
Epoch 046, Loss: 0.5438
Epoch 047, Loss: 0.5630
Epoch 048, Loss: 0.5256
Epoch 049, Loss: 0.5413
Epoch 050, Loss: 0.5199
Epoch 051, Loss: 0.5408
Epoch 052, Loss: 0.5004
Epoch 053, Loss: 0.5382
Epoch 054, Loss: 0.5201
Epoch 055, Loss: 0.5047
Epoch 056, Loss: 0.5181
Epoch 057, Loss: 0.5046
Epoch 058, Loss: 0.4861
Epoch 059, Loss: 0.4943
Epoch 060, Loss: 0.5247
Epoch 061, Loss: 0.4984
Epoch 062, Loss: 0.5069
Epoch 063, Loss: 0.4874
Epoch 064, Loss: 0.4885
Epoch 065, Loss: 0.5037
Epoch 066, Loss: 0.4874
Epoch 067, Loss: 0.4927
Epoch 068, Loss: 0.4864
Epoch 069, Loss: 0.5187
Epoch 070, Loss: 0.5002
Epoch 071, Loss: 0.4831
Epoch 072, Loss: 0.4912
Epoch 073, Loss: 0.4714
Epoch 074, Loss: 0.5071
Epoch 075, Loss: 0.4915
Epoch 076, Loss: 0.4918
Epoch 077, Loss: 0.4842
Epoch 078, Loss: 0.4602
Epoch 079, Loss: 0.4668
Epoch 080, Loss: 0.4699
Epoch 081, Loss: 0.4788
Epoch 082, Loss: 0.4952
Epoch 083, Loss: 0.4667
Epoch 084, Loss: 0.4568
Epoch 085, Loss: 0.4640
Epoch 086, Loss: 0.4605
Epoch 087, Loss: 0.4657
Epoch 088, Loss: 0.4457
Epoch 089, Loss: 0.4741
Epoch 090, Loss: 0.5106
Epoch 091, Loss: 0.4983
Epoch 092, Loss: 0.4997
Epoch 093, Loss: 0.4750
Epoch 094, Loss: 0.4484
Epoch 095, Loss: 0.4416
Epoch 096, Loss: 0.4396
Epoch 097, Loss: 0.4492
Epoch 098, Loss: 0.4321
Epoch 099, Loss: 0.4423
Epoch 100, Loss: 0.4384

Test RMSE: 0.5962
Test MAPE: 0.2080
Training time: 15.02 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.5718
Epoch 002, Loss: 0.8533
Epoch 003, Loss: 0.8322
Epoch 004, Loss: 0.8286
Epoch 005, Loss: 0.8744
Epoch 006, Loss: 0.8390
Epoch 007, Loss: 0.9079
Epoch 008, Loss: 0.8256
Epoch 009, Loss: 0.8350
Epoch 010, Loss: 0.8911
Epoch 011, Loss: 0.8549
Epoch 012, Loss: 0.8208
Epoch 013, Loss: 0.8072
Epoch 014, Loss: 0.8947
Epoch 015, Loss: 0.8028
Epoch 016, Loss: 0.8610
Epoch 017, Loss: 0.8952
Epoch 018, Loss: 0.9120
Epoch 019, Loss: 0.8863
Epoch 020, Loss: 0.8281
Epoch 021, Loss: 0.7850
Epoch 022, Loss: 0.8162
Epoch 023, Loss: 0.7884
Epoch 024, Loss: 0.8027
Epoch 025, Loss: 0.7926
Epoch 026, Loss: 0.7824
Epoch 027, Loss: 0.8630
Epoch 028, Loss: 0.8153
Epoch 029, Loss: 0.7687
Epoch 030, Loss: 0.7922
Epoch 031, Loss: 0.7947
Epoch 032, Loss: 0.7899
Epoch 033, Loss: 0.7698
Epoch 034, Loss: 0.8309
Epoch 035, Loss: 0.7566
Epoch 036, Loss: 0.7595
Epoch 037, Loss: 0.8017
Epoch 038, Loss: 0.7540
Epoch 039, Loss: 0.7210
Epoch 040, Loss: 0.7521
Epoch 041, Loss: 0.7500
Epoch 042, Loss: 0.7320
Epoch 043, Loss: 0.7165
Epoch 044, Loss: 0.7453
Epoch 045, Loss: 0.7175
Epoch 046, Loss: 0.6950
Epoch 047, Loss: 0.7229
Epoch 048, Loss: 0.6859
Epoch 049, Loss: 0.7194
Epoch 050, Loss: 0.7076
Epoch 051, Loss: 0.6835
Epoch 052, Loss: 0.6773
Epoch 053, Loss: 0.6675
Epoch 054, Loss: 0.7045
Epoch 055, Loss: 0.6960
Epoch 056, Loss: 0.7128
Epoch 057, Loss: 0.6755
Epoch 058, Loss: 0.6695
Epoch 059, Loss: 0.6482
Epoch 060, Loss: 0.6617
Epoch 061, Loss: 0.6498
Epoch 062, Loss: 0.6650
Epoch 063, Loss: 0.6258
Epoch 064, Loss: 0.6648
Epoch 065, Loss: 0.6489
Epoch 066, Loss: 0.6198
Epoch 067, Loss: 0.6029
Epoch 068, Loss: 0.6236
Epoch 069, Loss: 0.6589
Epoch 070, Loss: 0.6380
Epoch 071, Loss: 0.6178
Epoch 072, Loss: 0.5950
Epoch 073, Loss: 0.6441
Epoch 074, Loss: 0.5992
Epoch 075, Loss: 0.6092
Epoch 076, Loss: 0.5859
Epoch 077, Loss: 0.6062
Epoch 078, Loss: 0.6150
Epoch 079, Loss: 0.6289
Epoch 080, Loss: 0.5942
Epoch 081, Loss: 0.6045
Epoch 082, Loss: 0.6136
Epoch 083, Loss: 0.5866
Epoch 084, Loss: 0.5880
Epoch 085, Loss: 0.6055
Epoch 086, Loss: 0.5664
Epoch 087, Loss: 0.6100
Epoch 088, Loss: 0.5911
Epoch 089, Loss: 0.5971
Epoch 090, Loss: 0.5599
Epoch 091, Loss: 0.5762
Epoch 092, Loss: 0.5768
Epoch 093, Loss: 0.5701
Epoch 094, Loss: 0.5825
Epoch 095, Loss: 0.5851
Epoch 096, Loss: 0.6149
Epoch 097, Loss: 0.5559
Epoch 098, Loss: 0.5897
Epoch 099, Loss: 0.5856
Epoch 100, Loss: 0.5722

Test RMSE: 0.6644
Test MAPE: 0.1964
Training time: 15.05 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.8831
Epoch 002, Loss: 1.0375
Epoch 003, Loss: 0.9291
Epoch 004, Loss: 1.0676
Epoch 005, Loss: 1.0676
Epoch 006, Loss: 0.9013
Epoch 007, Loss: 0.9245
Epoch 008, Loss: 0.8937
Epoch 009, Loss: 1.0630
Epoch 010, Loss: 0.9762
Epoch 011, Loss: 1.0676
Epoch 012, Loss: 0.9902
Epoch 013, Loss: 0.9978
Epoch 014, Loss: 0.9177
Epoch 015, Loss: 0.9582
Epoch 016, Loss: 0.8943
Epoch 017, Loss: 0.9283
Epoch 018, Loss: 0.9207
Epoch 019, Loss: 0.8655
Epoch 020, Loss: 0.8549
Epoch 021, Loss: 0.8865
Epoch 022, Loss: 1.0068
Epoch 023, Loss: 0.9617
Epoch 024, Loss: 0.9294
Epoch 025, Loss: 0.8161
Epoch 026, Loss: 0.9067
Epoch 027, Loss: 0.8890
Epoch 028, Loss: 0.8836
Epoch 029, Loss: 0.8823
Epoch 030, Loss: 0.8280
Epoch 031, Loss: 0.8424
Epoch 032, Loss: 0.7918
Epoch 033, Loss: 0.8248
Epoch 034, Loss: 0.8664
Epoch 035, Loss: 0.7455
Epoch 036, Loss: 0.7736
Epoch 037, Loss: 0.8298
Epoch 038, Loss: 0.8344
Epoch 039, Loss: 0.7663
Epoch 040, Loss: 0.7908
Epoch 041, Loss: 0.7352
Epoch 042, Loss: 0.7754
Epoch 043, Loss: 0.9146
Epoch 044, Loss: 0.8366
Epoch 045, Loss: 0.7374
Epoch 046, Loss: 0.7671
Epoch 047, Loss: 0.6997
Epoch 048, Loss: 0.7713
Epoch 049, Loss: 0.6772
Epoch 050, Loss: 0.7013
Epoch 051, Loss: 0.6978
Epoch 052, Loss: 0.6861
Epoch 053, Loss: 0.7064
Epoch 054, Loss: 0.7201
Epoch 055, Loss: 0.6564
Epoch 056, Loss: 0.6072
Epoch 057, Loss: 0.6558
Epoch 058, Loss: 0.6726
Epoch 059, Loss: 0.6683
Epoch 060, Loss: 0.6672
Epoch 061, Loss: 0.6652
Epoch 062, Loss: 0.6796
Epoch 063, Loss: 0.6363
Epoch 064, Loss: 0.6635
Epoch 065, Loss: 0.5743
Epoch 066, Loss: 0.6827
Epoch 067, Loss: 0.6196
Epoch 068, Loss: 0.6178
Epoch 069, Loss: 0.6136
Epoch 070, Loss: 0.6061
Epoch 071, Loss: 0.5435
Epoch 072, Loss: 0.6677
Epoch 073, Loss: 0.6272
Epoch 074, Loss: 0.5650
Epoch 075, Loss: 0.6327
Epoch 076, Loss: 0.6061
Epoch 077, Loss: 0.5747
Epoch 078, Loss: 0.6049
Epoch 079, Loss: 0.6151
Epoch 080, Loss: 0.6386
Epoch 081, Loss: 0.6002
Epoch 082, Loss: 0.5920
Epoch 083, Loss: 0.5810
Epoch 084, Loss: 0.6110
Epoch 085, Loss: 0.6539
Epoch 086, Loss: 0.6153
Epoch 087, Loss: 0.6263
Epoch 088, Loss: 0.5979
Epoch 089, Loss: 0.5647
Epoch 090, Loss: 0.5410
Epoch 091, Loss: 0.5629
Epoch 092, Loss: 0.5643
Epoch 093, Loss: 0.5232
Epoch 094, Loss: 0.5328
Epoch 095, Loss: 0.5503
Epoch 096, Loss: 0.5428
Epoch 097, Loss: 0.5470
Epoch 098, Loss: 0.5294
Epoch 099, Loss: 0.5145
Epoch 100, Loss: 0.5564

Test RMSE: 0.7712
Test MAPE: 0.2092
Training time: 15.21 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.5200
Epoch 002, Loss: 1.2389
Epoch 003, Loss: 1.3272
Epoch 004, Loss: 1.2169
Epoch 005, Loss: 1.1757
Epoch 006, Loss: 1.2936
Epoch 007, Loss: 1.4085
Epoch 008, Loss: 1.5520
Epoch 009, Loss: 1.5059
Epoch 010, Loss: 1.1864
Epoch 011, Loss: 1.1752
Epoch 012, Loss: 1.2592
Epoch 013, Loss: 1.3165
Epoch 014, Loss: 1.2691
Epoch 015, Loss: 1.3238
Epoch 016, Loss: 1.3004
Epoch 017, Loss: 1.3260
Epoch 018, Loss: 1.2555
Epoch 019, Loss: 1.1963
Epoch 020, Loss: 1.4659
Epoch 021, Loss: 1.3483
Epoch 022, Loss: 1.6312
Epoch 023, Loss: 1.1560
Epoch 024, Loss: 1.3043
Epoch 025, Loss: 1.2252
Epoch 026, Loss: 1.1834
Epoch 027, Loss: 1.3241
Epoch 028, Loss: 1.1960
Epoch 029, Loss: 1.1910
Epoch 030, Loss: 1.2488
Epoch 031, Loss: 1.2172
Epoch 032, Loss: 1.1422
Epoch 033, Loss: 1.3846
Epoch 034, Loss: 1.1501
Epoch 035, Loss: 1.2719
Epoch 036, Loss: 1.2841
Epoch 037, Loss: 1.2328
Epoch 038, Loss: 1.1917
Epoch 039, Loss: 1.3030
Epoch 040, Loss: 1.3299
Epoch 041, Loss: 1.1813
Epoch 042, Loss: 1.1824
Epoch 043, Loss: 1.3849
Epoch 044, Loss: 1.4145
Epoch 045, Loss: 1.2375
Epoch 046, Loss: 1.2752
Epoch 047, Loss: 1.2753
Epoch 048, Loss: 1.1471
Epoch 049, Loss: 1.2098
Epoch 050, Loss: 1.2301
Epoch 051, Loss: 1.2362
Epoch 052, Loss: 1.3279
Epoch 053, Loss: 1.1468
Epoch 054, Loss: 1.2585
Epoch 055, Loss: 1.1743
Epoch 056, Loss: 1.1771
Epoch 057, Loss: 1.1407
Epoch 058, Loss: 1.2666
Epoch 059, Loss: 1.1955
Epoch 060, Loss: 1.3191
Epoch 061, Loss: 1.2695
Epoch 062, Loss: 1.3382
Epoch 063, Loss: 1.1511
Epoch 064, Loss: 1.2980
Epoch 065, Loss: 1.1052
Epoch 066, Loss: 1.1107
Epoch 067, Loss: 1.1553
Epoch 068, Loss: 0.9979
Epoch 069, Loss: 1.0651
Epoch 070, Loss: 1.0954
Epoch 071, Loss: 1.1451
Epoch 072, Loss: 1.0033
Epoch 073, Loss: 0.9833
Epoch 074, Loss: 0.9983
Epoch 075, Loss: 0.9381
Epoch 076, Loss: 0.8928
Epoch 077, Loss: 1.0042
Epoch 078, Loss: 0.9565
Epoch 079, Loss: 0.8770
Epoch 080, Loss: 0.9088
Epoch 081, Loss: 0.9076
Epoch 082, Loss: 0.8859
Epoch 083, Loss: 0.8395
Epoch 084, Loss: 0.8338
Epoch 085, Loss: 0.8077
Epoch 086, Loss: 0.8379
Epoch 087, Loss: 0.8182
Epoch 088, Loss: 0.8424
Epoch 089, Loss: 0.8648
Epoch 090, Loss: 0.7898
Epoch 091, Loss: 0.7723
Epoch 092, Loss: 0.7546
Epoch 093, Loss: 0.7569
Epoch 094, Loss: 0.7456
Epoch 095, Loss: 0.7579
Epoch 096, Loss: 0.8044
Epoch 097, Loss: 0.7532
Epoch 098, Loss: 0.7540
Epoch 099, Loss: 0.7029
Epoch 100, Loss: 0.8608

Test RMSE: 1.0237
Test MAPE: 0.2252
Training time: 15.76 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.1494
Epoch 002, Loss: 1.7305
Epoch 003, Loss: 1.6421
Epoch 004, Loss: 1.8908
Epoch 005, Loss: 1.9559
Epoch 006, Loss: 1.5366
Epoch 007, Loss: 2.0638
Epoch 008, Loss: 1.5463
Epoch 009, Loss: 1.6586
Epoch 010, Loss: 1.6030
Epoch 011, Loss: 1.6104
Epoch 012, Loss: 1.6252
Epoch 013, Loss: 1.6513
Epoch 014, Loss: 1.5533
Epoch 015, Loss: 1.5554
Epoch 016, Loss: 1.5682
Epoch 017, Loss: 1.4313
Epoch 018, Loss: 1.6981
Epoch 019, Loss: 1.6196
Epoch 020, Loss: 1.6139
Epoch 021, Loss: 1.6782
Epoch 022, Loss: 1.5746
Epoch 023, Loss: 1.5460
Epoch 024, Loss: 1.5116
Epoch 025, Loss: 1.6205
Epoch 026, Loss: 1.5797
Epoch 027, Loss: 1.7862
Epoch 028, Loss: 1.8218
Epoch 029, Loss: 1.5835
Epoch 030, Loss: 1.5032
Epoch 031, Loss: 1.4952
Epoch 032, Loss: 1.5339
Epoch 033, Loss: 1.2916
Epoch 034, Loss: 1.7313
Epoch 035, Loss: 1.3964
Epoch 036, Loss: 1.7610
Epoch 037, Loss: 1.4914
Epoch 038, Loss: 1.4631
Epoch 039, Loss: 1.5507
Epoch 040, Loss: 1.6448
Epoch 041, Loss: 1.6374
Epoch 042, Loss: 1.5838
Epoch 043, Loss: 1.5746
Epoch 044, Loss: 1.5247
Epoch 045, Loss: 1.6181
Epoch 046, Loss: 1.7126
Epoch 047, Loss: 1.4487
Epoch 048, Loss: 1.5365
Epoch 049, Loss: 1.6766
Epoch 050, Loss: 1.4425
Epoch 051, Loss: 1.5587
Epoch 052, Loss: 1.5031
Epoch 053, Loss: 1.4141
Epoch 054, Loss: 1.7529
Epoch 055, Loss: 1.6820
Epoch 056, Loss: 1.4758
Epoch 057, Loss: 1.6487
Epoch 058, Loss: 1.4350
Epoch 059, Loss: 1.4805
Epoch 060, Loss: 1.4480
Epoch 061, Loss: 1.6057
Epoch 062, Loss: 1.5290
Epoch 063, Loss: 1.4649
Epoch 064, Loss: 1.5954
Epoch 065, Loss: 1.3854
Epoch 066, Loss: 1.4777
Epoch 067, Loss: 1.4386
Epoch 068, Loss: 1.3662
Epoch 069, Loss: 1.4865
Epoch 070, Loss: 1.5038
Epoch 071, Loss: 1.4366
Epoch 072, Loss: 1.3898
Epoch 073, Loss: 1.4478
Epoch 074, Loss: 1.4118
Epoch 075, Loss: 1.4242
Epoch 076, Loss: 1.4336
Epoch 077, Loss: 1.6337
Epoch 078, Loss: 1.3028
Epoch 079, Loss: 1.5768
Epoch 080, Loss: 1.4113
Epoch 081, Loss: 1.4746
Epoch 082, Loss: 1.3778
Epoch 083, Loss: 1.4133
Epoch 084, Loss: 1.5494
Epoch 085, Loss: 1.5359
Epoch 086, Loss: 1.4436
Epoch 087, Loss: 1.4726
Epoch 088, Loss: 1.4697
Epoch 089, Loss: 1.3975
Epoch 090, Loss: 1.4453
Epoch 091, Loss: 1.2867
Epoch 092, Loss: 1.3957
Epoch 093, Loss: 1.4586
Epoch 094, Loss: 1.3206
Epoch 095, Loss: 1.4891
Epoch 096, Loss: 1.3563
Epoch 097, Loss: 1.6016
Epoch 098, Loss: 1.5902
Epoch 099, Loss: 1.3070
Epoch 100, Loss: 1.3908

Test RMSE: 1.4619
Test MAPE: 0.2169
Training time: 16.06 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.9873
Epoch 002, Loss: 3.2313
Epoch 003, Loss: 1.8573
Epoch 004, Loss: 0.8071
Epoch 005, Loss: 0.7609
Epoch 006, Loss: 0.7786
Epoch 007, Loss: 0.7602
Epoch 008, Loss: 0.7217
Epoch 009, Loss: 0.7625
Epoch 010, Loss: 0.6797
Epoch 011, Loss: 0.6375
Epoch 012, Loss: 0.6743
Epoch 013, Loss: 0.6276
Epoch 014, Loss: 0.6560
Epoch 015, Loss: 0.6197
Epoch 016, Loss: 0.6571
Epoch 017, Loss: 0.6370
Epoch 018, Loss: 0.6917
Epoch 019, Loss: 0.6261
Epoch 020, Loss: 0.6417
Epoch 021, Loss: 0.6212
Epoch 022, Loss: 0.6187
Epoch 023, Loss: 0.5671
Epoch 024, Loss: 0.5871
Epoch 025, Loss: 0.5956
Epoch 026, Loss: 0.6865
Epoch 027, Loss: 0.6329
Epoch 028, Loss: 0.6654
Epoch 029, Loss: 0.5564
Epoch 030, Loss: 0.5548
Epoch 031, Loss: 0.6061
Epoch 032, Loss: 0.5891
Epoch 033, Loss: 0.6115
Epoch 034, Loss: 0.6228
Epoch 035, Loss: 0.5927
Epoch 036, Loss: 0.5586
Epoch 037, Loss: 0.6026
Epoch 038, Loss: 0.6023
Epoch 039, Loss: 0.5633
Epoch 040, Loss: 0.6055
Epoch 041, Loss: 0.5774
Epoch 042, Loss: 0.6844
Epoch 043, Loss: 0.6443
Epoch 044, Loss: 0.5864
Epoch 045, Loss: 0.5780
Epoch 046, Loss: 0.5814
Epoch 047, Loss: 0.6248
Epoch 048, Loss: 0.5876
Epoch 049, Loss: 0.5441
Epoch 050, Loss: 0.5850
Epoch 051, Loss: 0.5573
Epoch 052, Loss: 0.5545
Epoch 053, Loss: 0.5831
Epoch 054, Loss: 0.5642
Epoch 055, Loss: 0.5248
Epoch 056, Loss: 0.5795
Epoch 057, Loss: 0.6208
Epoch 058, Loss: 0.6362
Epoch 059, Loss: 0.5409
Epoch 060, Loss: 0.5637
Epoch 061, Loss: 0.5618
Epoch 062, Loss: 0.5460
Epoch 063, Loss: 0.5472
Epoch 064, Loss: 0.5123
Epoch 065, Loss: 0.5484
Epoch 066, Loss: 0.5919
Epoch 067, Loss: 0.5511
Epoch 068, Loss: 0.5571
Epoch 069, Loss: 0.5355
Epoch 070, Loss: 0.6038
Epoch 071, Loss: 0.5427
Epoch 072, Loss: 0.5374
Epoch 073, Loss: 0.5905
Epoch 074, Loss: 0.6114
Epoch 075, Loss: 0.5443
Epoch 076, Loss: 0.5300
Epoch 077, Loss: 0.5251
Epoch 078, Loss: 0.5364
Epoch 079, Loss: 0.5252
Epoch 080, Loss: 0.5082
Epoch 081, Loss: 0.5367
Epoch 082, Loss: 0.4960
Epoch 083, Loss: 0.5072
Epoch 084, Loss: 0.5543
Epoch 085, Loss: 0.5167
Epoch 086, Loss: 0.5256
Epoch 087, Loss: 0.5124
Epoch 088, Loss: 0.5733
Epoch 089, Loss: 0.5513
Epoch 090, Loss: 0.5060
Epoch 091, Loss: 0.4948
Epoch 092, Loss: 0.5395
Epoch 093, Loss: 0.4984
Epoch 094, Loss: 0.4885
Epoch 095, Loss: 0.5404
Epoch 096, Loss: 0.6030
Epoch 097, Loss: 0.5016
Epoch 098, Loss: 0.5100
Epoch 099, Loss: 0.5667
Epoch 100, Loss: 0.4948

Test RMSE: 0.6572
Test MAPE: 336147125370880.0000
Training time: 78.48 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.596239 2.080464e-01      15.016279   GNN_model_10.pkl
       12   Q_values        0.2 0.664419 1.964345e-01      15.050428   GNN_model_12.pkl
       15   Q_values        0.2 0.771218 2.091546e-01      15.205080   GNN_model_15.pkl
       20   Q_values        0.2 1.023729 2.251836e-01      15.763740   GNN_model_20.pkl
       25   Q_values        0.2 1.461936 2.169469e-01      16.061266   GNN_model_25.pkl
     full   Q_values        0.2 0.657237 3.361471e+14      78.482019 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
