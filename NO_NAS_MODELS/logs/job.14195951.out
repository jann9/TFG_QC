
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59807
 Mean Absolute Percentage Error: 0.25567
 Training time:  0.12686
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55314
 Mean Absolute Percentage Error: 0.39748
 Training time:  0.07423
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71568
 Mean Absolute Percentage Error: 0.57758
 Training time:  0.12901
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86312
 Mean Absolute Percentage Error: 0.53976
 Training time:  0.03912
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70417
 Mean Absolute Percentage Error: 0.30237
 Training time:  0.07267
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52152
 Mean Absolute Percentage Error: 0.17657
 Training time:  0.10028
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60359
 Mean Absolute Percentage Error: 0.22681
 Training time:  0.10559
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61145
 Mean Absolute Percentage Error: 0.25929
 Training time:  0.10698
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54130
 Mean Absolute Percentage Error: 0.18005
 Training time:  0.15891
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67575
 Mean Absolute Percentage Error: 0.21881
 Training time:  0.03590
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61776
 Mean Absolute Percentage Error: 0.24080
 Training time:  0.18382
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65553
 Mean Absolute Percentage Error: 0.29663
 Training time:  0.05037
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60296
  MAPE on 10 nodes subset: 0.26912

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71086
  MAPE on 12 nodes subset: 0.56953

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68627
  MAPE on 15 nodes subset: 0.29151

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58595
  MAPE on 20 nodes subset: 0.23088

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53403
  MAPE on 25 nodes subset: 0.18700

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.598069 0.255671       0.126863       True             4                       MLP_model_10.pkl       31
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553139 0.397477       0.074231       True             4               MLP_model_10_Circuit.pkl       31
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715676 0.577580       0.129013       True             4                       MLP_model_12.pkl       31
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863124 0.539758       0.039124       True             4               MLP_model_12_Circuit.pkl       31
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704171 0.302367       0.072674       True             4                       MLP_model_15.pkl       31
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521524 0.176570       0.100278       True             4               MLP_model_15_Circuit.pkl       31
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.603589 0.226810       0.105586       True             4                       MLP_model_20.pkl       31
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611453 0.259290       0.106976       True             4               MLP_model_20_Circuit.pkl       31
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.541303 0.180054       0.158913       True             4                       MLP_model_25.pkl       31
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.675747 0.218814       0.035903       True             4               MLP_model_25_Circuit.pkl       31
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617765 0.240796       0.183824       True             4                     MLP_model_full.pkl       31
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.655533 0.296627       0.050373       True             4             MLP_model_full_Circuit.pkl       31
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602955 0.269120       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       31
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710858 0.569529       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       31
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686273 0.291505       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       31
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585945 0.230877       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       31
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534027 0.187001       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       31

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61654
 Mean Absolute Percentage Error: 0.42855
 Training time:  0.41159
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76252
 Mean Absolute Percentage Error: 0.40108
 Training time:  0.24240
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98408
 Mean Absolute Percentage Error: 0.66438
 Training time:  0.36444
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10997
 Mean Absolute Percentage Error: 0.66527
 Training time:  0.24780
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.61123
 Mean Absolute Percentage Error: 0.19064
 Training time:  0.44507
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79918
 Mean Absolute Percentage Error: 0.23460
 Training time:  0.24456
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.63472
 Mean Absolute Percentage Error: 0.26204
 Training time:  0.63167
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85323
 Mean Absolute Percentage Error: 0.33087
 Training time:  0.23944
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.75401
 Mean Absolute Percentage Error: 0.22986
 Training time:  0.69875
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69701
 Mean Absolute Percentage Error: 0.18389
 Training time:  0.23964
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.70260
 Mean Absolute Percentage Error: 0.30068
 Training time:  2.92956
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75033
 Mean Absolute Percentage Error: 0.29940
 Training time:  0.30158
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22207
  MAPE on 10 nodes subset: 0.02555

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.35779
  MAPE on 12 nodes subset: 0.26849

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13579
  MAPE on 15 nodes subset: 0.01559

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40019
  MAPE on 20 nodes subset: 0.09148

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.21636
  MAPE on 25 nodes subset: 0.02855

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.616537 0.428550       0.411594                           xgboost_model_10.pkl       92
       10             Circuit            50           5          4 0.762520 0.401079       0.242399                   xgboost_model_10_Circuit.pkl       92
       12            Q_values            50          78          4 0.984081 0.664378       0.364436                           xgboost_model_12.pkl       92
       12             Circuit            50           5          4 1.109965 0.665275       0.247797                   xgboost_model_12_Circuit.pkl       92
       15            Q_values            50         120          4 0.611234 0.190638       0.445066                           xgboost_model_15.pkl       92
       15             Circuit            50           5          4 0.799181 0.234599       0.244564                   xgboost_model_15_Circuit.pkl       92
       20            Q_values            50         210          4 0.634718 0.262040       0.631667                           xgboost_model_20.pkl       92
       20             Circuit            50           5          4 0.853233 0.330868       0.239436                   xgboost_model_20_Circuit.pkl       92
       25            Q_values            50         325          4 0.754007 0.229863       0.698752                           xgboost_model_25.pkl       92
       25             Circuit            50           5          4 0.697008 0.183888       0.239644                   xgboost_model_25_Circuit.pkl       92
     full            Q_values           250         325          4 0.702598 0.300680       2.929557                         xgboost_model_full.pkl       92
     full             Circuit           250           5          4 0.750330 0.299397       0.301582                 xgboost_model_full_Circuit.pkl       92
       10 Q_values_full_model            50         325          4 0.222074 0.025546       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       92
       12 Q_values_full_model            50         325          4 0.357792 0.268486       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       92
       15 Q_values_full_model            50         325          4 0.135788 0.015591       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       92
       20 Q_values_full_model            50         325          4 0.400189 0.091480       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       92
       25 Q_values_full_model            50         325          4 0.216361 0.028546       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       92

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 3.3276
Epoch 002, Loss: 0.6290
Epoch 003, Loss: 0.5654
Epoch 004, Loss: 0.5983
Epoch 005, Loss: 0.5718
Epoch 006, Loss: 0.5580
Epoch 007, Loss: 0.5820
Epoch 008, Loss: 0.5564
Epoch 009, Loss: 0.5697
Epoch 010, Loss: 0.5454
Epoch 011, Loss: 0.5989
Epoch 012, Loss: 0.5814
Epoch 013, Loss: 0.5562
Epoch 014, Loss: 0.5898
Epoch 015, Loss: 0.5895
Epoch 016, Loss: 0.5493
Epoch 017, Loss: 0.5752
Epoch 018, Loss: 0.5637
Epoch 019, Loss: 0.5557
Epoch 020, Loss: 0.5376
Epoch 021, Loss: 0.5374
Epoch 022, Loss: 0.5303
Epoch 023, Loss: 0.5381
Epoch 024, Loss: 0.5690
Epoch 025, Loss: 0.5701
Epoch 026, Loss: 0.5571
Epoch 027, Loss: 0.5618
Epoch 028, Loss: 0.5221
Epoch 029, Loss: 0.5432
Epoch 030, Loss: 0.5793
Epoch 031, Loss: 0.6029
Epoch 032, Loss: 0.5685
Epoch 033, Loss: 0.5605
Epoch 034, Loss: 0.6152
Epoch 035, Loss: 0.5383
Epoch 036, Loss: 0.5879
Epoch 037, Loss: 0.6579
Epoch 038, Loss: 0.5708
Epoch 039, Loss: 0.5498
Epoch 040, Loss: 0.5422
Epoch 041, Loss: 0.5439
Epoch 042, Loss: 0.5749
Epoch 043, Loss: 0.5271
Epoch 044, Loss: 0.5476
Epoch 045, Loss: 0.5425
Epoch 046, Loss: 0.5905
Epoch 047, Loss: 0.5465
Epoch 048, Loss: 0.5321
Epoch 049, Loss: 0.5280
Epoch 050, Loss: 0.5800
Epoch 051, Loss: 0.5189
Epoch 052, Loss: 0.5209
Epoch 053, Loss: 0.5059
Epoch 054, Loss: 0.5155
Epoch 055, Loss: 0.5013
Epoch 056, Loss: 0.5033
Epoch 057, Loss: 0.5321
Epoch 058, Loss: 0.5297
Epoch 059, Loss: 0.5331
Epoch 060, Loss: 0.5282
Epoch 061, Loss: 0.5181
Epoch 062, Loss: 0.5262
Epoch 063, Loss: 0.5343
Epoch 064, Loss: 0.5427
Epoch 065, Loss: 0.5531
Epoch 066, Loss: 0.5288
Epoch 067, Loss: 0.5099
Epoch 068, Loss: 0.5102
Epoch 069, Loss: 0.5311
Epoch 070, Loss: 0.4939
Epoch 071, Loss: 0.4841
Epoch 072, Loss: 0.4943
Epoch 073, Loss: 0.4966
Epoch 074, Loss: 0.5107
Epoch 075, Loss: 0.4708
Epoch 076, Loss: 0.5063
Epoch 077, Loss: 0.4848
Epoch 078, Loss: 0.4831
Epoch 079, Loss: 0.4806
Epoch 080, Loss: 0.4753
Epoch 081, Loss: 0.5116
Epoch 082, Loss: 0.5120
Epoch 083, Loss: 0.4756
Epoch 084, Loss: 0.4787
Epoch 085, Loss: 0.4789
Epoch 086, Loss: 0.4846
Epoch 087, Loss: 0.4724
Epoch 088, Loss: 0.4594
Epoch 089, Loss: 0.4771
Epoch 090, Loss: 0.4674
Epoch 091, Loss: 0.4509
Epoch 092, Loss: 0.4636
Epoch 093, Loss: 0.4891
Epoch 094, Loss: 0.4409
Epoch 095, Loss: 0.4668
Epoch 096, Loss: 0.4691
Epoch 097, Loss: 0.4442
Epoch 098, Loss: 0.4464
Epoch 099, Loss: 0.4594
Epoch 100, Loss: 0.4892

Test RMSE: 0.6448
Test MAPE: 0.2454
Training time: 12.11 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.8666
Epoch 002, Loss: 0.9208
Epoch 003, Loss: 0.8473
Epoch 004, Loss: 0.8807
Epoch 005, Loss: 1.0543
Epoch 006, Loss: 0.8710
Epoch 007, Loss: 0.8457
Epoch 008, Loss: 0.9346
Epoch 009, Loss: 0.8252
Epoch 010, Loss: 0.8648
Epoch 011, Loss: 0.8458
Epoch 012, Loss: 0.8365
Epoch 013, Loss: 0.8116
Epoch 014, Loss: 0.8881
Epoch 015, Loss: 0.8861
Epoch 016, Loss: 0.8594
Epoch 017, Loss: 0.9149
Epoch 018, Loss: 0.9322
Epoch 019, Loss: 0.8987
Epoch 020, Loss: 0.8392
Epoch 021, Loss: 0.8431
Epoch 022, Loss: 0.8789
Epoch 023, Loss: 0.8360
Epoch 024, Loss: 0.9095
Epoch 025, Loss: 0.8308
Epoch 026, Loss: 0.8418
Epoch 027, Loss: 0.8481
Epoch 028, Loss: 0.7919
Epoch 029, Loss: 0.8131
Epoch 030, Loss: 0.8455
Epoch 031, Loss: 0.8814
Epoch 032, Loss: 0.8365
Epoch 033, Loss: 0.9143
Epoch 034, Loss: 0.8192
Epoch 035, Loss: 0.7984
Epoch 036, Loss: 0.8333
Epoch 037, Loss: 0.7971
Epoch 038, Loss: 0.7992
Epoch 039, Loss: 0.8480
Epoch 040, Loss: 0.8064
Epoch 041, Loss: 0.8310
Epoch 042, Loss: 0.8599
Epoch 043, Loss: 0.8078
Epoch 044, Loss: 0.8088
Epoch 045, Loss: 0.7926
Epoch 046, Loss: 0.7981
Epoch 047, Loss: 0.7864
Epoch 048, Loss: 0.7961
Epoch 049, Loss: 0.8298
Epoch 050, Loss: 0.7965
Epoch 051, Loss: 0.7662
Epoch 052, Loss: 0.7806
Epoch 053, Loss: 0.7681
Epoch 054, Loss: 0.7658
Epoch 055, Loss: 0.7412
Epoch 056, Loss: 0.7405
Epoch 057, Loss: 0.8261
Epoch 058, Loss: 0.7453
Epoch 059, Loss: 0.8155
Epoch 060, Loss: 0.7730
Epoch 061, Loss: 0.7567
Epoch 062, Loss: 0.7738
Epoch 063, Loss: 0.7161
Epoch 064, Loss: 0.7181
Epoch 065, Loss: 0.7526
Epoch 066, Loss: 0.7768
Epoch 067, Loss: 0.7118
Epoch 068, Loss: 0.7211
Epoch 069, Loss: 0.6915
Epoch 070, Loss: 0.6853
Epoch 071, Loss: 0.6971
Epoch 072, Loss: 0.6611
Epoch 073, Loss: 0.7127
Epoch 074, Loss: 0.6706
Epoch 075, Loss: 0.6653
Epoch 076, Loss: 0.6306
Epoch 077, Loss: 0.6897
Epoch 078, Loss: 0.6369
Epoch 079, Loss: 0.6721
Epoch 080, Loss: 0.6705
Epoch 081, Loss: 0.6334
Epoch 082, Loss: 0.6024
Epoch 083, Loss: 0.6229
Epoch 084, Loss: 0.5857
Epoch 085, Loss: 0.6252
Epoch 086, Loss: 0.6014
Epoch 087, Loss: 0.5713
Epoch 088, Loss: 0.5792
Epoch 089, Loss: 0.6328
Epoch 090, Loss: 0.6073
Epoch 091, Loss: 0.6038
Epoch 092, Loss: 0.5877
Epoch 093, Loss: 0.5820
Epoch 094, Loss: 0.5865
Epoch 095, Loss: 0.5908
Epoch 096, Loss: 0.5798
Epoch 097, Loss: 0.6695
Epoch 098, Loss: 0.5884
Epoch 099, Loss: 0.5544
Epoch 100, Loss: 0.5714

Test RMSE: 0.6424
Test MAPE: 0.2000
Training time: 11.96 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.4100
Epoch 002, Loss: 1.0994
Epoch 003, Loss: 0.9858
Epoch 004, Loss: 0.9090
Epoch 005, Loss: 0.9964
Epoch 006, Loss: 0.9451
Epoch 007, Loss: 0.9374
Epoch 008, Loss: 1.0339
Epoch 009, Loss: 0.9645
Epoch 010, Loss: 0.9204
Epoch 011, Loss: 1.0158
Epoch 012, Loss: 1.0098
Epoch 013, Loss: 0.9503
Epoch 014, Loss: 1.0885
Epoch 015, Loss: 0.8791
Epoch 016, Loss: 0.9402
Epoch 017, Loss: 1.0596
Epoch 018, Loss: 0.9068
Epoch 019, Loss: 0.9160
Epoch 020, Loss: 0.9421
Epoch 021, Loss: 0.9368
Epoch 022, Loss: 0.8919
Epoch 023, Loss: 0.9131
Epoch 024, Loss: 0.9928
Epoch 025, Loss: 0.9115
Epoch 026, Loss: 0.9870
Epoch 027, Loss: 0.9281
Epoch 028, Loss: 0.8606
Epoch 029, Loss: 0.9982
Epoch 030, Loss: 0.9380
Epoch 031, Loss: 0.9153
Epoch 032, Loss: 0.8936
Epoch 033, Loss: 0.8883
Epoch 034, Loss: 1.0004
Epoch 035, Loss: 0.8816
Epoch 036, Loss: 0.8399
Epoch 037, Loss: 0.8827
Epoch 038, Loss: 0.8573
Epoch 039, Loss: 0.9263
Epoch 040, Loss: 0.9334
Epoch 041, Loss: 0.8788
Epoch 042, Loss: 0.8488
Epoch 043, Loss: 0.8464
Epoch 044, Loss: 0.8730
Epoch 045, Loss: 0.8915
Epoch 046, Loss: 0.8961
Epoch 047, Loss: 0.8307
Epoch 048, Loss: 0.8214
Epoch 049, Loss: 0.7948
Epoch 050, Loss: 0.8253
Epoch 051, Loss: 0.8938
Epoch 052, Loss: 0.7879
Epoch 053, Loss: 0.8474
Epoch 054, Loss: 0.8704
Epoch 055, Loss: 0.8336
Epoch 056, Loss: 0.8154
Epoch 057, Loss: 0.7361
Epoch 058, Loss: 0.7605
Epoch 059, Loss: 0.7261
Epoch 060, Loss: 0.7363
Epoch 061, Loss: 0.7339
Epoch 062, Loss: 0.6775
Epoch 063, Loss: 0.6623
Epoch 064, Loss: 0.6596
Epoch 065, Loss: 0.7432
Epoch 066, Loss: 0.6582
Epoch 067, Loss: 0.6665
Epoch 068, Loss: 0.6608
Epoch 069, Loss: 0.7234
Epoch 070, Loss: 0.6080
Epoch 071, Loss: 0.6201
Epoch 072, Loss: 0.6081
Epoch 073, Loss: 0.6298
Epoch 074, Loss: 0.6462
Epoch 075, Loss: 0.7009
Epoch 076, Loss: 0.6042
Epoch 077, Loss: 0.6346
Epoch 078, Loss: 0.6543
Epoch 079, Loss: 0.6027
Epoch 080, Loss: 0.5450
Epoch 081, Loss: 0.6188
Epoch 082, Loss: 0.5978
Epoch 083, Loss: 0.6120
Epoch 084, Loss: 0.6235
Epoch 085, Loss: 0.6137
Epoch 086, Loss: 0.6217
Epoch 087, Loss: 0.5852
Epoch 088, Loss: 0.5812
Epoch 089, Loss: 0.5792
Epoch 090, Loss: 0.5394
Epoch 091, Loss: 0.5718
Epoch 092, Loss: 0.5712
Epoch 093, Loss: 0.5320
Epoch 094, Loss: 0.5736
Epoch 095, Loss: 0.5576
Epoch 096, Loss: 0.5466
Epoch 097, Loss: 0.5155
Epoch 098, Loss: 0.5657
Epoch 099, Loss: 0.6102
Epoch 100, Loss: 0.5853

Test RMSE: 0.8857
Test MAPE: 0.1894
Training time: 12.11 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.6700
Epoch 002, Loss: 1.2243
Epoch 003, Loss: 1.4400
Epoch 004, Loss: 1.3372
Epoch 005, Loss: 1.2339
Epoch 006, Loss: 1.4305
Epoch 007, Loss: 1.3729
Epoch 008, Loss: 1.2720
Epoch 009, Loss: 1.2736
Epoch 010, Loss: 1.5269
Epoch 011, Loss: 1.2737
Epoch 012, Loss: 1.2781
Epoch 013, Loss: 1.2374
Epoch 014, Loss: 1.2566
Epoch 015, Loss: 1.2735
Epoch 016, Loss: 1.1724
Epoch 017, Loss: 1.1273
Epoch 018, Loss: 1.2946
Epoch 019, Loss: 1.1664
Epoch 020, Loss: 1.1736
Epoch 021, Loss: 1.0969
Epoch 022, Loss: 1.1763
Epoch 023, Loss: 1.2436
Epoch 024, Loss: 1.3155
Epoch 025, Loss: 1.0530
Epoch 026, Loss: 1.0792
Epoch 027, Loss: 1.1088
Epoch 028, Loss: 1.0650
Epoch 029, Loss: 0.9802
Epoch 030, Loss: 0.9556
Epoch 031, Loss: 0.9600
Epoch 032, Loss: 1.0318
Epoch 033, Loss: 0.8042
Epoch 034, Loss: 0.9443
Epoch 035, Loss: 0.9867
Epoch 036, Loss: 0.8265
Epoch 037, Loss: 0.8746
Epoch 038, Loss: 0.8852
Epoch 039, Loss: 0.8856
Epoch 040, Loss: 0.8999
Epoch 041, Loss: 0.7964
Epoch 042, Loss: 0.7944
Epoch 043, Loss: 0.7477
Epoch 044, Loss: 0.7711
Epoch 045, Loss: 0.7368
Epoch 046, Loss: 0.7733
Epoch 047, Loss: 0.8371
Epoch 048, Loss: 0.9097
Epoch 049, Loss: 0.7531
Epoch 050, Loss: 0.8502
Epoch 051, Loss: 0.7137
Epoch 052, Loss: 0.6657
Epoch 053, Loss: 0.6339
Epoch 054, Loss: 0.7622
Epoch 055, Loss: 0.6893
Epoch 056, Loss: 0.6799
Epoch 057, Loss: 0.6754
Epoch 058, Loss: 0.6299
Epoch 059, Loss: 0.6252
Epoch 060, Loss: 0.6730
Epoch 061, Loss: 0.8031
Epoch 062, Loss: 0.6830
Epoch 063, Loss: 0.6497
Epoch 064, Loss: 0.7066
Epoch 065, Loss: 0.7700
Epoch 066, Loss: 0.6550
Epoch 067, Loss: 0.6187
Epoch 068, Loss: 0.6664
Epoch 069, Loss: 0.6673
Epoch 070, Loss: 0.6423
Epoch 071, Loss: 0.6113
Epoch 072, Loss: 0.6147
Epoch 073, Loss: 0.6090
Epoch 074, Loss: 0.5798
Epoch 075, Loss: 0.5983
Epoch 076, Loss: 0.6258
Epoch 077, Loss: 0.6016
Epoch 078, Loss: 0.6554
Epoch 079, Loss: 0.7466
Epoch 080, Loss: 0.5740
Epoch 081, Loss: 0.5831
Epoch 082, Loss: 0.6052
Epoch 083, Loss: 0.6737
Epoch 084, Loss: 0.5962
Epoch 085, Loss: 0.5915
Epoch 086, Loss: 0.6277
Epoch 087, Loss: 0.5712
Epoch 088, Loss: 0.5524
Epoch 089, Loss: 0.5719
Epoch 090, Loss: 0.5847
Epoch 091, Loss: 0.5441
Epoch 092, Loss: 0.6595
Epoch 093, Loss: 0.5789
Epoch 094, Loss: 0.5697
Epoch 095, Loss: 0.6469
Epoch 096, Loss: 0.5367
Epoch 097, Loss: 0.5431
Epoch 098, Loss: 0.5692
Epoch 099, Loss: 0.5517
Epoch 100, Loss: 0.5186

Test RMSE: 0.9264
Test MAPE: 0.2446
Training time: 12.60 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 13.3271
Epoch 002, Loss: 1.5920
Epoch 003, Loss: 1.5590
Epoch 004, Loss: 1.5941
Epoch 005, Loss: 1.7517
Epoch 006, Loss: 1.5416
Epoch 007, Loss: 1.7275
Epoch 008, Loss: 1.7695
Epoch 009, Loss: 1.5118
Epoch 010, Loss: 2.0661
Epoch 011, Loss: 1.9076
Epoch 012, Loss: 1.6722
Epoch 013, Loss: 1.7064
Epoch 014, Loss: 1.4768
Epoch 015, Loss: 1.6232
Epoch 016, Loss: 1.5917
Epoch 017, Loss: 1.5589
Epoch 018, Loss: 1.6167
Epoch 019, Loss: 1.4389
Epoch 020, Loss: 1.7201
Epoch 021, Loss: 1.7762
Epoch 022, Loss: 1.6188
Epoch 023, Loss: 1.4611
Epoch 024, Loss: 1.6219
Epoch 025, Loss: 1.6497
Epoch 026, Loss: 1.6792
Epoch 027, Loss: 1.4495
Epoch 028, Loss: 1.7286
Epoch 029, Loss: 1.5165
Epoch 030, Loss: 1.4264
Epoch 031, Loss: 1.5633
Epoch 032, Loss: 1.5191
Epoch 033, Loss: 1.6057
Epoch 034, Loss: 1.5193
Epoch 035, Loss: 1.4938
Epoch 036, Loss: 1.5350
Epoch 037, Loss: 1.5447
Epoch 038, Loss: 1.4577
Epoch 039, Loss: 1.6002
Epoch 040, Loss: 1.5862
Epoch 041, Loss: 1.4399
Epoch 042, Loss: 1.5842
Epoch 043, Loss: 1.5833
Epoch 044, Loss: 1.5203
Epoch 045, Loss: 1.5692
Epoch 046, Loss: 1.4544
Epoch 047, Loss: 1.4292
Epoch 048, Loss: 1.6721
Epoch 049, Loss: 1.4778
Epoch 050, Loss: 1.5684
Epoch 051, Loss: 1.7634
Epoch 052, Loss: 1.6230
Epoch 053, Loss: 1.4794
Epoch 054, Loss: 1.6509
Epoch 055, Loss: 1.5396
Epoch 056, Loss: 1.3910
Epoch 057, Loss: 1.4330
Epoch 058, Loss: 1.4427
Epoch 059, Loss: 1.4619
Epoch 060, Loss: 1.5693
Epoch 061, Loss: 1.4654
Epoch 062, Loss: 1.6850
Epoch 063, Loss: 1.5869
Epoch 064, Loss: 1.4288
Epoch 065, Loss: 1.6088
Epoch 066, Loss: 1.7164
Epoch 067, Loss: 1.4960
Epoch 068, Loss: 1.4466
Epoch 069, Loss: 1.4246
Epoch 070, Loss: 1.4534
Epoch 071, Loss: 1.5000
Epoch 072, Loss: 1.4609
Epoch 073, Loss: 1.4515
Epoch 074, Loss: 1.4933
Epoch 075, Loss: 1.4258
Epoch 076, Loss: 1.5408
Epoch 077, Loss: 1.4508
Epoch 078, Loss: 1.4774
Epoch 079, Loss: 1.3501
Epoch 080, Loss: 1.4805
Epoch 081, Loss: 1.4284
Epoch 082, Loss: 1.4802
Epoch 083, Loss: 1.4751
Epoch 084, Loss: 1.4727
Epoch 085, Loss: 1.4914
Epoch 086, Loss: 1.5089
Epoch 087, Loss: 1.4421
Epoch 088, Loss: 1.4557
Epoch 089, Loss: 1.7374
Epoch 090, Loss: 1.4912
Epoch 091, Loss: 1.4392
Epoch 092, Loss: 1.4698
Epoch 093, Loss: 1.5498
Epoch 094, Loss: 1.4398
Epoch 095, Loss: 1.3690
Epoch 096, Loss: 1.5984
Epoch 097, Loss: 1.6815
Epoch 098, Loss: 1.5393
Epoch 099, Loss: 1.3239
Epoch 100, Loss: 1.5325

Test RMSE: 1.6668
Test MAPE: 0.2724
Training time: 12.89 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.6997
Epoch 002, Loss: 3.3143
Epoch 003, Loss: 3.2034
Epoch 004, Loss: 2.5652
Epoch 005, Loss: 1.2731
Epoch 006, Loss: 0.9174
Epoch 007, Loss: 0.8491
Epoch 008, Loss: 0.8589
Epoch 009, Loss: 0.8704
Epoch 010, Loss: 0.6547
Epoch 011, Loss: 0.7047
Epoch 012, Loss: 0.6798
Epoch 013, Loss: 0.7064
Epoch 014, Loss: 0.7155
Epoch 015, Loss: 0.7619
Epoch 016, Loss: 0.6694
Epoch 017, Loss: 0.6571
Epoch 018, Loss: 0.6265
Epoch 019, Loss: 0.6682
Epoch 020, Loss: 0.6108
Epoch 021, Loss: 0.5880
Epoch 022, Loss: 0.6399
Epoch 023, Loss: 0.6892
Epoch 024, Loss: 0.6912
Epoch 025, Loss: 0.6150
Epoch 026, Loss: 0.6514
Epoch 027, Loss: 0.6066
Epoch 028, Loss: 0.5978
Epoch 029, Loss: 0.5942
Epoch 030, Loss: 0.5526
Epoch 031, Loss: 0.5757
Epoch 032, Loss: 0.5593
Epoch 033, Loss: 0.6082
Epoch 034, Loss: 0.5601
Epoch 035, Loss: 0.5737
Epoch 036, Loss: 0.6266
Epoch 037, Loss: 0.5929
Epoch 038, Loss: 0.5905
Epoch 039, Loss: 0.6047
Epoch 040, Loss: 0.5642
Epoch 041, Loss: 0.5715
Epoch 042, Loss: 0.6202
Epoch 043, Loss: 0.5999
Epoch 044, Loss: 0.5582
Epoch 045, Loss: 0.5831
Epoch 046, Loss: 0.5185
Epoch 047, Loss: 0.5383
Epoch 048, Loss: 0.5948
Epoch 049, Loss: 0.5403
Epoch 050, Loss: 0.6011
Epoch 051, Loss: 0.5751
Epoch 052, Loss: 0.6251
Epoch 053, Loss: 0.5802
Epoch 054, Loss: 0.5981
Epoch 055, Loss: 0.6331
Epoch 056, Loss: 0.4926
Epoch 057, Loss: 0.6016
Epoch 058, Loss: 0.5923
Epoch 059, Loss: 0.5162
Epoch 060, Loss: 0.5147
Epoch 061, Loss: 0.5502
Epoch 062, Loss: 0.5126
Epoch 063, Loss: 0.5015
Epoch 064, Loss: 0.5539
Epoch 065, Loss: 0.5394
Epoch 066, Loss: 0.5417
Epoch 067, Loss: 0.4943
Epoch 068, Loss: 0.5504
Epoch 069, Loss: 0.5251
Epoch 070, Loss: 0.5390
Epoch 071, Loss: 0.5477
Epoch 072, Loss: 0.5040
Epoch 073, Loss: 0.5099
Epoch 074, Loss: 0.5273
Epoch 075, Loss: 0.6003
Epoch 076, Loss: 0.5717
Epoch 077, Loss: 0.5525
Epoch 078, Loss: 0.5001
Epoch 079, Loss: 0.5515
Epoch 080, Loss: 0.4998
Epoch 081, Loss: 0.5385
Epoch 082, Loss: 0.5062
Epoch 083, Loss: 0.5706
Epoch 084, Loss: 0.4920
Epoch 085, Loss: 0.5225
Epoch 086, Loss: 0.5072
Epoch 087, Loss: 0.4828
Epoch 088, Loss: 0.4902
Epoch 089, Loss: 0.4820
Epoch 090, Loss: 0.5013
Epoch 091, Loss: 0.4761
Epoch 092, Loss: 0.5045
Epoch 093, Loss: 0.4769
Epoch 094, Loss: 0.5984
Epoch 095, Loss: 0.4952
Epoch 096, Loss: 0.5312
Epoch 097, Loss: 0.5451
Epoch 098, Loss: 0.5361
Epoch 099, Loss: 0.5132
Epoch 100, Loss: 0.4763

Test RMSE: 0.7603
Test MAPE: 126361444286464.0000
Training time: 62.51 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.644849 2.454356e-01      12.109118   GNN_model_10.pkl
       12   Q_values        0.2 0.642442 1.999681e-01      11.957008   GNN_model_12.pkl
       15   Q_values        0.2 0.885662 1.894101e-01      12.109531   GNN_model_15.pkl
       20   Q_values        0.2 0.926353 2.445830e-01      12.597062   GNN_model_20.pkl
       25   Q_values        0.2 1.666770 2.723871e-01      12.891293   GNN_model_25.pkl
     full   Q_values        0.2 0.760298 1.263614e+14      62.514355 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
