
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59015
 Mean Absolute Percentage Error: 0.24511
 Training time:  0.03098
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55305
 Mean Absolute Percentage Error: 0.39815
 Training time:  0.01749
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71830
 Mean Absolute Percentage Error: 0.57140
 Training time:  0.05810
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86321
 Mean Absolute Percentage Error: 0.53988
 Training time:  0.01667
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70503
 Mean Absolute Percentage Error: 0.30270
 Training time:  0.03405
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52200
 Mean Absolute Percentage Error: 0.17705
 Training time:  0.01650
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60486
 Mean Absolute Percentage Error: 0.22789
 Training time:  0.07926
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61155
 Mean Absolute Percentage Error: 0.25969
 Training time:  0.01643
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53793
 Mean Absolute Percentage Error: 0.17646
 Training time:  0.14819
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67485
 Mean Absolute Percentage Error: 0.21885
 Training time:  0.03292
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61738
 Mean Absolute Percentage Error: 0.23816
 Training time:  0.18500
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65488
 Mean Absolute Percentage Error: 0.29679
 Training time:  0.04739
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60171
  MAPE on 10 nodes subset: 0.26690

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71112
  MAPE on 12 nodes subset: 0.56742

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68547
  MAPE on 15 nodes subset: 0.28911

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58491
  MAPE on 20 nodes subset: 0.22590

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52960
  MAPE on 25 nodes subset: 0.18378

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.590146 0.245107       0.030983       True             3                       MLP_model_10.pkl       11
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553055 0.398152       0.017487       True             4               MLP_model_10_Circuit.pkl       11
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.718299 0.571396       0.058097       True             3                       MLP_model_12.pkl       11
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863207 0.539885       0.016668       True             4               MLP_model_12_Circuit.pkl       11
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705033 0.302702       0.034046       True             4                       MLP_model_15.pkl       11
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522000 0.177053       0.016501       True             4               MLP_model_15_Circuit.pkl       11
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604855 0.227891       0.079261       True             4                       MLP_model_20.pkl       11
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611545 0.259686       0.016426       True             4               MLP_model_20_Circuit.pkl       11
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.537928 0.176458       0.148195       True             4                       MLP_model_25.pkl       11
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674854 0.218852       0.032916       True             4               MLP_model_25_Circuit.pkl       11
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617379 0.238156       0.184999       True             4                     MLP_model_full.pkl       11
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654883 0.296787       0.047387       True             4             MLP_model_full_Circuit.pkl       11
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601711 0.266901       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.711125 0.567416       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.685473 0.289108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.584908 0.225899       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.529598 0.183776       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.62163
 Mean Absolute Percentage Error: 0.44942
 Training time:  0.35357
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76159
 Mean Absolute Percentage Error: 0.39985
 Training time:  0.25040
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.01613
 Mean Absolute Percentage Error: 0.68039
 Training time:  0.36957
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10809
 Mean Absolute Percentage Error: 0.66075
 Training time:  0.26174
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62842
 Mean Absolute Percentage Error: 0.19493
 Training time:  0.46134
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80543
 Mean Absolute Percentage Error: 0.23109
 Training time:  0.25657
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.64778
 Mean Absolute Percentage Error: 0.28266
 Training time:  0.63105
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84920
 Mean Absolute Percentage Error: 0.32861
 Training time:  0.26304
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74726
 Mean Absolute Percentage Error: 0.22498
 Training time:  0.72134
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69869
 Mean Absolute Percentage Error: 0.18673
 Training time:  0.24962
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71895
 Mean Absolute Percentage Error: 0.30565
 Training time:  2.97335
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75259
 Mean Absolute Percentage Error: 0.30074
 Training time:  0.31405
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24468
  MAPE on 10 nodes subset: 0.02410

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34574
  MAPE on 12 nodes subset: 0.27766

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.14326
  MAPE on 15 nodes subset: 0.01609

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40588
  MAPE on 20 nodes subset: 0.09659

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.18373
  MAPE on 25 nodes subset: 0.02403

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.621634 0.449421       0.353574                           xgboost_model_10.pkl       28
       10             Circuit            50           5          4 0.761589 0.399852       0.250397                   xgboost_model_10_Circuit.pkl       28
       12            Q_values            50          78          4 1.016129 0.680388       0.369572                           xgboost_model_12.pkl       28
       12             Circuit            50           5          4 1.108086 0.660755       0.261735                   xgboost_model_12_Circuit.pkl       28
       15            Q_values            50         120          4 0.628422 0.194932       0.461342                           xgboost_model_15.pkl       28
       15             Circuit            50           5          4 0.805432 0.231086       0.256567                   xgboost_model_15_Circuit.pkl       28
       20            Q_values            50         210          4 0.647776 0.282661       0.631051                           xgboost_model_20.pkl       28
       20             Circuit            50           5          4 0.849200 0.328607       0.263037                   xgboost_model_20_Circuit.pkl       28
       25            Q_values            50         325          4 0.747259 0.224982       0.721339                           xgboost_model_25.pkl       28
       25             Circuit            50           5          4 0.698685 0.186735       0.249620                   xgboost_model_25_Circuit.pkl       28
     full            Q_values           250         325          4 0.718947 0.305652       2.973354                         xgboost_model_full.pkl       28
     full             Circuit           250           5          4 0.752590 0.300742       0.314052                 xgboost_model_full_Circuit.pkl       28
       10 Q_values_full_model            50         325          4 0.244683 0.024101       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       12 Q_values_full_model            50         325          4 0.345745 0.277660       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       15 Q_values_full_model            50         325          4 0.143263 0.016093       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       20 Q_values_full_model            50         325          4 0.405882 0.096586       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       25 Q_values_full_model            50         325          4 0.183734 0.024031       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.5645
Epoch 002, Loss: 0.6281
Epoch 003, Loss: 0.5705
Epoch 004, Loss: 0.5647
Epoch 005, Loss: 0.5841
Epoch 006, Loss: 0.5913
Epoch 007, Loss: 0.5360
Epoch 008, Loss: 0.5652
Epoch 009, Loss: 0.5217
Epoch 010, Loss: 0.5328
Epoch 011, Loss: 0.5876
Epoch 012, Loss: 0.5708
Epoch 013, Loss: 0.5751
Epoch 014, Loss: 0.6234
Epoch 015, Loss: 0.5953
Epoch 016, Loss: 0.6308
Epoch 017, Loss: 0.5653
Epoch 018, Loss: 0.5483
Epoch 019, Loss: 0.6002
Epoch 020, Loss: 0.6275
Epoch 021, Loss: 0.6038
Epoch 022, Loss: 0.6035
Epoch 023, Loss: 0.6013
Epoch 024, Loss: 0.6517
Epoch 025, Loss: 0.5690
Epoch 026, Loss: 0.5479
Epoch 027, Loss: 0.5578
Epoch 028, Loss: 0.5466
Epoch 029, Loss: 0.5456
Epoch 030, Loss: 0.5751
Epoch 031, Loss: 0.5498
Epoch 032, Loss: 0.6390
Epoch 033, Loss: 0.5891
Epoch 034, Loss: 0.5509
Epoch 035, Loss: 0.5302
Epoch 036, Loss: 0.5402
Epoch 037, Loss: 0.5453
Epoch 038, Loss: 0.5456
Epoch 039, Loss: 0.5477
Epoch 040, Loss: 0.5424
Epoch 041, Loss: 0.5230
Epoch 042, Loss: 0.5825
Epoch 043, Loss: 0.5682
Epoch 044, Loss: 0.5622
Epoch 045, Loss: 0.5686
Epoch 046, Loss: 0.5331
Epoch 047, Loss: 0.5452
Epoch 048, Loss: 0.5329
Epoch 049, Loss: 0.5517
Epoch 050, Loss: 0.5178
Epoch 051, Loss: 0.5151
Epoch 052, Loss: 0.5198
Epoch 053, Loss: 0.5215
Epoch 054, Loss: 0.5366
Epoch 055, Loss: 0.5028
Epoch 056, Loss: 0.5534
Epoch 057, Loss: 0.5176
Epoch 058, Loss: 0.5149
Epoch 059, Loss: 0.5034
Epoch 060, Loss: 0.5444
Epoch 061, Loss: 0.5419
Epoch 062, Loss: 0.5010
Epoch 063, Loss: 0.5167
Epoch 064, Loss: 0.4990
Epoch 065, Loss: 0.5061
Epoch 066, Loss: 0.5106
Epoch 067, Loss: 0.4977
Epoch 068, Loss: 0.5246
Epoch 069, Loss: 0.5219
Epoch 070, Loss: 0.4949
Epoch 071, Loss: 0.4903
Epoch 072, Loss: 0.5164
Epoch 073, Loss: 0.4982
Epoch 074, Loss: 0.5089
Epoch 075, Loss: 0.5058
Epoch 076, Loss: 0.4899
Epoch 077, Loss: 0.4955
Epoch 078, Loss: 0.4792
Epoch 079, Loss: 0.4788
Epoch 080, Loss: 0.5014
Epoch 081, Loss: 0.4854
Epoch 082, Loss: 0.4771
Epoch 083, Loss: 0.4740
Epoch 084, Loss: 0.4850
Epoch 085, Loss: 0.4682
Epoch 086, Loss: 0.4827
Epoch 087, Loss: 0.4906
Epoch 088, Loss: 0.4840
Epoch 089, Loss: 0.4744
Epoch 090, Loss: 0.4634
Epoch 091, Loss: 0.4588
Epoch 092, Loss: 0.4490
Epoch 093, Loss: 0.4546
Epoch 094, Loss: 0.4573
Epoch 095, Loss: 0.4439
Epoch 096, Loss: 0.4568
Epoch 097, Loss: 0.4340
Epoch 098, Loss: 0.4551
Epoch 099, Loss: 0.4504
Epoch 100, Loss: 0.4515

Test RMSE: 0.6335
Test MAPE: 0.2156
Training time: 12.16 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 4.0647
Epoch 002, Loss: 0.8891
Epoch 003, Loss: 0.8786
Epoch 004, Loss: 0.8737
Epoch 005, Loss: 0.8181
Epoch 006, Loss: 0.9456
Epoch 007, Loss: 0.8434
Epoch 008, Loss: 0.7907
Epoch 009, Loss: 0.8568
Epoch 010, Loss: 0.9076
Epoch 011, Loss: 0.7909
Epoch 012, Loss: 0.9107
Epoch 013, Loss: 0.8591
Epoch 014, Loss: 0.8128
Epoch 015, Loss: 0.8483
Epoch 016, Loss: 0.8560
Epoch 017, Loss: 0.8575
Epoch 018, Loss: 0.8137
Epoch 019, Loss: 0.8028
Epoch 020, Loss: 0.9321
Epoch 021, Loss: 0.8842
Epoch 022, Loss: 0.8013
Epoch 023, Loss: 0.8365
Epoch 024, Loss: 0.8088
Epoch 025, Loss: 0.8603
Epoch 026, Loss: 0.7875
Epoch 027, Loss: 0.8227
Epoch 028, Loss: 0.8099
Epoch 029, Loss: 0.8634
Epoch 030, Loss: 0.8243
Epoch 031, Loss: 0.8435
Epoch 032, Loss: 0.8424
Epoch 033, Loss: 0.8158
Epoch 034, Loss: 0.7855
Epoch 035, Loss: 0.7878
Epoch 036, Loss: 0.7970
Epoch 037, Loss: 0.9428
Epoch 038, Loss: 0.8368
Epoch 039, Loss: 0.7965
Epoch 040, Loss: 0.8276
Epoch 041, Loss: 0.7820
Epoch 042, Loss: 0.8371
Epoch 043, Loss: 0.7978
Epoch 044, Loss: 0.8660
Epoch 045, Loss: 0.8029
Epoch 046, Loss: 0.8051
Epoch 047, Loss: 0.8249
Epoch 048, Loss: 0.7785
Epoch 049, Loss: 0.8018
Epoch 050, Loss: 0.8911
Epoch 051, Loss: 0.8132
Epoch 052, Loss: 0.8243
Epoch 053, Loss: 0.7785
Epoch 054, Loss: 0.8140
Epoch 055, Loss: 0.8352
Epoch 056, Loss: 0.7636
Epoch 057, Loss: 0.7506
Epoch 058, Loss: 0.7604
Epoch 059, Loss: 0.7542
Epoch 060, Loss: 0.7738
Epoch 061, Loss: 0.7156
Epoch 062, Loss: 0.7573
Epoch 063, Loss: 0.7268
Epoch 064, Loss: 0.7594
Epoch 065, Loss: 0.7076
Epoch 066, Loss: 0.7478
Epoch 067, Loss: 0.7296
Epoch 068, Loss: 0.7348
Epoch 069, Loss: 0.7138
Epoch 070, Loss: 0.7135
Epoch 071, Loss: 0.7476
Epoch 072, Loss: 0.7148
Epoch 073, Loss: 0.7436
Epoch 074, Loss: 0.6612
Epoch 075, Loss: 0.6820
Epoch 076, Loss: 0.6620
Epoch 077, Loss: 0.6755
Epoch 078, Loss: 0.6462
Epoch 079, Loss: 0.6510
Epoch 080, Loss: 0.6548
Epoch 081, Loss: 0.6616
Epoch 082, Loss: 0.6520
Epoch 083, Loss: 0.6238
Epoch 084, Loss: 0.6326
Epoch 085, Loss: 0.6101
Epoch 086, Loss: 0.6424
Epoch 087, Loss: 0.6332
Epoch 088, Loss: 0.6293
Epoch 089, Loss: 0.5987
Epoch 090, Loss: 0.6337
Epoch 091, Loss: 0.6191
Epoch 092, Loss: 0.6326
Epoch 093, Loss: 0.6103
Epoch 094, Loss: 0.6257
Epoch 095, Loss: 0.6386
Epoch 096, Loss: 0.6001
Epoch 097, Loss: 0.6018
Epoch 098, Loss: 0.6806
Epoch 099, Loss: 0.6245
Epoch 100, Loss: 0.5849

Test RMSE: 0.7275
Test MAPE: 0.2460
Training time: 12.32 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.9533
Epoch 002, Loss: 1.1206
Epoch 003, Loss: 0.9269
Epoch 004, Loss: 0.9242
Epoch 005, Loss: 0.9943
Epoch 006, Loss: 0.8982
Epoch 007, Loss: 1.0678
Epoch 008, Loss: 1.0537
Epoch 009, Loss: 0.9047
Epoch 010, Loss: 0.9378
Epoch 011, Loss: 0.9227
Epoch 012, Loss: 0.8991
Epoch 013, Loss: 1.0209
Epoch 014, Loss: 0.9935
Epoch 015, Loss: 0.9923
Epoch 016, Loss: 0.8942
Epoch 017, Loss: 1.0091
Epoch 018, Loss: 0.9820
Epoch 019, Loss: 0.8999
Epoch 020, Loss: 0.9156
Epoch 021, Loss: 0.9064
Epoch 022, Loss: 0.8903
Epoch 023, Loss: 0.9162
Epoch 024, Loss: 0.9295
Epoch 025, Loss: 0.9010
Epoch 026, Loss: 0.8705
Epoch 027, Loss: 1.0666
Epoch 028, Loss: 0.9470
Epoch 029, Loss: 0.9321
Epoch 030, Loss: 0.8930
Epoch 031, Loss: 0.9370
Epoch 032, Loss: 0.8433
Epoch 033, Loss: 0.9039
Epoch 034, Loss: 0.8531
Epoch 035, Loss: 0.8777
Epoch 036, Loss: 0.8935
Epoch 037, Loss: 0.9089
Epoch 038, Loss: 0.9226
Epoch 039, Loss: 0.9343
Epoch 040, Loss: 0.8719
Epoch 041, Loss: 0.8900
Epoch 042, Loss: 0.8174
Epoch 043, Loss: 0.8857
Epoch 044, Loss: 0.8273
Epoch 045, Loss: 0.8781
Epoch 046, Loss: 0.9218
Epoch 047, Loss: 0.8317
Epoch 048, Loss: 0.8727
Epoch 049, Loss: 0.7831
Epoch 050, Loss: 0.8399
Epoch 051, Loss: 0.8011
Epoch 052, Loss: 0.7828
Epoch 053, Loss: 0.7856
Epoch 054, Loss: 0.7956
Epoch 055, Loss: 0.7602
Epoch 056, Loss: 0.8160
Epoch 057, Loss: 0.8105
Epoch 058, Loss: 0.7069
Epoch 059, Loss: 0.8235
Epoch 060, Loss: 0.7886
Epoch 061, Loss: 0.7284
Epoch 062, Loss: 0.6667
Epoch 063, Loss: 0.7300
Epoch 064, Loss: 0.7094
Epoch 065, Loss: 0.7255
Epoch 066, Loss: 0.6827
Epoch 067, Loss: 0.7006
Epoch 068, Loss: 0.6545
Epoch 069, Loss: 0.6781
Epoch 070, Loss: 0.6428
Epoch 071, Loss: 0.6059
Epoch 072, Loss: 0.6061
Epoch 073, Loss: 0.5983
Epoch 074, Loss: 0.6713
Epoch 075, Loss: 0.6066
Epoch 076, Loss: 0.5805
Epoch 077, Loss: 0.6058
Epoch 078, Loss: 0.5610
Epoch 079, Loss: 0.5261
Epoch 080, Loss: 0.6536
Epoch 081, Loss: 0.5591
Epoch 082, Loss: 0.6180
Epoch 083, Loss: 0.5880
Epoch 084, Loss: 0.6652
Epoch 085, Loss: 0.5748
Epoch 086, Loss: 0.5644
Epoch 087, Loss: 0.6257
Epoch 088, Loss: 0.5228
Epoch 089, Loss: 0.5374
Epoch 090, Loss: 0.5638
Epoch 091, Loss: 0.7079
Epoch 092, Loss: 0.5281
Epoch 093, Loss: 0.5548
Epoch 094, Loss: 0.5121
Epoch 095, Loss: 0.5794
Epoch 096, Loss: 0.5561
Epoch 097, Loss: 0.5030
Epoch 098, Loss: 0.5394
Epoch 099, Loss: 0.5030
Epoch 100, Loss: 0.5092

Test RMSE: 0.8625
Test MAPE: 0.1862
Training time: 12.56 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.2563
Epoch 002, Loss: 1.2950
Epoch 003, Loss: 1.4145
Epoch 004, Loss: 1.6224
Epoch 005, Loss: 1.3642
Epoch 006, Loss: 1.2152
Epoch 007, Loss: 1.2646
Epoch 008, Loss: 1.2045
Epoch 009, Loss: 1.3203
Epoch 010, Loss: 1.2517
Epoch 011, Loss: 1.2086
Epoch 012, Loss: 1.2764
Epoch 013, Loss: 1.2466
Epoch 014, Loss: 1.2270
Epoch 015, Loss: 1.1041
Epoch 016, Loss: 1.2532
Epoch 017, Loss: 1.4093
Epoch 018, Loss: 1.2070
Epoch 019, Loss: 1.2086
Epoch 020, Loss: 1.1849
Epoch 021, Loss: 1.0994
Epoch 022, Loss: 1.2482
Epoch 023, Loss: 1.1736
Epoch 024, Loss: 1.1962
Epoch 025, Loss: 1.4167
Epoch 026, Loss: 1.3703
Epoch 027, Loss: 1.1533
Epoch 028, Loss: 1.1582
Epoch 029, Loss: 1.2290
Epoch 030, Loss: 1.2447
Epoch 031, Loss: 1.1241
Epoch 032, Loss: 1.2592
Epoch 033, Loss: 1.2823
Epoch 034, Loss: 1.0961
Epoch 035, Loss: 1.1371
Epoch 036, Loss: 1.0967
Epoch 037, Loss: 1.0720
Epoch 038, Loss: 1.2055
Epoch 039, Loss: 1.2835
Epoch 040, Loss: 1.0733
Epoch 041, Loss: 1.0499
Epoch 042, Loss: 1.0070
Epoch 043, Loss: 1.0049
Epoch 044, Loss: 0.9649
Epoch 045, Loss: 0.9479
Epoch 046, Loss: 0.9768
Epoch 047, Loss: 0.9040
Epoch 048, Loss: 0.9400
Epoch 049, Loss: 0.9304
Epoch 050, Loss: 0.9399
Epoch 051, Loss: 0.9540
Epoch 052, Loss: 0.9534
Epoch 053, Loss: 0.9298
Epoch 054, Loss: 0.8988
Epoch 055, Loss: 0.8501
Epoch 056, Loss: 0.8258
Epoch 057, Loss: 0.9159
Epoch 058, Loss: 0.8063
Epoch 059, Loss: 0.9446
Epoch 060, Loss: 0.8796
Epoch 061, Loss: 0.8175
Epoch 062, Loss: 0.8459
Epoch 063, Loss: 0.8251
Epoch 064, Loss: 0.8997
Epoch 065, Loss: 0.8000
Epoch 066, Loss: 0.8147
Epoch 067, Loss: 0.7982
Epoch 068, Loss: 0.7604
Epoch 069, Loss: 0.8099
Epoch 070, Loss: 0.8158
Epoch 071, Loss: 0.7503
Epoch 072, Loss: 0.7928
Epoch 073, Loss: 0.7296
Epoch 074, Loss: 0.8387
Epoch 075, Loss: 0.7301
Epoch 076, Loss: 0.8170
Epoch 077, Loss: 0.8687
Epoch 078, Loss: 0.8526
Epoch 079, Loss: 0.8627
Epoch 080, Loss: 0.7826
Epoch 081, Loss: 0.7918
Epoch 082, Loss: 0.7662
Epoch 083, Loss: 0.7587
Epoch 084, Loss: 0.8721
Epoch 085, Loss: 0.7526
Epoch 086, Loss: 0.7143
Epoch 087, Loss: 0.7266
Epoch 088, Loss: 0.8523
Epoch 089, Loss: 0.7268
Epoch 090, Loss: 0.6903
Epoch 091, Loss: 0.8107
Epoch 092, Loss: 0.7560
Epoch 093, Loss: 0.6884
Epoch 094, Loss: 0.7311
Epoch 095, Loss: 0.7203
Epoch 096, Loss: 0.6753
Epoch 097, Loss: 0.6671
Epoch 098, Loss: 0.8623
Epoch 099, Loss: 0.6929
Epoch 100, Loss: 0.6579

Test RMSE: 0.9557
Test MAPE: 0.2461
Training time: 12.87 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 9.4117
Epoch 002, Loss: 1.4960
Epoch 003, Loss: 1.6709
Epoch 004, Loss: 1.5682
Epoch 005, Loss: 1.5439
Epoch 006, Loss: 1.5691
Epoch 007, Loss: 1.8712
Epoch 008, Loss: 1.5711
Epoch 009, Loss: 1.7152
Epoch 010, Loss: 1.7224
Epoch 011, Loss: 1.7183
Epoch 012, Loss: 1.7535
Epoch 013, Loss: 1.5682
Epoch 014, Loss: 1.8252
Epoch 015, Loss: 1.4628
Epoch 016, Loss: 1.7936
Epoch 017, Loss: 1.5515
Epoch 018, Loss: 1.6363
Epoch 019, Loss: 1.6707
Epoch 020, Loss: 1.4687
Epoch 021, Loss: 1.6846
Epoch 022, Loss: 1.6281
Epoch 023, Loss: 1.4681
Epoch 024, Loss: 1.6690
Epoch 025, Loss: 1.4978
Epoch 026, Loss: 1.7496
Epoch 027, Loss: 1.5565
Epoch 028, Loss: 1.5558
Epoch 029, Loss: 1.5835
Epoch 030, Loss: 1.4687
Epoch 031, Loss: 1.5749
Epoch 032, Loss: 1.4667
Epoch 033, Loss: 1.5163
Epoch 034, Loss: 2.0311
Epoch 035, Loss: 1.6124
Epoch 036, Loss: 1.5723
Epoch 037, Loss: 1.5001
Epoch 038, Loss: 1.4230
Epoch 039, Loss: 1.5266
Epoch 040, Loss: 1.5273
Epoch 041, Loss: 1.5853
Epoch 042, Loss: 1.4612
Epoch 043, Loss: 1.4872
Epoch 044, Loss: 1.5731
Epoch 045, Loss: 1.5269
Epoch 046, Loss: 1.6508
Epoch 047, Loss: 1.4623
Epoch 048, Loss: 1.4479
Epoch 049, Loss: 1.4558
Epoch 050, Loss: 1.6741
Epoch 051, Loss: 1.4779
Epoch 052, Loss: 1.3964
Epoch 053, Loss: 1.5074
Epoch 054, Loss: 1.5214
Epoch 055, Loss: 1.5730
Epoch 056, Loss: 1.6349
Epoch 057, Loss: 1.5008
Epoch 058, Loss: 1.5756
Epoch 059, Loss: 1.4139
Epoch 060, Loss: 1.3614
Epoch 061, Loss: 1.5191
Epoch 062, Loss: 1.4541
Epoch 063, Loss: 1.4490
Epoch 064, Loss: 1.6090
Epoch 065, Loss: 1.9550
Epoch 066, Loss: 1.5053
Epoch 067, Loss: 1.5856
Epoch 068, Loss: 1.5599
Epoch 069, Loss: 1.5096
Epoch 070, Loss: 1.6726
Epoch 071, Loss: 1.4659
Epoch 072, Loss: 1.5819
Epoch 073, Loss: 1.4983
Epoch 074, Loss: 1.3772
Epoch 075, Loss: 1.4036
Epoch 076, Loss: 1.3268
Epoch 077, Loss: 1.4357
Epoch 078, Loss: 1.3118
Epoch 079, Loss: 1.3692
Epoch 080, Loss: 1.3263
Epoch 081, Loss: 1.1542
Epoch 082, Loss: 1.2252
Epoch 083, Loss: 1.1119
Epoch 084, Loss: 0.9918
Epoch 085, Loss: 1.0982
Epoch 086, Loss: 0.9978
Epoch 087, Loss: 1.0849
Epoch 088, Loss: 1.1348
Epoch 089, Loss: 0.8790
Epoch 090, Loss: 1.0222
Epoch 091, Loss: 1.0307
Epoch 092, Loss: 0.9741
Epoch 093, Loss: 0.8130
Epoch 094, Loss: 0.8323
Epoch 095, Loss: 0.9581
Epoch 096, Loss: 0.8215
Epoch 097, Loss: 0.8373
Epoch 098, Loss: 0.8628
Epoch 099, Loss: 0.8018
Epoch 100, Loss: 0.8669

Test RMSE: 1.4297
Test MAPE: 0.2156
Training time: 13.31 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7285
Epoch 002, Loss: 3.3578
Epoch 003, Loss: 3.2835
Epoch 004, Loss: 3.1719
Epoch 005, Loss: 3.1324
Epoch 006, Loss: 2.7983
Epoch 007, Loss: 2.6052
Epoch 008, Loss: 2.3890
Epoch 009, Loss: 1.9465
Epoch 010, Loss: 1.6849
Epoch 011, Loss: 0.9234
Epoch 012, Loss: 0.7916
Epoch 013, Loss: 0.8974
Epoch 014, Loss: 0.6980
Epoch 015, Loss: 0.6820
Epoch 016, Loss: 0.6543
Epoch 017, Loss: 0.6532
Epoch 018, Loss: 0.7883
Epoch 019, Loss: 0.7176
Epoch 020, Loss: 0.6732
Epoch 021, Loss: 0.7324
Epoch 022, Loss: 0.6770
Epoch 023, Loss: 0.6133
Epoch 024, Loss: 0.6749
Epoch 025, Loss: 0.6360
Epoch 026, Loss: 0.6044
Epoch 027, Loss: 0.7137
Epoch 028, Loss: 0.6019
Epoch 029, Loss: 0.5960
Epoch 030, Loss: 0.5786
Epoch 031, Loss: 0.6308
Epoch 032, Loss: 0.6343
Epoch 033, Loss: 0.5739
Epoch 034, Loss: 0.5939
Epoch 035, Loss: 0.6131
Epoch 036, Loss: 0.6426
Epoch 037, Loss: 0.5770
Epoch 038, Loss: 0.5586
Epoch 039, Loss: 0.6187
Epoch 040, Loss: 0.6285
Epoch 041, Loss: 0.6314
Epoch 042, Loss: 0.5469
Epoch 043, Loss: 0.6294
Epoch 044, Loss: 0.6111
Epoch 045, Loss: 0.5419
Epoch 046, Loss: 0.5659
Epoch 047, Loss: 0.6192
Epoch 048, Loss: 0.5942
Epoch 049, Loss: 0.6166
Epoch 050, Loss: 0.5186
Epoch 051, Loss: 0.5917
Epoch 052, Loss: 0.5500
Epoch 053, Loss: 0.8838
Epoch 054, Loss: 0.5183
Epoch 055, Loss: 0.5528
Epoch 056, Loss: 0.4899
Epoch 057, Loss: 0.5429
Epoch 058, Loss: 0.5432
Epoch 059, Loss: 0.5483
Epoch 060, Loss: 0.7023
Epoch 061, Loss: 0.5381
Epoch 062, Loss: 0.5473
Epoch 063, Loss: 0.6008
Epoch 064, Loss: 0.5322
Epoch 065, Loss: 0.5984
Epoch 066, Loss: 0.5694
Epoch 067, Loss: 0.5413
Epoch 068, Loss: 0.5689
Epoch 069, Loss: 0.5623
Epoch 070, Loss: 0.5489
Epoch 071, Loss: 0.6169
Epoch 072, Loss: 0.5580
Epoch 073, Loss: 0.5799
Epoch 074, Loss: 0.5886
Epoch 075, Loss: 0.5108
Epoch 076, Loss: 0.5256
Epoch 077, Loss: 0.5069
Epoch 078, Loss: 0.5587
Epoch 079, Loss: 0.5610
Epoch 080, Loss: 0.5313
Epoch 081, Loss: 0.5119
Epoch 082, Loss: 0.5378
Epoch 083, Loss: 0.5114
Epoch 084, Loss: 0.5513
Epoch 085, Loss: 0.4854
Epoch 086, Loss: 0.5630
Epoch 087, Loss: 0.5394
Epoch 088, Loss: 0.4876
Epoch 089, Loss: 0.5364
Epoch 090, Loss: 0.5567
Epoch 091, Loss: 0.4681
Epoch 092, Loss: 0.5409
Epoch 093, Loss: 0.5857
Epoch 094, Loss: 0.4976
Epoch 095, Loss: 0.5264
Epoch 096, Loss: 0.5600
Epoch 097, Loss: 0.5155
Epoch 098, Loss: 0.5524
Epoch 099, Loss: 0.5254
Epoch 100, Loss: 0.5530

Test RMSE: 0.7740
Test MAPE: 180945361567744.0000
Training time: 64.80 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.633515 2.156183e-01      12.155485   GNN_model_10.pkl
       12   Q_values        0.2 0.727468 2.460492e-01      12.320625   GNN_model_12.pkl
       15   Q_values        0.2 0.862546 1.861740e-01      12.564118   GNN_model_15.pkl
       20   Q_values        0.2 0.955666 2.461159e-01      12.865236   GNN_model_20.pkl
       25   Q_values        0.2 1.429696 2.156115e-01      13.310688   GNN_model_25.pkl
     full   Q_values        0.2 0.773979 1.809454e+14      64.800250 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 24%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
