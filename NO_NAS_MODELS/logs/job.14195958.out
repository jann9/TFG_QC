
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59683
 Mean Absolute Percentage Error: 0.25453
 Training time:  0.03581
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55253
 Mean Absolute Percentage Error: 0.39635
 Training time:  0.01779
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71587
 Mean Absolute Percentage Error: 0.57650
 Training time:  0.06158
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86121
 Mean Absolute Percentage Error: 0.53731
 Training time:  0.01737
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69224
 Mean Absolute Percentage Error: 0.29209
 Training time:  0.03442
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52216
 Mean Absolute Percentage Error: 0.17590
 Training time:  0.01705
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60469
 Mean Absolute Percentage Error: 0.22746
 Training time:  0.08245
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61097
 Mean Absolute Percentage Error: 0.25818
 Training time:  0.01709
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54014
 Mean Absolute Percentage Error: 0.17925
 Training time:  0.14471
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67733
 Mean Absolute Percentage Error: 0.21839
 Training time:  0.01706
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61667
 Mean Absolute Percentage Error: 0.23955
 Training time:  0.11207
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65617
 Mean Absolute Percentage Error: 0.29548
 Training time:  0.02424
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60243
  MAPE on 10 nodes subset: 0.26879

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71061
  MAPE on 12 nodes subset: 0.57206

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68802
  MAPE on 15 nodes subset: 0.29333

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58611
  MAPE on 20 nodes subset: 0.22957

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52784
  MAPE on 25 nodes subset: 0.18211

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596825 0.254529       0.035811       True             4                       MLP_model_10.pkl       33
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552533 0.396347       0.017792       True             4               MLP_model_10_Circuit.pkl       33
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715867 0.576503       0.061579       True             4                       MLP_model_12.pkl       33
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861212 0.537306       0.017365       True             4               MLP_model_12_Circuit.pkl       33
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692237 0.292091       0.034420       True             3                       MLP_model_15.pkl       33
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522163 0.175898       0.017046       True             4               MLP_model_15_Circuit.pkl       33
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604692 0.227465       0.082446       True             4                       MLP_model_20.pkl       33
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.610972 0.258177       0.017094       True             4               MLP_model_20_Circuit.pkl       33
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540139 0.179253       0.144710       True             4                       MLP_model_25.pkl       33
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677333 0.218386       0.017065       True             4               MLP_model_25_Circuit.pkl       33
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616675 0.239554       0.112072       True             4                     MLP_model_full.pkl       33
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.656171 0.295485       0.024242       True             4             MLP_model_full_Circuit.pkl       33
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602425 0.268791       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710613 0.572056       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.688015 0.293328       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586115 0.229571       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.527844 0.182108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59401
 Mean Absolute Percentage Error: 0.43370
 Training time:  0.34590
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75777
 Mean Absolute Percentage Error: 0.39224
 Training time:  0.25241
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98528
 Mean Absolute Percentage Error: 0.67209
 Training time:  0.37509
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10948
 Mean Absolute Percentage Error: 0.66134
 Training time:  0.26435
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.58637
 Mean Absolute Percentage Error: 0.18300
 Training time:  0.48419
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79346
 Mean Absolute Percentage Error: 0.22667
 Training time:  0.27260
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.63950
 Mean Absolute Percentage Error: 0.26714
 Training time:  0.68793
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85060
 Mean Absolute Percentage Error: 0.32936
 Training time:  0.27313
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73448
 Mean Absolute Percentage Error: 0.22691
 Training time:  0.79463
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69855
 Mean Absolute Percentage Error: 0.18431
 Training time:  0.26926
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72381
 Mean Absolute Percentage Error: 0.30676
 Training time:  3.34592
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75294
 Mean Absolute Percentage Error: 0.30073
 Training time:  0.33296
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22539
  MAPE on 10 nodes subset: 0.02758

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.35289
  MAPE on 12 nodes subset: 0.26848

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.11411
  MAPE on 15 nodes subset: 0.01408

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40091
  MAPE on 20 nodes subset: 0.09517

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.20798
  MAPE on 25 nodes subset: 0.02627

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.594008 0.433701       0.345897                           xgboost_model_10.pkl       13
       10             Circuit            50           5          4 0.757769 0.392244       0.252410                   xgboost_model_10_Circuit.pkl       13
       12            Q_values            50          78          4 0.985282 0.672094       0.375088                           xgboost_model_12.pkl       13
       12             Circuit            50           5          4 1.109481 0.661343       0.264350                   xgboost_model_12_Circuit.pkl       13
       15            Q_values            50         120          4 0.586368 0.183004       0.484194                           xgboost_model_15.pkl       13
       15             Circuit            50           5          4 0.793463 0.226672       0.272602                   xgboost_model_15_Circuit.pkl       13
       20            Q_values            50         210          4 0.639498 0.267140       0.687932                           xgboost_model_20.pkl       13
       20             Circuit            50           5          4 0.850598 0.329363       0.273134                   xgboost_model_20_Circuit.pkl       13
       25            Q_values            50         325          4 0.734479 0.226913       0.794627                           xgboost_model_25.pkl       13
       25             Circuit            50           5          4 0.698545 0.184313       0.269259                   xgboost_model_25_Circuit.pkl       13
     full            Q_values           250         325          4 0.723814 0.306755       3.345921                         xgboost_model_full.pkl       13
     full             Circuit           250           5          4 0.752935 0.300732       0.332959                 xgboost_model_full_Circuit.pkl       13
       10 Q_values_full_model            50         325          4 0.225387 0.027578       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       12 Q_values_full_model            50         325          4 0.352891 0.268481       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       15 Q_values_full_model            50         325          4 0.114109 0.014077       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       20 Q_values_full_model            50         325          4 0.400908 0.095170       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       25 Q_values_full_model            50         325          4 0.207977 0.026266       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.9068
Epoch 002, Loss: 0.5726
Epoch 003, Loss: 0.5613
Epoch 004, Loss: 0.5595
Epoch 005, Loss: 0.5854
Epoch 006, Loss: 0.5476
Epoch 007, Loss: 0.5945
Epoch 008, Loss: 0.5757
Epoch 009, Loss: 0.5729
Epoch 010, Loss: 0.6031
Epoch 011, Loss: 0.5723
Epoch 012, Loss: 0.6013
Epoch 013, Loss: 0.7604
Epoch 014, Loss: 0.5980
Epoch 015, Loss: 0.5996
Epoch 016, Loss: 0.5440
Epoch 017, Loss: 0.5676
Epoch 018, Loss: 0.6327
Epoch 019, Loss: 0.5789
Epoch 020, Loss: 0.6098
Epoch 021, Loss: 0.5705
Epoch 022, Loss: 0.5341
Epoch 023, Loss: 0.5872
Epoch 024, Loss: 0.6155
Epoch 025, Loss: 0.6165
Epoch 026, Loss: 0.6444
Epoch 027, Loss: 0.5889
Epoch 028, Loss: 0.5415
Epoch 029, Loss: 0.5466
Epoch 030, Loss: 0.5579
Epoch 031, Loss: 0.5572
Epoch 032, Loss: 0.5801
Epoch 033, Loss: 0.5507
Epoch 034, Loss: 0.5870
Epoch 035, Loss: 0.5680
Epoch 036, Loss: 0.6090
Epoch 037, Loss: 0.5770
Epoch 038, Loss: 0.5279
Epoch 039, Loss: 0.6288
Epoch 040, Loss: 0.5383
Epoch 041, Loss: 0.5244
Epoch 042, Loss: 0.5927
Epoch 043, Loss: 0.5594
Epoch 044, Loss: 0.5343
Epoch 045, Loss: 0.5575
Epoch 046, Loss: 0.5837
Epoch 047, Loss: 0.5419
Epoch 048, Loss: 0.5277
Epoch 049, Loss: 0.5732
Epoch 050, Loss: 0.5059
Epoch 051, Loss: 0.5993
Epoch 052, Loss: 0.5316
Epoch 053, Loss: 0.5246
Epoch 054, Loss: 0.5248
Epoch 055, Loss: 0.5108
Epoch 056, Loss: 0.5741
Epoch 057, Loss: 0.5140
Epoch 058, Loss: 0.5557
Epoch 059, Loss: 0.5465
Epoch 060, Loss: 0.5136
Epoch 061, Loss: 0.5132
Epoch 062, Loss: 0.4874
Epoch 063, Loss: 0.5501
Epoch 064, Loss: 0.5686
Epoch 065, Loss: 0.5178
Epoch 066, Loss: 0.5309
Epoch 067, Loss: 0.4992
Epoch 068, Loss: 0.4942
Epoch 069, Loss: 0.5069
Epoch 070, Loss: 0.5152
Epoch 071, Loss: 0.5428
Epoch 072, Loss: 0.5008
Epoch 073, Loss: 0.4939
Epoch 074, Loss: 0.4945
Epoch 075, Loss: 0.5199
Epoch 076, Loss: 0.5092
Epoch 077, Loss: 0.5109
Epoch 078, Loss: 0.4894
Epoch 079, Loss: 0.4909
Epoch 080, Loss: 0.4854
Epoch 081, Loss: 0.4828
Epoch 082, Loss: 0.4935
Epoch 083, Loss: 0.4689
Epoch 084, Loss: 0.4870
Epoch 085, Loss: 0.4709
Epoch 086, Loss: 0.4823
Epoch 087, Loss: 0.4850
Epoch 088, Loss: 0.4581
Epoch 089, Loss: 0.4686
Epoch 090, Loss: 0.4626
Epoch 091, Loss: 0.4813
Epoch 092, Loss: 0.4586
Epoch 093, Loss: 0.4703
Epoch 094, Loss: 0.4478
Epoch 095, Loss: 0.5101
Epoch 096, Loss: 0.4721
Epoch 097, Loss: 0.4364
Epoch 098, Loss: 0.4465
Epoch 099, Loss: 0.4473
Epoch 100, Loss: 0.4537

Test RMSE: 0.6356
Test MAPE: 0.2249
Training time: 14.82 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.7991
Epoch 002, Loss: 0.8374
Epoch 003, Loss: 0.9123
Epoch 004, Loss: 0.8151
Epoch 005, Loss: 0.8621
Epoch 006, Loss: 0.9136
Epoch 007, Loss: 0.9143
Epoch 008, Loss: 0.8915
Epoch 009, Loss: 0.9171
Epoch 010, Loss: 0.8216
Epoch 011, Loss: 0.8706
Epoch 012, Loss: 0.8899
Epoch 013, Loss: 1.0005
Epoch 014, Loss: 0.8439
Epoch 015, Loss: 0.8236
Epoch 016, Loss: 0.9691
Epoch 017, Loss: 0.8675
Epoch 018, Loss: 0.8511
Epoch 019, Loss: 0.8559
Epoch 020, Loss: 0.8715
Epoch 021, Loss: 0.8403
Epoch 022, Loss: 0.8537
Epoch 023, Loss: 0.8444
Epoch 024, Loss: 0.8922
Epoch 025, Loss: 0.7967
Epoch 026, Loss: 0.8500
Epoch 027, Loss: 0.8113
Epoch 028, Loss: 0.8386
Epoch 029, Loss: 0.8337
Epoch 030, Loss: 0.8284
Epoch 031, Loss: 0.8666
Epoch 032, Loss: 0.8194
Epoch 033, Loss: 0.8891
Epoch 034, Loss: 0.8254
Epoch 035, Loss: 0.8043
Epoch 036, Loss: 0.8108
Epoch 037, Loss: 0.8754
Epoch 038, Loss: 0.8161
Epoch 039, Loss: 0.8582
Epoch 040, Loss: 0.7933
Epoch 041, Loss: 0.8292
Epoch 042, Loss: 0.8608
Epoch 043, Loss: 0.8066
Epoch 044, Loss: 0.8192
Epoch 045, Loss: 0.8184
Epoch 046, Loss: 0.8336
Epoch 047, Loss: 0.8234
Epoch 048, Loss: 0.8278
Epoch 049, Loss: 0.8128
Epoch 050, Loss: 0.8070
Epoch 051, Loss: 0.7846
Epoch 052, Loss: 0.7809
Epoch 053, Loss: 0.7697
Epoch 054, Loss: 0.7772
Epoch 055, Loss: 0.8206
Epoch 056, Loss: 0.7922
Epoch 057, Loss: 0.7709
Epoch 058, Loss: 0.7799
Epoch 059, Loss: 0.7776
Epoch 060, Loss: 0.7700
Epoch 061, Loss: 0.7412
Epoch 062, Loss: 0.7332
Epoch 063, Loss: 0.7105
Epoch 064, Loss: 0.7272
Epoch 065, Loss: 0.6756
Epoch 066, Loss: 0.7091
Epoch 067, Loss: 0.7375
Epoch 068, Loss: 0.7440
Epoch 069, Loss: 0.7071
Epoch 070, Loss: 0.7641
Epoch 071, Loss: 0.7268
Epoch 072, Loss: 0.7654
Epoch 073, Loss: 0.7080
Epoch 074, Loss: 0.6869
Epoch 075, Loss: 0.6896
Epoch 076, Loss: 0.6863
Epoch 077, Loss: 0.6719
Epoch 078, Loss: 0.6820
Epoch 079, Loss: 0.6639
Epoch 080, Loss: 0.6979
Epoch 081, Loss: 0.6974
Epoch 082, Loss: 0.7015
Epoch 083, Loss: 0.6825
Epoch 084, Loss: 0.6918
Epoch 085, Loss: 0.6400
Epoch 086, Loss: 0.6420
Epoch 087, Loss: 0.6428
Epoch 088, Loss: 0.6214
Epoch 089, Loss: 0.6488
Epoch 090, Loss: 0.6248
Epoch 091, Loss: 0.6307
Epoch 092, Loss: 0.5986
Epoch 093, Loss: 0.6556
Epoch 094, Loss: 0.6207
Epoch 095, Loss: 0.6002
Epoch 096, Loss: 0.5919
Epoch 097, Loss: 0.6111
Epoch 098, Loss: 0.5626
Epoch 099, Loss: 0.6355
Epoch 100, Loss: 0.6261

Test RMSE: 0.6526
Test MAPE: 0.1984
Training time: 14.48 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.7918
Epoch 002, Loss: 0.9891
Epoch 003, Loss: 0.9286
Epoch 004, Loss: 1.0308
Epoch 005, Loss: 0.9218
Epoch 006, Loss: 0.8953
Epoch 007, Loss: 1.0096
Epoch 008, Loss: 0.9819
Epoch 009, Loss: 0.9404
Epoch 010, Loss: 1.1058
Epoch 011, Loss: 0.8783
Epoch 012, Loss: 0.9108
Epoch 013, Loss: 0.9058
Epoch 014, Loss: 1.0114
Epoch 015, Loss: 0.9149
Epoch 016, Loss: 1.0708
Epoch 017, Loss: 0.9446
Epoch 018, Loss: 0.9562
Epoch 019, Loss: 0.9445
Epoch 020, Loss: 0.9421
Epoch 021, Loss: 0.8714
Epoch 022, Loss: 0.9600
Epoch 023, Loss: 0.9616
Epoch 024, Loss: 0.9032
Epoch 025, Loss: 0.9347
Epoch 026, Loss: 0.9165
Epoch 027, Loss: 0.9330
Epoch 028, Loss: 0.8921
Epoch 029, Loss: 1.0557
Epoch 030, Loss: 0.9284
Epoch 031, Loss: 0.8557
Epoch 032, Loss: 0.8824
Epoch 033, Loss: 0.8984
Epoch 034, Loss: 0.8973
Epoch 035, Loss: 0.9504
Epoch 036, Loss: 0.9054
Epoch 037, Loss: 0.9073
Epoch 038, Loss: 0.8720
Epoch 039, Loss: 0.8673
Epoch 040, Loss: 0.8921
Epoch 041, Loss: 0.8408
Epoch 042, Loss: 0.8773
Epoch 043, Loss: 0.8741
Epoch 044, Loss: 0.8874
Epoch 045, Loss: 0.8553
Epoch 046, Loss: 0.8198
Epoch 047, Loss: 0.8164
Epoch 048, Loss: 1.0650
Epoch 049, Loss: 0.8238
Epoch 050, Loss: 0.8376
Epoch 051, Loss: 0.8670
Epoch 052, Loss: 0.7724
Epoch 053, Loss: 0.8726
Epoch 054, Loss: 0.7501
Epoch 055, Loss: 0.7822
Epoch 056, Loss: 0.7202
Epoch 057, Loss: 0.7494
Epoch 058, Loss: 0.7227
Epoch 059, Loss: 0.8134
Epoch 060, Loss: 0.7300
Epoch 061, Loss: 0.7205
Epoch 062, Loss: 0.6689
Epoch 063, Loss: 0.7209
Epoch 064, Loss: 0.6984
Epoch 065, Loss: 0.7274
Epoch 066, Loss: 0.6724
Epoch 067, Loss: 0.6341
Epoch 068, Loss: 0.6411
Epoch 069, Loss: 0.6584
Epoch 070, Loss: 0.6416
Epoch 071, Loss: 0.6520
Epoch 072, Loss: 0.6558
Epoch 073, Loss: 0.6013
Epoch 074, Loss: 0.7057
Epoch 075, Loss: 0.6160
Epoch 076, Loss: 0.5690
Epoch 077, Loss: 0.5819
Epoch 078, Loss: 0.5779
Epoch 079, Loss: 0.6121
Epoch 080, Loss: 0.5905
Epoch 081, Loss: 0.6090
Epoch 082, Loss: 0.5954
Epoch 083, Loss: 0.5483
Epoch 084, Loss: 0.6084
Epoch 085, Loss: 0.6626
Epoch 086, Loss: 0.5128
Epoch 087, Loss: 0.5668
Epoch 088, Loss: 0.5696
Epoch 089, Loss: 0.5734
Epoch 090, Loss: 0.5379
Epoch 091, Loss: 0.5212
Epoch 092, Loss: 0.5716
Epoch 093, Loss: 0.5139
Epoch 094, Loss: 0.5356
Epoch 095, Loss: 0.5477
Epoch 096, Loss: 0.5368
Epoch 097, Loss: 0.4964
Epoch 098, Loss: 0.5131
Epoch 099, Loss: 0.5779
Epoch 100, Loss: 0.5088

Test RMSE: 0.7735
Test MAPE: 0.2301
Training time: 14.82 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.6345
Epoch 002, Loss: 1.2868
Epoch 003, Loss: 1.3844
Epoch 004, Loss: 1.2923
Epoch 005, Loss: 1.3814
Epoch 006, Loss: 1.3197
Epoch 007, Loss: 1.1244
Epoch 008, Loss: 1.4151
Epoch 009, Loss: 1.2636
Epoch 010, Loss: 1.2386
Epoch 011, Loss: 1.2008
Epoch 012, Loss: 1.3541
Epoch 013, Loss: 1.3392
Epoch 014, Loss: 1.2882
Epoch 015, Loss: 1.1605
Epoch 016, Loss: 1.2392
Epoch 017, Loss: 1.2027
Epoch 018, Loss: 1.2731
Epoch 019, Loss: 1.2150
Epoch 020, Loss: 1.1731
Epoch 021, Loss: 1.3912
Epoch 022, Loss: 1.1766
Epoch 023, Loss: 1.2608
Epoch 024, Loss: 1.2399
Epoch 025, Loss: 1.3830
Epoch 026, Loss: 1.2087
Epoch 027, Loss: 1.1667
Epoch 028, Loss: 1.3800
Epoch 029, Loss: 1.1561
Epoch 030, Loss: 1.1635
Epoch 031, Loss: 1.1512
Epoch 032, Loss: 1.2610
Epoch 033, Loss: 1.2332
Epoch 034, Loss: 1.1915
Epoch 035, Loss: 1.3021
Epoch 036, Loss: 1.1700
Epoch 037, Loss: 1.1888
Epoch 038, Loss: 1.2150
Epoch 039, Loss: 1.1007
Epoch 040, Loss: 1.1642
Epoch 041, Loss: 1.1278
Epoch 042, Loss: 1.2439
Epoch 043, Loss: 1.2614
Epoch 044, Loss: 1.0550
Epoch 045, Loss: 1.0184
Epoch 046, Loss: 1.0008
Epoch 047, Loss: 1.3072
Epoch 048, Loss: 1.1244
Epoch 049, Loss: 0.9632
Epoch 050, Loss: 0.8767
Epoch 051, Loss: 0.8766
Epoch 052, Loss: 0.8836
Epoch 053, Loss: 0.8722
Epoch 054, Loss: 0.8782
Epoch 055, Loss: 0.8421
Epoch 056, Loss: 0.8019
Epoch 057, Loss: 0.7491
Epoch 058, Loss: 0.8129
Epoch 059, Loss: 0.7581
Epoch 060, Loss: 0.7306
Epoch 061, Loss: 0.6946
Epoch 062, Loss: 0.7129
Epoch 063, Loss: 0.7828
Epoch 064, Loss: 0.7017
Epoch 065, Loss: 0.6500
Epoch 066, Loss: 0.6952
Epoch 067, Loss: 0.6328
Epoch 068, Loss: 0.6055
Epoch 069, Loss: 0.6409
Epoch 070, Loss: 0.6059
Epoch 071, Loss: 0.5839
Epoch 072, Loss: 0.6119
Epoch 073, Loss: 0.6350
Epoch 074, Loss: 0.5955
Epoch 075, Loss: 0.5758
Epoch 076, Loss: 0.5627
Epoch 077, Loss: 0.5372
Epoch 078, Loss: 0.6164
Epoch 079, Loss: 0.5435
Epoch 080, Loss: 0.5609
Epoch 081, Loss: 0.5888
Epoch 082, Loss: 0.6171
Epoch 083, Loss: 0.6046
Epoch 084, Loss: 0.5834
Epoch 085, Loss: 0.5240
Epoch 086, Loss: 0.5162
Epoch 087, Loss: 0.5801
Epoch 088, Loss: 0.5578
Epoch 089, Loss: 0.5810
Epoch 090, Loss: 0.5320
Epoch 091, Loss: 0.5361
Epoch 092, Loss: 0.4830
Epoch 093, Loss: 0.6030
Epoch 094, Loss: 0.4866
Epoch 095, Loss: 0.5055
Epoch 096, Loss: 0.4786
Epoch 097, Loss: 0.4682
Epoch 098, Loss: 0.5725
Epoch 099, Loss: 0.4963
Epoch 100, Loss: 0.5136

Test RMSE: 0.9073
Test MAPE: 0.2008
Training time: 15.11 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 11.2342
Epoch 002, Loss: 1.6744
Epoch 003, Loss: 1.6358
Epoch 004, Loss: 1.9799
Epoch 005, Loss: 1.5963
Epoch 006, Loss: 1.5146
Epoch 007, Loss: 1.6842
Epoch 008, Loss: 1.8324
Epoch 009, Loss: 1.7564
Epoch 010, Loss: 1.6701
Epoch 011, Loss: 1.5264
Epoch 012, Loss: 1.5509
Epoch 013, Loss: 1.7489
Epoch 014, Loss: 1.5511
Epoch 015, Loss: 1.5605
Epoch 016, Loss: 1.5533
Epoch 017, Loss: 1.6819
Epoch 018, Loss: 1.4707
Epoch 019, Loss: 1.5643
Epoch 020, Loss: 1.7251
Epoch 021, Loss: 1.7709
Epoch 022, Loss: 1.5212
Epoch 023, Loss: 1.5188
Epoch 024, Loss: 1.7647
Epoch 025, Loss: 1.4800
Epoch 026, Loss: 1.5671
Epoch 027, Loss: 1.9733
Epoch 028, Loss: 1.6751
Epoch 029, Loss: 1.4572
Epoch 030, Loss: 1.5690
Epoch 031, Loss: 1.5018
Epoch 032, Loss: 1.4924
Epoch 033, Loss: 1.6476
Epoch 034, Loss: 1.9069
Epoch 035, Loss: 1.4496
Epoch 036, Loss: 1.6559
Epoch 037, Loss: 1.4925
Epoch 038, Loss: 1.5890
Epoch 039, Loss: 1.4411
Epoch 040, Loss: 1.4919
Epoch 041, Loss: 1.4940
Epoch 042, Loss: 1.3438
Epoch 043, Loss: 1.9778
Epoch 044, Loss: 1.5611
Epoch 045, Loss: 1.6372
Epoch 046, Loss: 1.7009
Epoch 047, Loss: 1.5585
Epoch 048, Loss: 1.5792
Epoch 049, Loss: 1.5809
Epoch 050, Loss: 1.5017
Epoch 051, Loss: 1.5082
Epoch 052, Loss: 1.7046
Epoch 053, Loss: 1.5355
Epoch 054, Loss: 1.5138
Epoch 055, Loss: 1.5399
Epoch 056, Loss: 1.4795
Epoch 057, Loss: 1.5640
Epoch 058, Loss: 1.4774
Epoch 059, Loss: 1.7040
Epoch 060, Loss: 1.5670
Epoch 061, Loss: 1.3710
Epoch 062, Loss: 1.5486
Epoch 063, Loss: 1.5049
Epoch 064, Loss: 1.5251
Epoch 065, Loss: 1.5153
Epoch 066, Loss: 1.5255
Epoch 067, Loss: 1.3825
Epoch 068, Loss: 1.4765
Epoch 069, Loss: 1.5655
Epoch 070, Loss: 1.5498
Epoch 071, Loss: 1.6241
Epoch 072, Loss: 1.6133
Epoch 073, Loss: 1.5123
Epoch 074, Loss: 1.4314
Epoch 075, Loss: 1.5248
Epoch 076, Loss: 1.5761
Epoch 077, Loss: 1.5747
Epoch 078, Loss: 1.4433
Epoch 079, Loss: 1.3806
Epoch 080, Loss: 1.4592
Epoch 081, Loss: 1.4072
Epoch 082, Loss: 1.5039
Epoch 083, Loss: 1.5493
Epoch 084, Loss: 1.3681
Epoch 085, Loss: 1.5501
Epoch 086, Loss: 1.4569
Epoch 087, Loss: 1.3917
Epoch 088, Loss: 1.6096
Epoch 089, Loss: 1.5680
Epoch 090, Loss: 1.4961
Epoch 091, Loss: 1.4052
Epoch 092, Loss: 1.3964
Epoch 093, Loss: 1.4425
Epoch 094, Loss: 1.3455
Epoch 095, Loss: 1.4764
Epoch 096, Loss: 1.4823
Epoch 097, Loss: 1.5743
Epoch 098, Loss: 1.3810
Epoch 099, Loss: 1.2589
Epoch 100, Loss: 1.4707

Test RMSE: 1.4641
Test MAPE: 0.1942
Training time: 15.79 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8415
Epoch 002, Loss: 3.3437
Epoch 003, Loss: 3.2339
Epoch 004, Loss: 2.3346
Epoch 005, Loss: 1.2581
Epoch 006, Loss: 0.7670
Epoch 007, Loss: 0.7048
Epoch 008, Loss: 0.6477
Epoch 009, Loss: 0.6373
Epoch 010, Loss: 0.6945
Epoch 011, Loss: 0.7415
Epoch 012, Loss: 0.6686
Epoch 013, Loss: 0.6353
Epoch 014, Loss: 0.6052
Epoch 015, Loss: 0.6300
Epoch 016, Loss: 0.6070
Epoch 017, Loss: 0.5753
Epoch 018, Loss: 0.6148
Epoch 019, Loss: 0.6519
Epoch 020, Loss: 0.6556
Epoch 021, Loss: 0.6531
Epoch 022, Loss: 0.6047
Epoch 023, Loss: 0.5348
Epoch 024, Loss: 0.6245
Epoch 025, Loss: 0.6217
Epoch 026, Loss: 0.6328
Epoch 027, Loss: 0.5963
Epoch 028, Loss: 0.6090
Epoch 029, Loss: 0.6202
Epoch 030, Loss: 0.5932
Epoch 031, Loss: 0.5817
Epoch 032, Loss: 0.5542
Epoch 033, Loss: 0.5833
Epoch 034, Loss: 0.6062
Epoch 035, Loss: 0.5491
Epoch 036, Loss: 0.5926
Epoch 037, Loss: 0.5860
Epoch 038, Loss: 0.5585
Epoch 039, Loss: 0.5789
Epoch 040, Loss: 0.5410
Epoch 041, Loss: 0.5707
Epoch 042, Loss: 0.5589
Epoch 043, Loss: 0.5489
Epoch 044, Loss: 0.5537
Epoch 045, Loss: 0.5276
Epoch 046, Loss: 0.5462
Epoch 047, Loss: 0.5402
Epoch 048, Loss: 0.5312
Epoch 049, Loss: 0.5198
Epoch 050, Loss: 0.5225
Epoch 051, Loss: 0.5568
Epoch 052, Loss: 0.5706
Epoch 053, Loss: 0.5770
Epoch 054, Loss: 0.5497
Epoch 055, Loss: 0.5324
Epoch 056, Loss: 0.5218
Epoch 057, Loss: 0.5077
Epoch 058, Loss: 0.5857
Epoch 059, Loss: 0.6134
Epoch 060, Loss: 0.5423
Epoch 061, Loss: 0.5141
Epoch 062, Loss: 0.5668
Epoch 063, Loss: 0.5053
Epoch 064, Loss: 0.5292
Epoch 065, Loss: 0.5342
Epoch 066, Loss: 0.5477
Epoch 067, Loss: 0.5013
Epoch 068, Loss: 0.5022
Epoch 069, Loss: 0.5505
Epoch 070, Loss: 0.5027
Epoch 071, Loss: 0.5106
Epoch 072, Loss: 0.5123
Epoch 073, Loss: 0.5026
Epoch 074, Loss: 0.5579
Epoch 075, Loss: 0.4885
Epoch 076, Loss: 0.5473
Epoch 077, Loss: 0.4960
Epoch 078, Loss: 0.5265
Epoch 079, Loss: 0.4770
Epoch 080, Loss: 0.5429
Epoch 081, Loss: 0.5272
Epoch 082, Loss: 0.4898
Epoch 083, Loss: 0.5232
Epoch 084, Loss: 0.4726
Epoch 085, Loss: 0.4895
Epoch 086, Loss: 0.4710
Epoch 087, Loss: 0.4694
Epoch 088, Loss: 0.4611
Epoch 089, Loss: 0.5215
Epoch 090, Loss: 0.4714
Epoch 091, Loss: 0.5630
Epoch 092, Loss: 0.4792
Epoch 093, Loss: 0.4692
Epoch 094, Loss: 0.4658
Epoch 095, Loss: 0.4986
Epoch 096, Loss: 0.4718
Epoch 097, Loss: 0.4811
Epoch 098, Loss: 0.4756
Epoch 099, Loss: 0.5333
Epoch 100, Loss: 0.4801

Test RMSE: 0.6677
Test MAPE: 321592554946560.0000
Training time: 76.38 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.635596 2.248599e-01      14.821562   GNN_model_10.pkl
       12   Q_values        0.2 0.652627 1.983623e-01      14.482456   GNN_model_12.pkl
       15   Q_values        0.2 0.773509 2.300597e-01      14.823628   GNN_model_15.pkl
       20   Q_values        0.2 0.907263 2.007724e-01      15.109356   GNN_model_20.pkl
       25   Q_values        0.2 1.464057 1.942481e-01      15.786220   GNN_model_25.pkl
     full   Q_values        0.2 0.667661 3.215926e+14      76.379078 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 61%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
