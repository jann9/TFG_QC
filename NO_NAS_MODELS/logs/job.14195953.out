
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59683
 Mean Absolute Percentage Error: 0.25453
 Training time:  0.08004
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55253
 Mean Absolute Percentage Error: 0.39635
 Training time:  0.09126
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71587
 Mean Absolute Percentage Error: 0.57650
 Training time:  0.15476
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86121
 Mean Absolute Percentage Error: 0.53731
 Training time:  0.01646
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.69224
 Mean Absolute Percentage Error: 0.29209
 Training time:  0.03129
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52216
 Mean Absolute Percentage Error: 0.17590
 Training time:  0.05097
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60469
 Mean Absolute Percentage Error: 0.22746
 Training time:  0.04834
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61097
 Mean Absolute Percentage Error: 0.25818
 Training time:  0.05182
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.54014
 Mean Absolute Percentage Error: 0.17925
 Training time:  0.09902
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67733
 Mean Absolute Percentage Error: 0.21839
 Training time:  0.01654
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61667
 Mean Absolute Percentage Error: 0.23955
 Training time:  0.10471
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65617
 Mean Absolute Percentage Error: 0.29548
 Training time:  0.02060
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60243
  MAPE on 10 nodes subset: 0.26879

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71061
  MAPE on 12 nodes subset: 0.57206

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68802
  MAPE on 15 nodes subset: 0.29333

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58611
  MAPE on 20 nodes subset: 0.22957

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52784
  MAPE on 25 nodes subset: 0.18211

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596825 0.254529       0.080037       True             4                       MLP_model_10.pkl       33
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552533 0.396347       0.091259       True             4               MLP_model_10_Circuit.pkl       33
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715867 0.576503       0.154763       True             4                       MLP_model_12.pkl       33
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861212 0.537306       0.016463       True             4               MLP_model_12_Circuit.pkl       33
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.692237 0.292091       0.031290       True             3                       MLP_model_15.pkl       33
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522163 0.175898       0.050968       True             4               MLP_model_15_Circuit.pkl       33
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604692 0.227465       0.048337       True             4                       MLP_model_20.pkl       33
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.610972 0.258177       0.051825       True             4               MLP_model_20_Circuit.pkl       33
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.540139 0.179253       0.099024       True             4                       MLP_model_25.pkl       33
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677333 0.218386       0.016543       True             4               MLP_model_25_Circuit.pkl       33
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616675 0.239554       0.104714       True             4                     MLP_model_full.pkl       33
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.656171 0.295485       0.020595       True             4             MLP_model_full_Circuit.pkl       33
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602425 0.268791       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710613 0.572056       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.688015 0.293328       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586115 0.229571       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.527844 0.182108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       33

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61202
 Mean Absolute Percentage Error: 0.45660
 Training time:  0.47928
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.77252
 Mean Absolute Percentage Error: 0.40394
 Training time:  0.24194
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.00072
 Mean Absolute Percentage Error: 0.67070
 Training time:  0.36488
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.11053
 Mean Absolute Percentage Error: 0.66596
 Training time:  0.23685
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.61550
 Mean Absolute Percentage Error: 0.19066
 Training time:  0.44571
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79884
 Mean Absolute Percentage Error: 0.23346
 Training time:  0.23852
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65229
 Mean Absolute Percentage Error: 0.28276
 Training time:  0.62636
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84757
 Mean Absolute Percentage Error: 0.33033
 Training time:  0.23931
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73076
 Mean Absolute Percentage Error: 0.21999
 Training time:  0.71325
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70204
 Mean Absolute Percentage Error: 0.18679
 Training time:  0.23872
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.73100
 Mean Absolute Percentage Error: 0.30357
 Training time:  2.98005
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75185
 Mean Absolute Percentage Error: 0.29940
 Training time:  0.30011
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24690
  MAPE on 10 nodes subset: 0.02610

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.33020
  MAPE on 12 nodes subset: 0.25900

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.12561
  MAPE on 15 nodes subset: 0.01378

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.37592
  MAPE on 20 nodes subset: 0.08629

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19014
  MAPE on 25 nodes subset: 0.02338

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.612017 0.456603       0.479277                           xgboost_model_10.pkl       61
       10             Circuit            50           5          4 0.772517 0.403935       0.241937                   xgboost_model_10_Circuit.pkl       61
       12            Q_values            50          78          4 1.000721 0.670696       0.364881                           xgboost_model_12.pkl       61
       12             Circuit            50           5          4 1.110534 0.665962       0.236848                   xgboost_model_12_Circuit.pkl       61
       15            Q_values            50         120          4 0.615504 0.190663       0.445710                           xgboost_model_15.pkl       61
       15             Circuit            50           5          4 0.798838 0.233461       0.238525                   xgboost_model_15_Circuit.pkl       61
       20            Q_values            50         210          4 0.652291 0.282756       0.626358                           xgboost_model_20.pkl       61
       20             Circuit            50           5          4 0.847569 0.330327       0.239306                   xgboost_model_20_Circuit.pkl       61
       25            Q_values            50         325          4 0.730759 0.219988       0.713252                           xgboost_model_25.pkl       61
       25             Circuit            50           5          4 0.702038 0.186790       0.238718                   xgboost_model_25_Circuit.pkl       61
     full            Q_values           250         325          4 0.731000 0.303573       2.980053                         xgboost_model_full.pkl       61
     full             Circuit           250           5          4 0.751851 0.299398       0.300108                 xgboost_model_full_Circuit.pkl       61
       10 Q_values_full_model            50         325          4 0.246896 0.026103       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       61
       12 Q_values_full_model            50         325          4 0.330203 0.258997       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       61
       15 Q_values_full_model            50         325          4 0.125612 0.013781       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       61
       20 Q_values_full_model            50         325          4 0.375924 0.086287       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       61
       25 Q_values_full_model            50         325          4 0.190144 0.023382       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       61

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.8228
Epoch 002, Loss: 0.6127
Epoch 003, Loss: 0.5755
Epoch 004, Loss: 0.6284
Epoch 005, Loss: 0.5968
Epoch 006, Loss: 0.5526
Epoch 007, Loss: 0.5745
Epoch 008, Loss: 0.5654
Epoch 009, Loss: 0.5926
Epoch 010, Loss: 0.5939
Epoch 011, Loss: 0.5679
Epoch 012, Loss: 0.5751
Epoch 013, Loss: 0.6138
Epoch 014, Loss: 0.5650
Epoch 015, Loss: 0.5605
Epoch 016, Loss: 0.6291
Epoch 017, Loss: 0.5982
Epoch 018, Loss: 0.5633
Epoch 019, Loss: 0.6155
Epoch 020, Loss: 0.5570
Epoch 021, Loss: 0.6283
Epoch 022, Loss: 0.5751
Epoch 023, Loss: 0.5884
Epoch 024, Loss: 0.5427
Epoch 025, Loss: 0.5862
Epoch 026, Loss: 0.6491
Epoch 027, Loss: 0.6747
Epoch 028, Loss: 0.5334
Epoch 029, Loss: 0.5703
Epoch 030, Loss: 0.6278
Epoch 031, Loss: 0.5466
Epoch 032, Loss: 0.5304
Epoch 033, Loss: 0.5198
Epoch 034, Loss: 0.5891
Epoch 035, Loss: 0.5466
Epoch 036, Loss: 0.5437
Epoch 037, Loss: 0.5273
Epoch 038, Loss: 0.5185
Epoch 039, Loss: 0.5463
Epoch 040, Loss: 0.5396
Epoch 041, Loss: 0.5105
Epoch 042, Loss: 0.5025
Epoch 043, Loss: 0.5323
Epoch 044, Loss: 0.5596
Epoch 045, Loss: 0.5582
Epoch 046, Loss: 0.5424
Epoch 047, Loss: 0.5566
Epoch 048, Loss: 0.5397
Epoch 049, Loss: 0.5017
Epoch 050, Loss: 0.5191
Epoch 051, Loss: 0.5214
Epoch 052, Loss: 0.5029
Epoch 053, Loss: 0.5031
Epoch 054, Loss: 0.5392
Epoch 055, Loss: 0.4918
Epoch 056, Loss: 0.4907
Epoch 057, Loss: 0.4917
Epoch 058, Loss: 0.4974
Epoch 059, Loss: 0.4963
Epoch 060, Loss: 0.5005
Epoch 061, Loss: 0.4933
Epoch 062, Loss: 0.5053
Epoch 063, Loss: 0.4834
Epoch 064, Loss: 0.5053
Epoch 065, Loss: 0.4801
Epoch 066, Loss: 0.4647
Epoch 067, Loss: 0.4751
Epoch 068, Loss: 0.4792
Epoch 069, Loss: 0.4748
Epoch 070, Loss: 0.5078
Epoch 071, Loss: 0.4868
Epoch 072, Loss: 0.5026
Epoch 073, Loss: 0.4989
Epoch 074, Loss: 0.4671
Epoch 075, Loss: 0.4806
Epoch 076, Loss: 0.4763
Epoch 077, Loss: 0.4697
Epoch 078, Loss: 0.4510
Epoch 079, Loss: 0.4780
Epoch 080, Loss: 0.4618
Epoch 081, Loss: 0.4644
Epoch 082, Loss: 0.4594
Epoch 083, Loss: 0.4755
Epoch 084, Loss: 0.4548
Epoch 085, Loss: 0.4499
Epoch 086, Loss: 0.4387
Epoch 087, Loss: 0.4646
Epoch 088, Loss: 0.4426
Epoch 089, Loss: 0.4301
Epoch 090, Loss: 0.4236
Epoch 091, Loss: 0.4300
Epoch 092, Loss: 0.4288
Epoch 093, Loss: 0.4178
Epoch 094, Loss: 0.4192
Epoch 095, Loss: 0.4064
Epoch 096, Loss: 0.4035
Epoch 097, Loss: 0.4120
Epoch 098, Loss: 0.4144
Epoch 099, Loss: 0.4062
Epoch 100, Loss: 0.3980

Test RMSE: 0.6079
Test MAPE: 0.2108
Training time: 12.32 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 4.3255
Epoch 002, Loss: 0.9917
Epoch 003, Loss: 0.8135
Epoch 004, Loss: 0.8682
Epoch 005, Loss: 0.9149
Epoch 006, Loss: 0.8356
Epoch 007, Loss: 0.8526
Epoch 008, Loss: 0.8303
Epoch 009, Loss: 0.8593
Epoch 010, Loss: 0.8932
Epoch 011, Loss: 0.9338
Epoch 012, Loss: 0.9696
Epoch 013, Loss: 0.8248
Epoch 014, Loss: 0.8487
Epoch 015, Loss: 0.8500
Epoch 016, Loss: 0.8484
Epoch 017, Loss: 0.8173
Epoch 018, Loss: 0.8146
Epoch 019, Loss: 0.8189
Epoch 020, Loss: 0.8262
Epoch 021, Loss: 0.8103
Epoch 022, Loss: 0.8665
Epoch 023, Loss: 0.8365
Epoch 024, Loss: 0.8637
Epoch 025, Loss: 0.8589
Epoch 026, Loss: 0.8554
Epoch 027, Loss: 0.8517
Epoch 028, Loss: 0.8457
Epoch 029, Loss: 0.8254
Epoch 030, Loss: 0.8295
Epoch 031, Loss: 0.8071
Epoch 032, Loss: 0.8304
Epoch 033, Loss: 0.8399
Epoch 034, Loss: 0.8296
Epoch 035, Loss: 0.8555
Epoch 036, Loss: 0.8340
Epoch 037, Loss: 0.8130
Epoch 038, Loss: 0.8275
Epoch 039, Loss: 0.8238
Epoch 040, Loss: 0.8510
Epoch 041, Loss: 0.7879
Epoch 042, Loss: 0.8561
Epoch 043, Loss: 0.7882
Epoch 044, Loss: 0.8473
Epoch 045, Loss: 0.8206
Epoch 046, Loss: 0.9392
Epoch 047, Loss: 0.8355
Epoch 048, Loss: 0.8573
Epoch 049, Loss: 0.8122
Epoch 050, Loss: 0.8548
Epoch 051, Loss: 0.8447
Epoch 052, Loss: 0.8182
Epoch 053, Loss: 0.8740
Epoch 054, Loss: 0.9177
Epoch 055, Loss: 0.8696
Epoch 056, Loss: 0.8371
Epoch 057, Loss: 0.8347
Epoch 058, Loss: 0.8087
Epoch 059, Loss: 0.8162
Epoch 060, Loss: 0.8151
Epoch 061, Loss: 0.8312
Epoch 062, Loss: 0.8242
Epoch 063, Loss: 0.8807
Epoch 064, Loss: 0.8531
Epoch 065, Loss: 0.8192
Epoch 066, Loss: 0.7961
Epoch 067, Loss: 0.7919
Epoch 068, Loss: 0.7988
Epoch 069, Loss: 0.8167
Epoch 070, Loss: 0.8074
Epoch 071, Loss: 0.8010
Epoch 072, Loss: 0.8084
Epoch 073, Loss: 0.7977
Epoch 074, Loss: 0.8291
Epoch 075, Loss: 0.8001
Epoch 076, Loss: 0.8107
Epoch 077, Loss: 0.7892
Epoch 078, Loss: 0.8173
Epoch 079, Loss: 0.8017
Epoch 080, Loss: 0.8274
Epoch 081, Loss: 0.8248
Epoch 082, Loss: 0.8029
Epoch 083, Loss: 0.7862
Epoch 084, Loss: 0.7914
Epoch 085, Loss: 0.8533
Epoch 086, Loss: 0.7789
Epoch 087, Loss: 0.8024
Epoch 088, Loss: 0.8102
Epoch 089, Loss: 0.8238
Epoch 090, Loss: 0.8043
Epoch 091, Loss: 0.7853
Epoch 092, Loss: 0.8051
Epoch 093, Loss: 0.7944
Epoch 094, Loss: 0.8092
Epoch 095, Loss: 0.8488
Epoch 096, Loss: 0.7978
Epoch 097, Loss: 0.7914
Epoch 098, Loss: 0.7922
Epoch 099, Loss: 0.7851
Epoch 100, Loss: 0.7759

Test RMSE: 0.7434
Test MAPE: 0.2304
Training time: 12.27 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 5.4279
Epoch 002, Loss: 0.9836
Epoch 003, Loss: 0.9830
Epoch 004, Loss: 0.9470
Epoch 005, Loss: 1.0741
Epoch 006, Loss: 1.0118
Epoch 007, Loss: 0.9711
Epoch 008, Loss: 0.9165
Epoch 009, Loss: 0.9899
Epoch 010, Loss: 0.9936
Epoch 011, Loss: 0.9046
Epoch 012, Loss: 0.8961
Epoch 013, Loss: 0.8945
Epoch 014, Loss: 0.9270
Epoch 015, Loss: 0.9088
Epoch 016, Loss: 1.0317
Epoch 017, Loss: 1.0472
Epoch 018, Loss: 1.0000
Epoch 019, Loss: 0.9039
Epoch 020, Loss: 1.0086
Epoch 021, Loss: 1.0153
Epoch 022, Loss: 0.9381
Epoch 023, Loss: 0.9636
Epoch 024, Loss: 0.8690
Epoch 025, Loss: 0.8947
Epoch 026, Loss: 0.9002
Epoch 027, Loss: 0.9691
Epoch 028, Loss: 0.8900
Epoch 029, Loss: 0.9298
Epoch 030, Loss: 0.9463
Epoch 031, Loss: 1.0126
Epoch 032, Loss: 0.9031
Epoch 033, Loss: 0.8687
Epoch 034, Loss: 0.8731
Epoch 035, Loss: 0.9191
Epoch 036, Loss: 0.9646
Epoch 037, Loss: 0.8920
Epoch 038, Loss: 0.8970
Epoch 039, Loss: 0.9670
Epoch 040, Loss: 0.9105
Epoch 041, Loss: 0.8807
Epoch 042, Loss: 0.9042
Epoch 043, Loss: 0.9290
Epoch 044, Loss: 0.9067
Epoch 045, Loss: 0.9129
Epoch 046, Loss: 0.9031
Epoch 047, Loss: 0.8875
Epoch 048, Loss: 0.8929
Epoch 049, Loss: 0.9370
Epoch 050, Loss: 0.8882
Epoch 051, Loss: 0.8663
Epoch 052, Loss: 0.9026
Epoch 053, Loss: 0.8335
Epoch 054, Loss: 0.8585
Epoch 055, Loss: 0.8273
Epoch 056, Loss: 0.8486
Epoch 057, Loss: 0.7897
Epoch 058, Loss: 0.7787
Epoch 059, Loss: 0.8030
Epoch 060, Loss: 0.9243
Epoch 061, Loss: 0.7970
Epoch 062, Loss: 0.7698
Epoch 063, Loss: 0.7725
Epoch 064, Loss: 0.8099
Epoch 065, Loss: 0.7645
Epoch 066, Loss: 0.7846
Epoch 067, Loss: 0.7644
Epoch 068, Loss: 0.8188
Epoch 069, Loss: 0.7826
Epoch 070, Loss: 0.7673
Epoch 071, Loss: 0.7930
Epoch 072, Loss: 0.7961
Epoch 073, Loss: 0.7390
Epoch 074, Loss: 0.7266
Epoch 075, Loss: 0.7044
Epoch 076, Loss: 0.7186
Epoch 077, Loss: 0.7339
Epoch 078, Loss: 0.6979
Epoch 079, Loss: 0.7286
Epoch 080, Loss: 0.7039
Epoch 081, Loss: 0.6691
Epoch 082, Loss: 0.6762
Epoch 083, Loss: 0.6560
Epoch 084, Loss: 0.6697
Epoch 085, Loss: 0.6868
Epoch 086, Loss: 0.6291
Epoch 087, Loss: 0.6807
Epoch 088, Loss: 0.6193
Epoch 089, Loss: 0.6747
Epoch 090, Loss: 0.6584
Epoch 091, Loss: 0.6451
Epoch 092, Loss: 0.6207
Epoch 093, Loss: 0.6322
Epoch 094, Loss: 0.6514
Epoch 095, Loss: 0.6494
Epoch 096, Loss: 0.7286
Epoch 097, Loss: 0.6292
Epoch 098, Loss: 0.6748
Epoch 099, Loss: 0.6588
Epoch 100, Loss: 0.6290

Test RMSE: 0.8824
Test MAPE: 0.2235
Training time: 12.44 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.7135
Epoch 002, Loss: 1.3750
Epoch 003, Loss: 1.3023
Epoch 004, Loss: 1.2041
Epoch 005, Loss: 1.4037
Epoch 006, Loss: 1.4417
Epoch 007, Loss: 1.3559
Epoch 008, Loss: 1.2754
Epoch 009, Loss: 1.3630
Epoch 010, Loss: 1.5351
Epoch 011, Loss: 1.2211
Epoch 012, Loss: 1.3357
Epoch 013, Loss: 1.3791
Epoch 014, Loss: 1.4258
Epoch 015, Loss: 1.2894
Epoch 016, Loss: 1.1998
Epoch 017, Loss: 1.2724
Epoch 018, Loss: 1.3110
Epoch 019, Loss: 1.2067
Epoch 020, Loss: 1.2802
Epoch 021, Loss: 1.2425
Epoch 022, Loss: 1.2943
Epoch 023, Loss: 1.2393
Epoch 024, Loss: 1.3082
Epoch 025, Loss: 1.2576
Epoch 026, Loss: 1.4238
Epoch 027, Loss: 1.4240
Epoch 028, Loss: 1.4892
Epoch 029, Loss: 1.3493
Epoch 030, Loss: 1.4339
Epoch 031, Loss: 1.2090
Epoch 032, Loss: 1.2681
Epoch 033, Loss: 1.3046
Epoch 034, Loss: 1.3060
Epoch 035, Loss: 1.2759
Epoch 036, Loss: 1.2262
Epoch 037, Loss: 1.1613
Epoch 038, Loss: 1.2653
Epoch 039, Loss: 1.2457
Epoch 040, Loss: 1.1834
Epoch 041, Loss: 1.2512
Epoch 042, Loss: 1.2018
Epoch 043, Loss: 1.2058
Epoch 044, Loss: 1.1348
Epoch 045, Loss: 1.1813
Epoch 046, Loss: 1.1965
Epoch 047, Loss: 1.1777
Epoch 048, Loss: 1.1528
Epoch 049, Loss: 1.0212
Epoch 050, Loss: 1.5757
Epoch 051, Loss: 1.2172
Epoch 052, Loss: 1.1645
Epoch 053, Loss: 1.1761
Epoch 054, Loss: 1.1752
Epoch 055, Loss: 1.1828
Epoch 056, Loss: 1.1861
Epoch 057, Loss: 1.1262
Epoch 058, Loss: 1.1751
Epoch 059, Loss: 1.1175
Epoch 060, Loss: 1.1020
Epoch 061, Loss: 1.2029
Epoch 062, Loss: 1.2059
Epoch 063, Loss: 1.1939
Epoch 064, Loss: 1.1961
Epoch 065, Loss: 1.1341
Epoch 066, Loss: 1.1246
Epoch 067, Loss: 1.2357
Epoch 068, Loss: 1.1024
Epoch 069, Loss: 1.0329
Epoch 070, Loss: 1.0551
Epoch 071, Loss: 0.9782
Epoch 072, Loss: 1.0100
Epoch 073, Loss: 1.0118
Epoch 074, Loss: 1.0282
Epoch 075, Loss: 0.9724
Epoch 076, Loss: 0.9448
Epoch 077, Loss: 0.8198
Epoch 078, Loss: 0.8710
Epoch 079, Loss: 0.8751
Epoch 080, Loss: 0.8428
Epoch 081, Loss: 0.8488
Epoch 082, Loss: 0.8595
Epoch 083, Loss: 0.7994
Epoch 084, Loss: 0.7536
Epoch 085, Loss: 0.8969
Epoch 086, Loss: 0.8318
Epoch 087, Loss: 0.8166
Epoch 088, Loss: 0.8142
Epoch 089, Loss: 0.7440
Epoch 090, Loss: 0.7542
Epoch 091, Loss: 0.7925
Epoch 092, Loss: 0.6852
Epoch 093, Loss: 0.6676
Epoch 094, Loss: 0.6294
Epoch 095, Loss: 0.6868
Epoch 096, Loss: 0.7169
Epoch 097, Loss: 0.6377
Epoch 098, Loss: 0.7633
Epoch 099, Loss: 0.6009
Epoch 100, Loss: 0.5733

Test RMSE: 0.9379
Test MAPE: 0.2394
Training time: 13.00 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 11.2248
Epoch 002, Loss: 1.6285
Epoch 003, Loss: 1.6864
Epoch 004, Loss: 1.7491
Epoch 005, Loss: 1.5147
Epoch 006, Loss: 1.7012
Epoch 007, Loss: 1.7004
Epoch 008, Loss: 1.7403
Epoch 009, Loss: 1.7636
Epoch 010, Loss: 1.5802
Epoch 011, Loss: 1.5023
Epoch 012, Loss: 1.5290
Epoch 013, Loss: 1.4439
Epoch 014, Loss: 1.6697
Epoch 015, Loss: 1.6648
Epoch 016, Loss: 1.4810
Epoch 017, Loss: 1.8575
Epoch 018, Loss: 1.5746
Epoch 019, Loss: 1.6392
Epoch 020, Loss: 1.5381
Epoch 021, Loss: 1.7613
Epoch 022, Loss: 1.6325
Epoch 023, Loss: 1.7293
Epoch 024, Loss: 1.4662
Epoch 025, Loss: 1.5588
Epoch 026, Loss: 1.6405
Epoch 027, Loss: 1.4676
Epoch 028, Loss: 1.4067
Epoch 029, Loss: 1.9049
Epoch 030, Loss: 1.5320
Epoch 031, Loss: 1.5514
Epoch 032, Loss: 1.7016
Epoch 033, Loss: 1.6232
Epoch 034, Loss: 1.5714
Epoch 035, Loss: 1.5714
Epoch 036, Loss: 1.6228
Epoch 037, Loss: 1.3870
Epoch 038, Loss: 1.7040
Epoch 039, Loss: 1.4593
Epoch 040, Loss: 1.4284
Epoch 041, Loss: 1.5771
Epoch 042, Loss: 1.5056
Epoch 043, Loss: 1.5258
Epoch 044, Loss: 1.5681
Epoch 045, Loss: 1.4739
Epoch 046, Loss: 1.6717
Epoch 047, Loss: 1.7261
Epoch 048, Loss: 1.4232
Epoch 049, Loss: 1.6376
Epoch 050, Loss: 1.6581
Epoch 051, Loss: 1.8052
Epoch 052, Loss: 1.4152
Epoch 053, Loss: 1.4136
Epoch 054, Loss: 1.5545
Epoch 055, Loss: 1.4343
Epoch 056, Loss: 1.4673
Epoch 057, Loss: 1.4425
Epoch 058, Loss: 1.5454
Epoch 059, Loss: 1.6626
Epoch 060, Loss: 1.3615
Epoch 061, Loss: 1.4741
Epoch 062, Loss: 1.4343
Epoch 063, Loss: 1.4231
Epoch 064, Loss: 1.5096
Epoch 065, Loss: 1.5285
Epoch 066, Loss: 1.5733
Epoch 067, Loss: 1.4047
Epoch 068, Loss: 1.4847
Epoch 069, Loss: 1.7291
Epoch 070, Loss: 1.6983
Epoch 071, Loss: 1.6727
Epoch 072, Loss: 1.5794
Epoch 073, Loss: 1.7067
Epoch 074, Loss: 1.6340
Epoch 075, Loss: 1.4087
Epoch 076, Loss: 1.4285
Epoch 077, Loss: 1.5082
Epoch 078, Loss: 1.4484
Epoch 079, Loss: 1.5063
Epoch 080, Loss: 1.3753
Epoch 081, Loss: 1.4576
Epoch 082, Loss: 1.5878
Epoch 083, Loss: 1.4070
Epoch 084, Loss: 1.5301
Epoch 085, Loss: 1.4447
Epoch 086, Loss: 1.5318
Epoch 087, Loss: 1.4334
Epoch 088, Loss: 1.4621
Epoch 089, Loss: 1.5495
Epoch 090, Loss: 1.4127
Epoch 091, Loss: 1.8210
Epoch 092, Loss: 1.4034
Epoch 093, Loss: 1.4906
Epoch 094, Loss: 1.5709
Epoch 095, Loss: 1.4710
Epoch 096, Loss: 1.4594
Epoch 097, Loss: 1.3407
Epoch 098, Loss: 1.4364
Epoch 099, Loss: 1.3957
Epoch 100, Loss: 1.4416

Test RMSE: 1.5341
Test MAPE: 0.2318
Training time: 13.25 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7537
Epoch 002, Loss: 3.2519
Epoch 003, Loss: 1.9744
Epoch 004, Loss: 0.8986
Epoch 005, Loss: 0.8284
Epoch 006, Loss: 0.7010
Epoch 007, Loss: 0.8370
Epoch 008, Loss: 0.6702
Epoch 009, Loss: 0.6416
Epoch 010, Loss: 0.7366
Epoch 011, Loss: 0.6825
Epoch 012, Loss: 0.6298
Epoch 013, Loss: 0.7154
Epoch 014, Loss: 0.6570
Epoch 015, Loss: 0.6768
Epoch 016, Loss: 0.7267
Epoch 017, Loss: 0.6173
Epoch 018, Loss: 0.6342
Epoch 019, Loss: 0.6027
Epoch 020, Loss: 0.6657
Epoch 021, Loss: 0.5688
Epoch 022, Loss: 0.6349
Epoch 023, Loss: 0.6052
Epoch 024, Loss: 0.6158
Epoch 025, Loss: 0.6368
Epoch 026, Loss: 0.6415
Epoch 027, Loss: 0.6386
Epoch 028, Loss: 0.5917
Epoch 029, Loss: 0.6068
Epoch 030, Loss: 0.5855
Epoch 031, Loss: 0.6203
Epoch 032, Loss: 0.5817
Epoch 033, Loss: 0.6079
Epoch 034, Loss: 0.6357
Epoch 035, Loss: 0.6131
Epoch 036, Loss: 0.6210
Epoch 037, Loss: 0.5503
Epoch 038, Loss: 0.6081
Epoch 039, Loss: 0.5639
Epoch 040, Loss: 0.6198
Epoch 041, Loss: 0.5446
Epoch 042, Loss: 0.6022
Epoch 043, Loss: 0.6001
Epoch 044, Loss: 0.5950
Epoch 045, Loss: 0.5390
Epoch 046, Loss: 0.5641
Epoch 047, Loss: 0.5866
Epoch 048, Loss: 0.5786
Epoch 049, Loss: 0.5802
Epoch 050, Loss: 0.5795
Epoch 051, Loss: 0.5457
Epoch 052, Loss: 0.5873
Epoch 053, Loss: 0.5494
Epoch 054, Loss: 0.5959
Epoch 055, Loss: 0.5839
Epoch 056, Loss: 0.5470
Epoch 057, Loss: 0.6146
Epoch 058, Loss: 0.5737
Epoch 059, Loss: 0.5625
Epoch 060, Loss: 0.5368
Epoch 061, Loss: 0.5362
Epoch 062, Loss: 0.5498
Epoch 063, Loss: 0.5356
Epoch 064, Loss: 0.5868
Epoch 065, Loss: 0.5560
Epoch 066, Loss: 0.5219
Epoch 067, Loss: 0.5390
Epoch 068, Loss: 0.5697
Epoch 069, Loss: 0.5634
Epoch 070, Loss: 0.5441
Epoch 071, Loss: 0.5391
Epoch 072, Loss: 0.5189
Epoch 073, Loss: 0.5454
Epoch 074, Loss: 0.5092
Epoch 075, Loss: 0.5361
Epoch 076, Loss: 0.5308
Epoch 077, Loss: 0.5875
Epoch 078, Loss: 0.5215
Epoch 079, Loss: 0.5191
Epoch 080, Loss: 0.5297
Epoch 081, Loss: 0.5429
Epoch 082, Loss: 0.5256
Epoch 083, Loss: 0.5051
Epoch 084, Loss: 0.5319
Epoch 085, Loss: 0.5026
Epoch 086, Loss: 0.5292
Epoch 087, Loss: 0.5257
Epoch 088, Loss: 0.5622
Epoch 089, Loss: 0.5381
Epoch 090, Loss: 0.6022
Epoch 091, Loss: 0.5027
Epoch 092, Loss: 0.5218
Epoch 093, Loss: 0.5049
Epoch 094, Loss: 0.5295
Epoch 095, Loss: 0.5588
Epoch 096, Loss: 0.5067
Epoch 097, Loss: 0.5175
Epoch 098, Loss: 0.5182
Epoch 099, Loss: 0.5291
Epoch 100, Loss: 0.5613

Test RMSE: 0.6669
Test MAPE: 406751924977664.0000
Training time: 64.26 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.607918 2.107902e-01      12.322745   GNN_model_10.pkl
       12   Q_values        0.2 0.743401 2.303590e-01      12.268132   GNN_model_12.pkl
       15   Q_values        0.2 0.882391 2.235328e-01      12.442297   GNN_model_15.pkl
       20   Q_values        0.2 0.937874 2.393654e-01      12.997588   GNN_model_20.pkl
       25   Q_values        0.2 1.534102 2.317954e-01      13.254787   GNN_model_25.pkl
     full   Q_values        0.2 0.666923 4.067519e+14      64.257843 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 61%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 51%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
