
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59793
 Mean Absolute Percentage Error: 0.25575
 Training time:  0.07281
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55265
 Mean Absolute Percentage Error: 0.39853
 Training time:  0.07661
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71611
 Mean Absolute Percentage Error: 0.57765
 Training time:  0.17388
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86339
 Mean Absolute Percentage Error: 0.54084
 Training time:  0.06315
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70435
 Mean Absolute Percentage Error: 0.30286
 Training time:  0.12031
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52259
 Mean Absolute Percentage Error: 0.17753
 Training time:  0.14973
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60380
 Mean Absolute Percentage Error: 0.22760
 Training time:  0.11107
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61190
 Mean Absolute Percentage Error: 0.26006
 Training time:  0.10539
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53789
 Mean Absolute Percentage Error: 0.17757
 Training time:  0.19091
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67359
 Mean Absolute Percentage Error: 0.21888
 Training time:  0.03396
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61730
 Mean Absolute Percentage Error: 0.23938
 Training time:  0.17780
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65466
 Mean Absolute Percentage Error: 0.29725
 Training time:  0.05255
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60078
  MAPE on 10 nodes subset: 0.26687

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71159
  MAPE on 12 nodes subset: 0.57044

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68332
  MAPE on 15 nodes subset: 0.28820

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58595
  MAPE on 20 nodes subset: 0.22693

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53534
  MAPE on 25 nodes subset: 0.18818

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597930 0.255749       0.072809       True             4                       MLP_model_10.pkl       39
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552653 0.398530       0.076610       True             4               MLP_model_10_Circuit.pkl       39
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.716114 0.577646       0.173876       True             4                       MLP_model_12.pkl       39
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863388 0.540840       0.063154       True             4               MLP_model_12_Circuit.pkl       39
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704350 0.302856       0.120305       True             4                       MLP_model_15.pkl       39
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522593 0.177532       0.149733       True             4               MLP_model_15_Circuit.pkl       39
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.603797 0.227602       0.111070       True             4                       MLP_model_20.pkl       39
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611904 0.260057       0.105391       True             4               MLP_model_20_Circuit.pkl       39
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.537894 0.177575       0.190913       True             4                       MLP_model_25.pkl       39
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.673593 0.218881       0.033957       True             4               MLP_model_25_Circuit.pkl       39
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617299 0.239378       0.177801       True             4                     MLP_model_full.pkl       39
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654661 0.297250       0.052554       True             4             MLP_model_full_Circuit.pkl       39
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.600777 0.266869       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       39
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.711591 0.570436       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       39
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.683322 0.288200       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       39
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585954 0.226930       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       39
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.535342 0.188185       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       39

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59867
 Mean Absolute Percentage Error: 0.43014
 Training time:  0.45086
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75251
 Mean Absolute Percentage Error: 0.38868
 Training time:  0.37354
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.00848
 Mean Absolute Percentage Error: 0.66781
 Training time:  0.48858
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.09989
 Mean Absolute Percentage Error: 0.65794
 Training time:  0.37310
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.61296
 Mean Absolute Percentage Error: 0.19588
 Training time:  0.56938
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80437
 Mean Absolute Percentage Error: 0.23391
 Training time:  0.37588
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.67931
 Mean Absolute Percentage Error: 0.29077
 Training time:  0.76716
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85231
 Mean Absolute Percentage Error: 0.32999
 Training time:  0.37700
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73743
 Mean Absolute Percentage Error: 0.23193
 Training time:  0.92191
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69551
 Mean Absolute Percentage Error: 0.19188
 Training time:  0.38242
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71702
 Mean Absolute Percentage Error: 0.30330
 Training time:  3.59030
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75388
 Mean Absolute Percentage Error: 0.30085
 Training time:  0.44906
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.21060
  MAPE on 10 nodes subset: 0.02512

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.31553
  MAPE on 12 nodes subset: 0.24804

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13965
  MAPE on 15 nodes subset: 0.01665

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.38193
  MAPE on 20 nodes subset: 0.08415

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19782
  MAPE on 25 nodes subset: 0.02712

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.598672 0.430139       0.450859                           xgboost_model_10.pkl       11
       10             Circuit            50           5          4 0.752507 0.388676       0.373536                   xgboost_model_10_Circuit.pkl       11
       12            Q_values            50          78          4 1.008478 0.667812       0.488581                           xgboost_model_12.pkl       11
       12             Circuit            50           5          4 1.099890 0.657939       0.373097                   xgboost_model_12_Circuit.pkl       11
       15            Q_values            50         120          4 0.612956 0.195884       0.569380                           xgboost_model_15.pkl       11
       15             Circuit            50           5          4 0.804368 0.233907       0.375884                   xgboost_model_15_Circuit.pkl       11
       20            Q_values            50         210          4 0.679308 0.290774       0.767156                           xgboost_model_20.pkl       11
       20             Circuit            50           5          4 0.852306 0.329991       0.377002                   xgboost_model_20_Circuit.pkl       11
       25            Q_values            50         325          4 0.737435 0.231930       0.921911                           xgboost_model_25.pkl       11
       25             Circuit            50           5          4 0.695514 0.191879       0.382425                   xgboost_model_25_Circuit.pkl       11
     full            Q_values           250         325          4 0.717024 0.303296       3.590296                         xgboost_model_full.pkl       11
     full             Circuit           250           5          4 0.753883 0.300846       0.449056                 xgboost_model_full_Circuit.pkl       11
       10 Q_values_full_model            50         325          4 0.210596 0.025120       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       11
       12 Q_values_full_model            50         325          4 0.315534 0.248039       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       11
       15 Q_values_full_model            50         325          4 0.139645 0.016652       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       11
       20 Q_values_full_model            50         325          4 0.381932 0.084151       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       11
       25 Q_values_full_model            50         325          4 0.197819 0.027120       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       11

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.9987
Epoch 002, Loss: 0.6742
Epoch 003, Loss: 0.5889
Epoch 004, Loss: 0.6172
Epoch 005, Loss: 0.6037
Epoch 006, Loss: 0.5590
Epoch 007, Loss: 0.5791
Epoch 008, Loss: 0.6556
Epoch 009, Loss: 0.5591
Epoch 010, Loss: 0.5838
Epoch 011, Loss: 0.5932
Epoch 012, Loss: 0.6047
Epoch 013, Loss: 0.6379
Epoch 014, Loss: 0.6254
Epoch 015, Loss: 0.6078
Epoch 016, Loss: 0.5516
Epoch 017, Loss: 0.5598
Epoch 018, Loss: 0.5736
Epoch 019, Loss: 0.5832
Epoch 020, Loss: 0.5383
Epoch 021, Loss: 0.5592
Epoch 022, Loss: 0.5518
Epoch 023, Loss: 0.5583
Epoch 024, Loss: 0.5608
Epoch 025, Loss: 0.5592
Epoch 026, Loss: 0.5566
Epoch 027, Loss: 0.5813
Epoch 028, Loss: 0.6689
Epoch 029, Loss: 0.5904
Epoch 030, Loss: 0.5745
Epoch 031, Loss: 0.5668
Epoch 032, Loss: 0.5531
Epoch 033, Loss: 0.5706
Epoch 034, Loss: 0.5240
Epoch 035, Loss: 0.5362
Epoch 036, Loss: 0.5388
Epoch 037, Loss: 0.5615
Epoch 038, Loss: 0.5527
Epoch 039, Loss: 0.5273
Epoch 040, Loss: 0.5036
Epoch 041, Loss: 0.5560
Epoch 042, Loss: 0.5213
Epoch 043, Loss: 0.5146
Epoch 044, Loss: 0.5315
Epoch 045, Loss: 0.4969
Epoch 046, Loss: 0.5189
Epoch 047, Loss: 0.5459
Epoch 048, Loss: 0.5317
Epoch 049, Loss: 0.4944
Epoch 050, Loss: 0.5080
Epoch 051, Loss: 0.5187
Epoch 052, Loss: 0.5163
Epoch 053, Loss: 0.4947
Epoch 054, Loss: 0.5103
Epoch 055, Loss: 0.4960
Epoch 056, Loss: 0.4930
Epoch 057, Loss: 0.5069
Epoch 058, Loss: 0.5010
Epoch 059, Loss: 0.5099
Epoch 060, Loss: 0.4937
Epoch 061, Loss: 0.5087
Epoch 062, Loss: 0.4918
Epoch 063, Loss: 0.4882
Epoch 064, Loss: 0.5046
Epoch 065, Loss: 0.4922
Epoch 066, Loss: 0.4977
Epoch 067, Loss: 0.4839
Epoch 068, Loss: 0.5005
Epoch 069, Loss: 0.4920
Epoch 070, Loss: 0.4884
Epoch 071, Loss: 0.4789
Epoch 072, Loss: 0.4846
Epoch 073, Loss: 0.4762
Epoch 074, Loss: 0.4730
Epoch 075, Loss: 0.4620
Epoch 076, Loss: 0.4611
Epoch 077, Loss: 0.4629
Epoch 078, Loss: 0.4574
Epoch 079, Loss: 0.4643
Epoch 080, Loss: 0.4492
Epoch 081, Loss: 0.4500
Epoch 082, Loss: 0.4674
Epoch 083, Loss: 0.4476
Epoch 084, Loss: 0.4874
Epoch 085, Loss: 0.4477
Epoch 086, Loss: 0.4743
Epoch 087, Loss: 0.4465
Epoch 088, Loss: 0.4257
Epoch 089, Loss: 0.4348
Epoch 090, Loss: 0.4537
Epoch 091, Loss: 0.4304
Epoch 092, Loss: 0.4232
Epoch 093, Loss: 0.4215
Epoch 094, Loss: 0.4463
Epoch 095, Loss: 0.4289
Epoch 096, Loss: 0.4241
Epoch 097, Loss: 0.4471
Epoch 098, Loss: 0.4231
Epoch 099, Loss: 0.4223
Epoch 100, Loss: 0.4572

Test RMSE: 0.6660
Test MAPE: 0.2260
Training time: 19.22 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 4.2418
Epoch 002, Loss: 0.8222
Epoch 003, Loss: 0.8316
Epoch 004, Loss: 0.8796
Epoch 005, Loss: 0.8381
Epoch 006, Loss: 0.8643
Epoch 007, Loss: 0.8040
Epoch 008, Loss: 0.9031
Epoch 009, Loss: 0.8680
Epoch 010, Loss: 0.8313
Epoch 011, Loss: 0.9052
Epoch 012, Loss: 0.8796
Epoch 013, Loss: 0.8465
Epoch 014, Loss: 0.9492
Epoch 015, Loss: 0.8645
Epoch 016, Loss: 0.8988
Epoch 017, Loss: 0.8629
Epoch 018, Loss: 0.8475
Epoch 019, Loss: 0.8215
Epoch 020, Loss: 0.8376
Epoch 021, Loss: 0.8436
Epoch 022, Loss: 0.8221
Epoch 023, Loss: 0.8436
Epoch 024, Loss: 0.8550
Epoch 025, Loss: 0.8747
Epoch 026, Loss: 0.7976
Epoch 027, Loss: 0.8114
Epoch 028, Loss: 0.7806
Epoch 029, Loss: 0.9233
Epoch 030, Loss: 0.8292
Epoch 031, Loss: 0.9055
Epoch 032, Loss: 0.9102
Epoch 033, Loss: 0.8925
Epoch 034, Loss: 0.9139
Epoch 035, Loss: 0.8385
Epoch 036, Loss: 0.8146
Epoch 037, Loss: 0.8150
Epoch 038, Loss: 0.8785
Epoch 039, Loss: 0.8351
Epoch 040, Loss: 0.8425
Epoch 041, Loss: 0.7985
Epoch 042, Loss: 0.8232
Epoch 043, Loss: 0.8227
Epoch 044, Loss: 0.7857
Epoch 045, Loss: 0.8808
Epoch 046, Loss: 0.8618
Epoch 047, Loss: 0.7953
Epoch 048, Loss: 0.7452
Epoch 049, Loss: 0.8554
Epoch 050, Loss: 0.7844
Epoch 051, Loss: 0.7897
Epoch 052, Loss: 0.8280
Epoch 053, Loss: 0.7854
Epoch 054, Loss: 0.8344
Epoch 055, Loss: 0.7748
Epoch 056, Loss: 0.7852
Epoch 057, Loss: 0.7480
Epoch 058, Loss: 0.8399
Epoch 059, Loss: 0.7584
Epoch 060, Loss: 0.7417
Epoch 061, Loss: 0.7665
Epoch 062, Loss: 0.7629
Epoch 063, Loss: 0.7532
Epoch 064, Loss: 0.7730
Epoch 065, Loss: 0.7291
Epoch 066, Loss: 0.7136
Epoch 067, Loss: 0.7276
Epoch 068, Loss: 0.7466
Epoch 069, Loss: 0.7116
Epoch 070, Loss: 0.6967
Epoch 071, Loss: 0.7528
Epoch 072, Loss: 0.7136
Epoch 073, Loss: 0.7013
Epoch 074, Loss: 0.7223
Epoch 075, Loss: 0.6816
Epoch 076, Loss: 0.6683
Epoch 077, Loss: 0.6569
Epoch 078, Loss: 0.6840
Epoch 079, Loss: 0.6670
Epoch 080, Loss: 0.6512
Epoch 081, Loss: 0.6538
Epoch 082, Loss: 0.6435
Epoch 083, Loss: 0.6680
Epoch 084, Loss: 0.6484
Epoch 085, Loss: 0.6244
Epoch 086, Loss: 0.6239
Epoch 087, Loss: 0.6260
Epoch 088, Loss: 0.6511
Epoch 089, Loss: 0.6262
Epoch 090, Loss: 0.6109
Epoch 091, Loss: 0.6135
Epoch 092, Loss: 0.6153
Epoch 093, Loss: 0.6010
Epoch 094, Loss: 0.5589
Epoch 095, Loss: 0.6185
Epoch 096, Loss: 0.5902
Epoch 097, Loss: 0.6158
Epoch 098, Loss: 0.6405
Epoch 099, Loss: 0.6231
Epoch 100, Loss: 0.5760

Test RMSE: 0.8829
Test MAPE: 0.2788
Training time: 16.67 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.0414
Epoch 002, Loss: 0.9901
Epoch 003, Loss: 0.9573
Epoch 004, Loss: 0.9411
Epoch 005, Loss: 1.0294
Epoch 006, Loss: 1.1069
Epoch 007, Loss: 1.0598
Epoch 008, Loss: 0.9823
Epoch 009, Loss: 0.9543
Epoch 010, Loss: 0.9722
Epoch 011, Loss: 0.9195
Epoch 012, Loss: 0.9988
Epoch 013, Loss: 0.9013
Epoch 014, Loss: 0.9544
Epoch 015, Loss: 0.9001
Epoch 016, Loss: 0.9337
Epoch 017, Loss: 0.9214
Epoch 018, Loss: 0.8922
Epoch 019, Loss: 0.9498
Epoch 020, Loss: 0.8850
Epoch 021, Loss: 1.0864
Epoch 022, Loss: 0.9130
Epoch 023, Loss: 0.9351
Epoch 024, Loss: 0.9407
Epoch 025, Loss: 0.8853
Epoch 026, Loss: 0.9708
Epoch 027, Loss: 0.8709
Epoch 028, Loss: 0.9246
Epoch 029, Loss: 0.9013
Epoch 030, Loss: 0.8874
Epoch 031, Loss: 0.9032
Epoch 032, Loss: 0.8783
Epoch 033, Loss: 0.9233
Epoch 034, Loss: 0.9187
Epoch 035, Loss: 0.9201
Epoch 036, Loss: 0.8909
Epoch 037, Loss: 0.8607
Epoch 038, Loss: 0.9385
Epoch 039, Loss: 1.0200
Epoch 040, Loss: 0.8816
Epoch 041, Loss: 0.8589
Epoch 042, Loss: 0.8753
Epoch 043, Loss: 0.9072
Epoch 044, Loss: 0.8827
Epoch 045, Loss: 0.8679
Epoch 046, Loss: 0.9926
Epoch 047, Loss: 0.8761
Epoch 048, Loss: 0.8544
Epoch 049, Loss: 0.8368
Epoch 050, Loss: 0.7901
Epoch 051, Loss: 0.9063
Epoch 052, Loss: 0.8207
Epoch 053, Loss: 0.8293
Epoch 054, Loss: 0.9462
Epoch 055, Loss: 0.9493
Epoch 056, Loss: 0.8522
Epoch 057, Loss: 0.7568
Epoch 058, Loss: 0.7909
Epoch 059, Loss: 0.7345
Epoch 060, Loss: 0.8336
Epoch 061, Loss: 0.7225
Epoch 062, Loss: 0.7375
Epoch 063, Loss: 0.6909
Epoch 064, Loss: 0.7046
Epoch 065, Loss: 0.6650
Epoch 066, Loss: 0.7753
Epoch 067, Loss: 0.7009
Epoch 068, Loss: 0.7021
Epoch 069, Loss: 0.6447
Epoch 070, Loss: 0.6872
Epoch 071, Loss: 0.6497
Epoch 072, Loss: 0.6380
Epoch 073, Loss: 0.6237
Epoch 074, Loss: 0.7440
Epoch 075, Loss: 0.7020
Epoch 076, Loss: 0.6095
Epoch 077, Loss: 0.5635
Epoch 078, Loss: 0.6159
Epoch 079, Loss: 0.5964
Epoch 080, Loss: 0.6221
Epoch 081, Loss: 0.6128
Epoch 082, Loss: 0.6199
Epoch 083, Loss: 0.5596
Epoch 084, Loss: 0.5664
Epoch 085, Loss: 0.6127
Epoch 086, Loss: 0.5387
Epoch 087, Loss: 0.6157
Epoch 088, Loss: 0.6038
Epoch 089, Loss: 0.5744
Epoch 090, Loss: 0.6026
Epoch 091, Loss: 0.5653
Epoch 092, Loss: 0.5466
Epoch 093, Loss: 0.5338
Epoch 094, Loss: 0.6570
Epoch 095, Loss: 0.5459
Epoch 096, Loss: 0.5298
Epoch 097, Loss: 0.5400
Epoch 098, Loss: 0.5159
Epoch 099, Loss: 0.5278
Epoch 100, Loss: 0.5373

Test RMSE: 0.8316
Test MAPE: 0.2117
Training time: 19.70 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.3911
Epoch 002, Loss: 1.3206
Epoch 003, Loss: 1.1884
Epoch 004, Loss: 1.3444
Epoch 005, Loss: 1.3586
Epoch 006, Loss: 1.3030
Epoch 007, Loss: 1.1873
Epoch 008, Loss: 1.2426
Epoch 009, Loss: 1.2292
Epoch 010, Loss: 1.3023
Epoch 011, Loss: 1.1442
Epoch 012, Loss: 1.2916
Epoch 013, Loss: 1.2409
Epoch 014, Loss: 1.2734
Epoch 015, Loss: 1.2739
Epoch 016, Loss: 1.2106
Epoch 017, Loss: 1.3514
Epoch 018, Loss: 1.2312
Epoch 019, Loss: 1.2539
Epoch 020, Loss: 1.1887
Epoch 021, Loss: 1.4918
Epoch 022, Loss: 1.2288
Epoch 023, Loss: 1.2733
Epoch 024, Loss: 1.2225
Epoch 025, Loss: 1.2198
Epoch 026, Loss: 1.2039
Epoch 027, Loss: 1.2386
Epoch 028, Loss: 1.1881
Epoch 029, Loss: 1.2302
Epoch 030, Loss: 1.2293
Epoch 031, Loss: 1.1411
Epoch 032, Loss: 1.1711
Epoch 033, Loss: 1.3084
Epoch 034, Loss: 1.0914
Epoch 035, Loss: 1.1340
Epoch 036, Loss: 1.1079
Epoch 037, Loss: 1.0090
Epoch 038, Loss: 1.1607
Epoch 039, Loss: 1.1335
Epoch 040, Loss: 1.1200
Epoch 041, Loss: 0.9388
Epoch 042, Loss: 1.0022
Epoch 043, Loss: 0.9148
Epoch 044, Loss: 0.8507
Epoch 045, Loss: 1.0178
Epoch 046, Loss: 0.9976
Epoch 047, Loss: 0.8717
Epoch 048, Loss: 0.9805
Epoch 049, Loss: 0.8450
Epoch 050, Loss: 0.8424
Epoch 051, Loss: 0.9129
Epoch 052, Loss: 0.9426
Epoch 053, Loss: 0.8241
Epoch 054, Loss: 0.8329
Epoch 055, Loss: 0.8314
Epoch 056, Loss: 0.7483
Epoch 057, Loss: 0.7603
Epoch 058, Loss: 0.7183
Epoch 059, Loss: 0.8050
Epoch 060, Loss: 0.9082
Epoch 061, Loss: 0.7226
Epoch 062, Loss: 0.8480
Epoch 063, Loss: 0.8549
Epoch 064, Loss: 0.8244
Epoch 065, Loss: 0.8930
Epoch 066, Loss: 0.8608
Epoch 067, Loss: 0.7699
Epoch 068, Loss: 0.7639
Epoch 069, Loss: 0.7031
Epoch 070, Loss: 0.6725
Epoch 071, Loss: 0.6801
Epoch 072, Loss: 0.6847
Epoch 073, Loss: 0.6662
Epoch 074, Loss: 0.6692
Epoch 075, Loss: 0.6861
Epoch 076, Loss: 0.8834
Epoch 077, Loss: 0.6461
Epoch 078, Loss: 0.6557
Epoch 079, Loss: 0.7535
Epoch 080, Loss: 0.6298
Epoch 081, Loss: 0.6790
Epoch 082, Loss: 0.7001
Epoch 083, Loss: 0.7814
Epoch 084, Loss: 0.7317
Epoch 085, Loss: 0.7802
Epoch 086, Loss: 0.6312
Epoch 087, Loss: 0.6596
Epoch 088, Loss: 0.5787
Epoch 089, Loss: 0.7093
Epoch 090, Loss: 0.7611
Epoch 091, Loss: 0.6483
Epoch 092, Loss: 0.5848
Epoch 093, Loss: 0.6484
Epoch 094, Loss: 0.6810
Epoch 095, Loss: 0.6835
Epoch 096, Loss: 0.6161
Epoch 097, Loss: 0.6555
Epoch 098, Loss: 0.6202
Epoch 099, Loss: 0.6018
Epoch 100, Loss: 0.6105

Test RMSE: 0.7150
Test MAPE: 0.2082
Training time: 20.88 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.1651
Epoch 002, Loss: 1.5245
Epoch 003, Loss: 1.7163
Epoch 004, Loss: 1.5712
Epoch 005, Loss: 1.5535
Epoch 006, Loss: 1.6512
Epoch 007, Loss: 1.5390
Epoch 008, Loss: 1.5819
Epoch 009, Loss: 1.8705
Epoch 010, Loss: 1.9705
Epoch 011, Loss: 1.6700
Epoch 012, Loss: 1.5166
Epoch 013, Loss: 1.6441
Epoch 014, Loss: 1.6047
Epoch 015, Loss: 1.5692
Epoch 016, Loss: 1.6723
Epoch 017, Loss: 1.5261
Epoch 018, Loss: 1.4986
Epoch 019, Loss: 1.4947
Epoch 020, Loss: 1.4525
Epoch 021, Loss: 1.7303
Epoch 022, Loss: 1.6151
Epoch 023, Loss: 1.7062
Epoch 024, Loss: 1.6568
Epoch 025, Loss: 1.5743
Epoch 026, Loss: 1.5586
Epoch 027, Loss: 1.5369
Epoch 028, Loss: 1.6099
Epoch 029, Loss: 1.3098
Epoch 030, Loss: 1.6443
Epoch 031, Loss: 1.5220
Epoch 032, Loss: 1.4768
Epoch 033, Loss: 1.5846
Epoch 034, Loss: 1.6013
Epoch 035, Loss: 1.6549
Epoch 036, Loss: 1.4229
Epoch 037, Loss: 1.5692
Epoch 038, Loss: 1.5410
Epoch 039, Loss: 1.4225
Epoch 040, Loss: 1.5183
Epoch 041, Loss: 1.4408
Epoch 042, Loss: 1.9743
Epoch 043, Loss: 1.5992
Epoch 044, Loss: 1.4629
Epoch 045, Loss: 1.4996
Epoch 046, Loss: 1.5473
Epoch 047, Loss: 1.6352
Epoch 048, Loss: 1.4912
Epoch 049, Loss: 1.4376
Epoch 050, Loss: 1.6482
Epoch 051, Loss: 1.6127
Epoch 052, Loss: 1.7855
Epoch 053, Loss: 1.7943
Epoch 054, Loss: 1.5613
Epoch 055, Loss: 1.5466
Epoch 056, Loss: 1.5437
Epoch 057, Loss: 1.4339
Epoch 058, Loss: 1.7099
Epoch 059, Loss: 1.5189
Epoch 060, Loss: 1.6124
Epoch 061, Loss: 1.3118
Epoch 062, Loss: 1.3183
Epoch 063, Loss: 1.2609
Epoch 064, Loss: 1.2544
Epoch 065, Loss: 1.2373
Epoch 066, Loss: 1.2885
Epoch 067, Loss: 1.0543
Epoch 068, Loss: 1.1581
Epoch 069, Loss: 1.0099
Epoch 070, Loss: 1.1803
Epoch 071, Loss: 1.0867
Epoch 072, Loss: 1.0173
Epoch 073, Loss: 1.0051
Epoch 074, Loss: 1.0042
Epoch 075, Loss: 1.0390
Epoch 076, Loss: 0.9552
Epoch 077, Loss: 1.0354
Epoch 078, Loss: 1.0647
Epoch 079, Loss: 0.9710
Epoch 080, Loss: 1.0586
Epoch 081, Loss: 0.9332
Epoch 082, Loss: 1.0499
Epoch 083, Loss: 0.9293
Epoch 084, Loss: 0.9530
Epoch 085, Loss: 0.8315
Epoch 086, Loss: 0.9689
Epoch 087, Loss: 0.9501
Epoch 088, Loss: 0.9280
Epoch 089, Loss: 0.8919
Epoch 090, Loss: 0.9404
Epoch 091, Loss: 0.8294
Epoch 092, Loss: 0.7990
Epoch 093, Loss: 0.7942
Epoch 094, Loss: 0.8100
Epoch 095, Loss: 0.7934
Epoch 096, Loss: 0.8014
Epoch 097, Loss: 0.9114
Epoch 098, Loss: 0.8406
Epoch 099, Loss: 1.0384
Epoch 100, Loss: 0.7805

Test RMSE: 1.7290
Test MAPE: 0.2253
Training time: 17.74 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7350
Epoch 002, Loss: 3.3419
Epoch 003, Loss: 3.1734
Epoch 004, Loss: 1.5466
Epoch 005, Loss: 0.9206
Epoch 006, Loss: 0.7150
Epoch 007, Loss: 0.6769
Epoch 008, Loss: 0.7388
Epoch 009, Loss: 0.7583
Epoch 010, Loss: 0.7651
Epoch 011, Loss: 0.6519
Epoch 012, Loss: 0.6795
Epoch 013, Loss: 0.6743
Epoch 014, Loss: 0.6731
Epoch 015, Loss: 0.6031
Epoch 016, Loss: 0.6575
Epoch 017, Loss: 0.6167
Epoch 018, Loss: 0.6175
Epoch 019, Loss: 0.6539
Epoch 020, Loss: 0.6125
Epoch 021, Loss: 0.6074
Epoch 022, Loss: 0.5805
Epoch 023, Loss: 0.5852
Epoch 024, Loss: 0.6471
Epoch 025, Loss: 0.5483
Epoch 026, Loss: 0.6079
Epoch 027, Loss: 0.6165
Epoch 028, Loss: 0.5524
Epoch 029, Loss: 0.6067
Epoch 030, Loss: 0.5991
Epoch 031, Loss: 0.5819
Epoch 032, Loss: 0.5982
Epoch 033, Loss: 0.6117
Epoch 034, Loss: 0.6012
Epoch 035, Loss: 0.6357
Epoch 036, Loss: 0.6061
Epoch 037, Loss: 0.5655
Epoch 038, Loss: 0.5938
Epoch 039, Loss: 0.6012
Epoch 040, Loss: 0.5739
Epoch 041, Loss: 0.5744
Epoch 042, Loss: 0.5807
Epoch 043, Loss: 0.5678
Epoch 044, Loss: 0.5305
Epoch 045, Loss: 0.6153
Epoch 046, Loss: 0.5739
Epoch 047, Loss: 0.5527
Epoch 048, Loss: 0.5793
Epoch 049, Loss: 0.5458
Epoch 050, Loss: 0.5408
Epoch 051, Loss: 0.5526
Epoch 052, Loss: 0.5283
Epoch 053, Loss: 0.5284
Epoch 054, Loss: 0.5441
Epoch 055, Loss: 0.5313
Epoch 056, Loss: 0.5276
Epoch 057, Loss: 0.5548
Epoch 058, Loss: 0.5790
Epoch 059, Loss: 0.5312
Epoch 060, Loss: 0.5570
Epoch 061, Loss: 0.5576
Epoch 062, Loss: 0.5532
Epoch 063, Loss: 0.5416
Epoch 064, Loss: 0.5060
Epoch 065, Loss: 0.5443
Epoch 066, Loss: 0.5087
Epoch 067, Loss: 0.5610
Epoch 068, Loss: 0.5556
Epoch 069, Loss: 0.5256
Epoch 070, Loss: 0.5255
Epoch 071, Loss: 0.5236
Epoch 072, Loss: 0.5349
Epoch 073, Loss: 0.5149
Epoch 074, Loss: 0.5125
Epoch 075, Loss: 0.5351
Epoch 076, Loss: 0.5397
Epoch 077, Loss: 0.5257
Epoch 078, Loss: 0.5135
Epoch 079, Loss: 0.5334
Epoch 080, Loss: 0.4930
Epoch 081, Loss: 0.5164
Epoch 082, Loss: 0.4759
Epoch 083, Loss: 0.5266
Epoch 084, Loss: 0.4911
Epoch 085, Loss: 0.4815
Epoch 086, Loss: 0.5019
Epoch 087, Loss: 0.5727
Epoch 088, Loss: 0.5422
Epoch 089, Loss: 0.4922
Epoch 090, Loss: 0.5568
Epoch 091, Loss: 0.4840
Epoch 092, Loss: 0.5279
Epoch 093, Loss: 0.4973
Epoch 094, Loss: 0.5028
Epoch 095, Loss: 0.4869
Epoch 096, Loss: 0.5022
Epoch 097, Loss: 0.4884
Epoch 098, Loss: 0.4950
Epoch 099, Loss: 0.5249
Epoch 100, Loss: 0.4566

Test RMSE: 0.6644
Test MAPE: 405095040679936.0000
Training time: 104.21 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.665972 2.260088e-01      19.215101   GNN_model_10.pkl
       12   Q_values        0.2 0.882892 2.788107e-01      16.668126   GNN_model_12.pkl
       15   Q_values        0.2 0.831646 2.116736e-01      19.699837   GNN_model_15.pkl
       20   Q_values        0.2 0.714973 2.081760e-01      20.883583   GNN_model_20.pkl
       25   Q_values        0.2 1.728991 2.253416e-01      17.738557   GNN_model_25.pkl
     full   Q_values        0.2 0.664386 4.050950e+14     104.212187 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
