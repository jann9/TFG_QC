
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59770
 Mean Absolute Percentage Error: 0.25542
 Training time:  0.03176
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55258
 Mean Absolute Percentage Error: 0.39777
 Training time:  0.01753
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71486
 Mean Absolute Percentage Error: 0.57860
 Training time:  0.05997
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86243
 Mean Absolute Percentage Error: 0.53894
 Training time:  0.01675
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70442
 Mean Absolute Percentage Error: 0.30324
 Training time:  0.03340
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52234
 Mean Absolute Percentage Error: 0.17680
 Training time:  0.01614
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60519
 Mean Absolute Percentage Error: 0.22788
 Training time:  0.07226
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61127
 Mean Absolute Percentage Error: 0.25926
 Training time:  0.01662
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53931
 Mean Absolute Percentage Error: 0.17849
 Training time:  0.15254
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67567
 Mean Absolute Percentage Error: 0.21848
 Training time:  0.03391
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61725
 Mean Absolute Percentage Error: 0.23948
 Training time:  0.19006
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65516
 Mean Absolute Percentage Error: 0.29615
 Training time:  0.04053
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60139
  MAPE on 10 nodes subset: 0.26715

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71079
  MAPE on 12 nodes subset: 0.56864

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68759
  MAPE on 15 nodes subset: 0.29184

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58604
  MAPE on 20 nodes subset: 0.22887

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53352
  MAPE on 25 nodes subset: 0.18639

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597703 0.255424       0.031759       True             4                       MLP_model_10.pkl       85
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552575 0.397767       0.017529       True             4               MLP_model_10_Circuit.pkl       85
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.714859 0.578602       0.059968       True             4                       MLP_model_12.pkl       85
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.862434 0.538945       0.016755       True             4               MLP_model_12_Circuit.pkl       85
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704423 0.303237       0.033400       True             4                       MLP_model_15.pkl       85
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522341 0.176798       0.016140       True             4               MLP_model_15_Circuit.pkl       85
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.605187 0.227883       0.072261       True             4                       MLP_model_20.pkl       85
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611269 0.259262       0.016622       True             4               MLP_model_20_Circuit.pkl       85
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.539305 0.178487       0.152542       True             4                       MLP_model_25.pkl       85
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.675665 0.218480       0.033907       True             4               MLP_model_25_Circuit.pkl       85
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617254 0.239479       0.190062       True             4                     MLP_model_full.pkl       85
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.655162 0.296153       0.040525       True             4             MLP_model_full_Circuit.pkl       85
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601394 0.267145       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       85
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.710793 0.568645       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       85
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.687594 0.291841       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       85
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586045 0.228866       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       85
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.533520 0.186391       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       85

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59979
 Mean Absolute Percentage Error: 0.42329
 Training time:  0.34031
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76411
 Mean Absolute Percentage Error: 0.39645
 Training time:  0.24692
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.00300
 Mean Absolute Percentage Error: 0.66761
 Training time:  0.36626
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.11025
 Mean Absolute Percentage Error: 0.66179
 Training time:  0.25569
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.59385
 Mean Absolute Percentage Error: 0.17536
 Training time:  0.44593
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79677
 Mean Absolute Percentage Error: 0.23126
 Training time:  0.24996
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.67182
 Mean Absolute Percentage Error: 0.28728
 Training time:  0.64666
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85184
 Mean Absolute Percentage Error: 0.32953
 Training time:  0.25079
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74432
 Mean Absolute Percentage Error: 0.21797
 Training time:  0.72634
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69116
 Mean Absolute Percentage Error: 0.18632
 Training time:  0.24531
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72346
 Mean Absolute Percentage Error: 0.30838
 Training time:  2.94390
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74987
 Mean Absolute Percentage Error: 0.29763
 Training time:  0.30633
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.23999
  MAPE on 10 nodes subset: 0.02676

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34367
  MAPE on 12 nodes subset: 0.27423

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.15151
  MAPE on 15 nodes subset: 0.01880

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.36165
  MAPE on 20 nodes subset: 0.08262

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19598
  MAPE on 25 nodes subset: 0.02797

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.599787 0.423290       0.340309                           xgboost_model_10.pkl       73
       10             Circuit            50           5          4 0.764108 0.396453       0.246921                   xgboost_model_10_Circuit.pkl       73
       12            Q_values            50          78          4 1.003005 0.667612       0.366256                           xgboost_model_12.pkl       73
       12             Circuit            50           5          4 1.110248 0.661785       0.255688                   xgboost_model_12_Circuit.pkl       73
       15            Q_values            50         120          4 0.593850 0.175357       0.445930                           xgboost_model_15.pkl       73
       15             Circuit            50           5          4 0.796770 0.231264       0.249960                   xgboost_model_15_Circuit.pkl       73
       20            Q_values            50         210          4 0.671822 0.287277       0.646660                           xgboost_model_20.pkl       73
       20             Circuit            50           5          4 0.851840 0.329533       0.250792                   xgboost_model_20_Circuit.pkl       73
       25            Q_values            50         325          4 0.744315 0.217974       0.726337                           xgboost_model_25.pkl       73
       25             Circuit            50           5          4 0.691159 0.186324       0.245314                   xgboost_model_25_Circuit.pkl       73
     full            Q_values           250         325          4 0.723457 0.308375       2.943903                         xgboost_model_full.pkl       73
     full             Circuit           250           5          4 0.749870 0.297631       0.306332                 xgboost_model_full_Circuit.pkl       73
       10 Q_values_full_model            50         325          4 0.239991 0.026763       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       73
       12 Q_values_full_model            50         325          4 0.343670 0.274226       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       73
       15 Q_values_full_model            50         325          4 0.151508 0.018804       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       73
       20 Q_values_full_model            50         325          4 0.361652 0.082625       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       73
       25 Q_values_full_model            50         325          4 0.195977 0.027969       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       73

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.3742
Epoch 002, Loss: 0.6311
Epoch 003, Loss: 0.5999
Epoch 004, Loss: 0.6707
Epoch 005, Loss: 0.6004
Epoch 006, Loss: 0.6228
Epoch 007, Loss: 0.6144
Epoch 008, Loss: 0.5365
Epoch 009, Loss: 0.5660
Epoch 010, Loss: 0.5638
Epoch 011, Loss: 0.5686
Epoch 012, Loss: 0.5734
Epoch 013, Loss: 0.5571
Epoch 014, Loss: 0.5860
Epoch 015, Loss: 0.5982
Epoch 016, Loss: 0.5874
Epoch 017, Loss: 0.5740
Epoch 018, Loss: 0.5660
Epoch 019, Loss: 0.5644
Epoch 020, Loss: 0.5859
Epoch 021, Loss: 0.5948
Epoch 022, Loss: 0.5525
Epoch 023, Loss: 0.5934
Epoch 024, Loss: 0.5482
Epoch 025, Loss: 0.5730
Epoch 026, Loss: 0.6127
Epoch 027, Loss: 0.5242
Epoch 028, Loss: 0.5567
Epoch 029, Loss: 0.5577
Epoch 030, Loss: 0.5242
Epoch 031, Loss: 0.5539
Epoch 032, Loss: 0.5445
Epoch 033, Loss: 0.5335
Epoch 034, Loss: 0.5706
Epoch 035, Loss: 0.5736
Epoch 036, Loss: 0.5314
Epoch 037, Loss: 0.5079
Epoch 038, Loss: 0.5000
Epoch 039, Loss: 0.5398
Epoch 040, Loss: 0.5391
Epoch 041, Loss: 0.5106
Epoch 042, Loss: 0.5160
Epoch 043, Loss: 0.5406
Epoch 044, Loss: 0.5249
Epoch 045, Loss: 0.5170
Epoch 046, Loss: 0.5382
Epoch 047, Loss: 0.5432
Epoch 048, Loss: 0.5205
Epoch 049, Loss: 0.5263
Epoch 050, Loss: 0.5182
Epoch 051, Loss: 0.5082
Epoch 052, Loss: 0.5480
Epoch 053, Loss: 0.5283
Epoch 054, Loss: 0.5430
Epoch 055, Loss: 0.5343
Epoch 056, Loss: 0.5578
Epoch 057, Loss: 0.4997
Epoch 058, Loss: 0.4899
Epoch 059, Loss: 0.4940
Epoch 060, Loss: 0.5114
Epoch 061, Loss: 0.4871
Epoch 062, Loss: 0.4929
Epoch 063, Loss: 0.5094
Epoch 064, Loss: 0.4817
Epoch 065, Loss: 0.5167
Epoch 066, Loss: 0.5024
Epoch 067, Loss: 0.5116
Epoch 068, Loss: 0.5192
Epoch 069, Loss: 0.5131
Epoch 070, Loss: 0.4890
Epoch 071, Loss: 0.4941
Epoch 072, Loss: 0.5056
Epoch 073, Loss: 0.4760
Epoch 074, Loss: 0.4881
Epoch 075, Loss: 0.4816
Epoch 076, Loss: 0.5118
Epoch 077, Loss: 0.5040
Epoch 078, Loss: 0.4937
Epoch 079, Loss: 0.4975
Epoch 080, Loss: 0.4902
Epoch 081, Loss: 0.4875
Epoch 082, Loss: 0.5024
Epoch 083, Loss: 0.4988
Epoch 084, Loss: 0.4770
Epoch 085, Loss: 0.4895
Epoch 086, Loss: 0.5049
Epoch 087, Loss: 0.4853
Epoch 088, Loss: 0.4750
Epoch 089, Loss: 0.4873
Epoch 090, Loss: 0.4758
Epoch 091, Loss: 0.4737
Epoch 092, Loss: 0.4673
Epoch 093, Loss: 0.4478
Epoch 094, Loss: 0.4672
Epoch 095, Loss: 0.4770
Epoch 096, Loss: 0.5047
Epoch 097, Loss: 0.4812
Epoch 098, Loss: 0.4618
Epoch 099, Loss: 0.4617
Epoch 100, Loss: 0.4487

Test RMSE: 0.6347
Test MAPE: 0.2300
Training time: 12.13 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.7732
Epoch 002, Loss: 0.8645
Epoch 003, Loss: 0.9701
Epoch 004, Loss: 0.8472
Epoch 005, Loss: 0.8504
Epoch 006, Loss: 0.9173
Epoch 007, Loss: 0.8458
Epoch 008, Loss: 0.8665
Epoch 009, Loss: 0.8751
Epoch 010, Loss: 0.9067
Epoch 011, Loss: 0.8114
Epoch 012, Loss: 0.8904
Epoch 013, Loss: 0.8475
Epoch 014, Loss: 0.8384
Epoch 015, Loss: 0.8071
Epoch 016, Loss: 0.8715
Epoch 017, Loss: 0.8207
Epoch 018, Loss: 0.8301
Epoch 019, Loss: 0.8935
Epoch 020, Loss: 0.8863
Epoch 021, Loss: 0.8628
Epoch 022, Loss: 0.8415
Epoch 023, Loss: 0.8429
Epoch 024, Loss: 0.8559
Epoch 025, Loss: 0.8393
Epoch 026, Loss: 0.8326
Epoch 027, Loss: 0.8860
Epoch 028, Loss: 0.8791
Epoch 029, Loss: 0.8489
Epoch 030, Loss: 0.8189
Epoch 031, Loss: 0.8969
Epoch 032, Loss: 0.8596
Epoch 033, Loss: 0.8274
Epoch 034, Loss: 0.8687
Epoch 035, Loss: 0.8412
Epoch 036, Loss: 0.8330
Epoch 037, Loss: 0.8556
Epoch 038, Loss: 0.8512
Epoch 039, Loss: 0.7768
Epoch 040, Loss: 0.8442
Epoch 041, Loss: 0.8412
Epoch 042, Loss: 0.8523
Epoch 043, Loss: 0.7945
Epoch 044, Loss: 0.7839
Epoch 045, Loss: 0.7876
Epoch 046, Loss: 0.8502
Epoch 047, Loss: 0.7842
Epoch 048, Loss: 0.8114
Epoch 049, Loss: 0.8003
Epoch 050, Loss: 0.7822
Epoch 051, Loss: 0.7740
Epoch 052, Loss: 0.7700
Epoch 053, Loss: 0.8071
Epoch 054, Loss: 0.7637
Epoch 055, Loss: 0.7884
Epoch 056, Loss: 0.7827
Epoch 057, Loss: 0.7664
Epoch 058, Loss: 0.7531
Epoch 059, Loss: 0.7602
Epoch 060, Loss: 0.7574
Epoch 061, Loss: 0.7455
Epoch 062, Loss: 0.7306
Epoch 063, Loss: 0.7085
Epoch 064, Loss: 0.7123
Epoch 065, Loss: 0.7909
Epoch 066, Loss: 0.7310
Epoch 067, Loss: 0.7306
Epoch 068, Loss: 0.7439
Epoch 069, Loss: 0.7167
Epoch 070, Loss: 0.7389
Epoch 071, Loss: 0.6908
Epoch 072, Loss: 0.7497
Epoch 073, Loss: 0.7029
Epoch 074, Loss: 0.7141
Epoch 075, Loss: 0.7177
Epoch 076, Loss: 0.6943
Epoch 077, Loss: 0.6673
Epoch 078, Loss: 0.6735
Epoch 079, Loss: 0.6897
Epoch 080, Loss: 0.6928
Epoch 081, Loss: 0.7171
Epoch 082, Loss: 0.6763
Epoch 083, Loss: 0.6473
Epoch 084, Loss: 0.6506
Epoch 085, Loss: 0.6393
Epoch 086, Loss: 0.6618
Epoch 087, Loss: 0.6349
Epoch 088, Loss: 0.6576
Epoch 089, Loss: 0.6902
Epoch 090, Loss: 0.6716
Epoch 091, Loss: 0.6407
Epoch 092, Loss: 0.6558
Epoch 093, Loss: 0.6187
Epoch 094, Loss: 0.6663
Epoch 095, Loss: 0.6244
Epoch 096, Loss: 0.6209
Epoch 097, Loss: 0.6217
Epoch 098, Loss: 0.6414
Epoch 099, Loss: 0.6187
Epoch 100, Loss: 0.6214

Test RMSE: 0.6068
Test MAPE: 0.1672
Training time: 12.36 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.5943
Epoch 002, Loss: 1.0749
Epoch 003, Loss: 0.9107
Epoch 004, Loss: 1.0525
Epoch 005, Loss: 0.9497
Epoch 006, Loss: 1.0548
Epoch 007, Loss: 0.9923
Epoch 008, Loss: 1.0516
Epoch 009, Loss: 0.9229
Epoch 010, Loss: 0.9859
Epoch 011, Loss: 0.9695
Epoch 012, Loss: 0.9419
Epoch 013, Loss: 0.9749
Epoch 014, Loss: 1.0561
Epoch 015, Loss: 0.9465
Epoch 016, Loss: 1.0464
Epoch 017, Loss: 0.9491
Epoch 018, Loss: 0.9917
Epoch 019, Loss: 0.8917
Epoch 020, Loss: 0.9359
Epoch 021, Loss: 1.0192
Epoch 022, Loss: 0.9541
Epoch 023, Loss: 0.9183
Epoch 024, Loss: 0.9247
Epoch 025, Loss: 0.9024
Epoch 026, Loss: 0.8840
Epoch 027, Loss: 0.9019
Epoch 028, Loss: 0.9460
Epoch 029, Loss: 0.9781
Epoch 030, Loss: 0.9068
Epoch 031, Loss: 0.9309
Epoch 032, Loss: 0.9065
Epoch 033, Loss: 0.9838
Epoch 034, Loss: 0.8580
Epoch 035, Loss: 0.9442
Epoch 036, Loss: 0.9935
Epoch 037, Loss: 0.9012
Epoch 038, Loss: 0.8865
Epoch 039, Loss: 0.9123
Epoch 040, Loss: 0.9312
Epoch 041, Loss: 0.9344
Epoch 042, Loss: 0.8565
Epoch 043, Loss: 0.9415
Epoch 044, Loss: 0.9248
Epoch 045, Loss: 0.8634
Epoch 046, Loss: 0.8502
Epoch 047, Loss: 0.8383
Epoch 048, Loss: 0.8672
Epoch 049, Loss: 0.9208
Epoch 050, Loss: 0.8877
Epoch 051, Loss: 0.8764
Epoch 052, Loss: 0.8454
Epoch 053, Loss: 0.8527
Epoch 054, Loss: 0.8057
Epoch 055, Loss: 0.7994
Epoch 056, Loss: 0.7469
Epoch 057, Loss: 0.8296
Epoch 058, Loss: 0.7531
Epoch 059, Loss: 0.7074
Epoch 060, Loss: 0.7466
Epoch 061, Loss: 0.6544
Epoch 062, Loss: 0.7783
Epoch 063, Loss: 0.7146
Epoch 064, Loss: 0.6611
Epoch 065, Loss: 0.6357
Epoch 066, Loss: 0.6113
Epoch 067, Loss: 0.6608
Epoch 068, Loss: 0.6298
Epoch 069, Loss: 0.6370
Epoch 070, Loss: 0.6316
Epoch 071, Loss: 0.6417
Epoch 072, Loss: 0.6504
Epoch 073, Loss: 0.6378
Epoch 074, Loss: 0.6337
Epoch 075, Loss: 0.6112
Epoch 076, Loss: 0.5700
Epoch 077, Loss: 0.5661
Epoch 078, Loss: 0.5837
Epoch 079, Loss: 0.5717
Epoch 080, Loss: 0.5370
Epoch 081, Loss: 0.5476
Epoch 082, Loss: 0.5093
Epoch 083, Loss: 0.5764
Epoch 084, Loss: 0.5407
Epoch 085, Loss: 0.5318
Epoch 086, Loss: 0.5993
Epoch 087, Loss: 0.5492
Epoch 088, Loss: 0.5311
Epoch 089, Loss: 0.6201
Epoch 090, Loss: 0.5181
Epoch 091, Loss: 0.5335
Epoch 092, Loss: 0.5482
Epoch 093, Loss: 0.5102
Epoch 094, Loss: 0.5179
Epoch 095, Loss: 0.5152
Epoch 096, Loss: 0.5138
Epoch 097, Loss: 0.5290
Epoch 098, Loss: 0.5155
Epoch 099, Loss: 0.5318
Epoch 100, Loss: 0.5062

Test RMSE: 0.7777
Test MAPE: 0.2017
Training time: 12.62 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 6.5571
Epoch 002, Loss: 1.8829
Epoch 003, Loss: 1.3905
Epoch 004, Loss: 1.3467
Epoch 005, Loss: 1.2684
Epoch 006, Loss: 1.2542
Epoch 007, Loss: 1.3027
Epoch 008, Loss: 1.5020
Epoch 009, Loss: 1.4320
Epoch 010, Loss: 1.1780
Epoch 011, Loss: 1.2071
Epoch 012, Loss: 1.4166
Epoch 013, Loss: 1.4131
Epoch 014, Loss: 1.5760
Epoch 015, Loss: 1.4475
Epoch 016, Loss: 1.3214
Epoch 017, Loss: 1.2840
Epoch 018, Loss: 1.1511
Epoch 019, Loss: 1.3882
Epoch 020, Loss: 1.2130
Epoch 021, Loss: 1.2427
Epoch 022, Loss: 1.2505
Epoch 023, Loss: 1.1464
Epoch 024, Loss: 1.2088
Epoch 025, Loss: 1.1895
Epoch 026, Loss: 1.1584
Epoch 027, Loss: 1.2948
Epoch 028, Loss: 1.1858
Epoch 029, Loss: 1.2798
Epoch 030, Loss: 1.3148
Epoch 031, Loss: 1.1511
Epoch 032, Loss: 1.2792
Epoch 033, Loss: 1.2057
Epoch 034, Loss: 1.2068
Epoch 035, Loss: 1.1444
Epoch 036, Loss: 1.1811
Epoch 037, Loss: 1.2969
Epoch 038, Loss: 1.2019
Epoch 039, Loss: 1.1927
Epoch 040, Loss: 1.2580
Epoch 041, Loss: 1.3461
Epoch 042, Loss: 1.1088
Epoch 043, Loss: 1.1652
Epoch 044, Loss: 1.2890
Epoch 045, Loss: 1.1660
Epoch 046, Loss: 1.1473
Epoch 047, Loss: 1.1580
Epoch 048, Loss: 1.3527
Epoch 049, Loss: 1.2523
Epoch 050, Loss: 1.1488
Epoch 051, Loss: 1.2055
Epoch 052, Loss: 1.4838
Epoch 053, Loss: 1.4390
Epoch 054, Loss: 1.1484
Epoch 055, Loss: 1.1319
Epoch 056, Loss: 1.1103
Epoch 057, Loss: 1.1437
Epoch 058, Loss: 1.1209
Epoch 059, Loss: 1.1121
Epoch 060, Loss: 1.1117
Epoch 061, Loss: 1.2796
Epoch 062, Loss: 1.1531
Epoch 063, Loss: 1.1122
Epoch 064, Loss: 1.0815
Epoch 065, Loss: 1.0257
Epoch 066, Loss: 1.1405
Epoch 067, Loss: 1.0296
Epoch 068, Loss: 0.9683
Epoch 069, Loss: 0.9734
Epoch 070, Loss: 0.9652
Epoch 071, Loss: 1.0921
Epoch 072, Loss: 1.0388
Epoch 073, Loss: 0.9213
Epoch 074, Loss: 0.8521
Epoch 075, Loss: 0.9730
Epoch 076, Loss: 0.9074
Epoch 077, Loss: 0.8597
Epoch 078, Loss: 0.9334
Epoch 079, Loss: 0.8245
Epoch 080, Loss: 0.7963
Epoch 081, Loss: 0.7837
Epoch 082, Loss: 0.8333
Epoch 083, Loss: 0.8059
Epoch 084, Loss: 0.8438
Epoch 085, Loss: 0.7579
Epoch 086, Loss: 0.8157
Epoch 087, Loss: 0.8998
Epoch 088, Loss: 0.7412
Epoch 089, Loss: 0.7366
Epoch 090, Loss: 0.8016
Epoch 091, Loss: 0.7434
Epoch 092, Loss: 0.7352
Epoch 093, Loss: 0.7191
Epoch 094, Loss: 0.7061
Epoch 095, Loss: 0.6626
Epoch 096, Loss: 0.6674
Epoch 097, Loss: 0.6881
Epoch 098, Loss: 0.6227
Epoch 099, Loss: 0.8075
Epoch 100, Loss: 0.7075

Test RMSE: 1.0905
Test MAPE: 0.2744
Training time: 13.14 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 11.0735
Epoch 002, Loss: 1.6464
Epoch 003, Loss: 1.7993
Epoch 004, Loss: 1.6711
Epoch 005, Loss: 1.9896
Epoch 006, Loss: 1.6197
Epoch 007, Loss: 1.6124
Epoch 008, Loss: 1.6694
Epoch 009, Loss: 1.7636
Epoch 010, Loss: 1.9813
Epoch 011, Loss: 1.4819
Epoch 012, Loss: 1.7552
Epoch 013, Loss: 1.5210
Epoch 014, Loss: 1.6541
Epoch 015, Loss: 1.7123
Epoch 016, Loss: 1.8375
Epoch 017, Loss: 1.4791
Epoch 018, Loss: 1.5387
Epoch 019, Loss: 1.5184
Epoch 020, Loss: 1.5094
Epoch 021, Loss: 1.5284
Epoch 022, Loss: 1.4533
Epoch 023, Loss: 1.6053
Epoch 024, Loss: 1.5044
Epoch 025, Loss: 1.5337
Epoch 026, Loss: 1.5844
Epoch 027, Loss: 1.5304
Epoch 028, Loss: 1.5538
Epoch 029, Loss: 1.5459
Epoch 030, Loss: 1.7027
Epoch 031, Loss: 1.6452
Epoch 032, Loss: 1.7505
Epoch 033, Loss: 1.4917
Epoch 034, Loss: 1.5633
Epoch 035, Loss: 1.6470
Epoch 036, Loss: 1.6686
Epoch 037, Loss: 1.6027
Epoch 038, Loss: 1.5026
Epoch 039, Loss: 1.6213
Epoch 040, Loss: 1.4314
Epoch 041, Loss: 1.6389
Epoch 042, Loss: 1.6494
Epoch 043, Loss: 1.4617
Epoch 044, Loss: 1.4203
Epoch 045, Loss: 1.6261
Epoch 046, Loss: 1.7202
Epoch 047, Loss: 1.5064
Epoch 048, Loss: 1.4680
Epoch 049, Loss: 1.5423
Epoch 050, Loss: 1.4650
Epoch 051, Loss: 1.4977
Epoch 052, Loss: 1.3885
Epoch 053, Loss: 1.5637
Epoch 054, Loss: 1.5237
Epoch 055, Loss: 1.8572
Epoch 056, Loss: 1.3864
Epoch 057, Loss: 1.4830
Epoch 058, Loss: 1.4382
Epoch 059, Loss: 1.5369
Epoch 060, Loss: 1.5604
Epoch 061, Loss: 1.4164
Epoch 062, Loss: 1.4378
Epoch 063, Loss: 1.4279
Epoch 064, Loss: 1.4628
Epoch 065, Loss: 1.7074
Epoch 066, Loss: 1.4804
Epoch 067, Loss: 1.8437
Epoch 068, Loss: 1.4569
Epoch 069, Loss: 1.4945
Epoch 070, Loss: 1.4815
Epoch 071, Loss: 1.3613
Epoch 072, Loss: 1.4202
Epoch 073, Loss: 1.4895
Epoch 074, Loss: 1.4493
Epoch 075, Loss: 1.4395
Epoch 076, Loss: 1.5299
Epoch 077, Loss: 1.3946
Epoch 078, Loss: 1.4617
Epoch 079, Loss: 1.4729
Epoch 080, Loss: 1.5562
Epoch 081, Loss: 1.4153
Epoch 082, Loss: 1.5401
Epoch 083, Loss: 1.3982
Epoch 084, Loss: 1.4907
Epoch 085, Loss: 1.6232
Epoch 086, Loss: 1.3484
Epoch 087, Loss: 1.6034
Epoch 088, Loss: 1.3982
Epoch 089, Loss: 1.4887
Epoch 090, Loss: 1.4675
Epoch 091, Loss: 1.5758
Epoch 092, Loss: 1.6633
Epoch 093, Loss: 1.5161
Epoch 094, Loss: 1.3589
Epoch 095, Loss: 1.5274
Epoch 096, Loss: 1.4473
Epoch 097, Loss: 1.4650
Epoch 098, Loss: 1.4311
Epoch 099, Loss: 1.4753
Epoch 100, Loss: 1.4363

Test RMSE: 1.5609
Test MAPE: 0.2424
Training time: 13.75 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7889
Epoch 002, Loss: 3.1930
Epoch 003, Loss: 2.6503
Epoch 004, Loss: 1.1752
Epoch 005, Loss: 0.7704
Epoch 006, Loss: 0.7208
Epoch 007, Loss: 0.7258
Epoch 008, Loss: 0.6887
Epoch 009, Loss: 0.7451
Epoch 010, Loss: 0.7186
Epoch 011, Loss: 0.6431
Epoch 012, Loss: 0.6610
Epoch 013, Loss: 0.6947
Epoch 014, Loss: 0.6448
Epoch 015, Loss: 0.6593
Epoch 016, Loss: 0.6363
Epoch 017, Loss: 0.6256
Epoch 018, Loss: 0.6413
Epoch 019, Loss: 0.6626
Epoch 020, Loss: 0.6886
Epoch 021, Loss: 0.6570
Epoch 022, Loss: 0.6097
Epoch 023, Loss: 0.6204
Epoch 024, Loss: 0.6574
Epoch 025, Loss: 0.6631
Epoch 026, Loss: 0.5970
Epoch 027, Loss: 0.6545
Epoch 028, Loss: 0.6498
Epoch 029, Loss: 0.5632
Epoch 030, Loss: 0.5481
Epoch 031, Loss: 0.6014
Epoch 032, Loss: 0.5992
Epoch 033, Loss: 0.5641
Epoch 034, Loss: 0.5717
Epoch 035, Loss: 0.6105
Epoch 036, Loss: 0.5453
Epoch 037, Loss: 0.6040
Epoch 038, Loss: 0.5431
Epoch 039, Loss: 0.6289
Epoch 040, Loss: 0.5423
Epoch 041, Loss: 0.5803
Epoch 042, Loss: 0.5629
Epoch 043, Loss: 0.5464
Epoch 044, Loss: 0.6077
Epoch 045, Loss: 0.5616
Epoch 046, Loss: 0.5424
Epoch 047, Loss: 0.5721
Epoch 048, Loss: 0.5349
Epoch 049, Loss: 0.6339
Epoch 050, Loss: 0.5470
Epoch 051, Loss: 0.5468
Epoch 052, Loss: 0.5133
Epoch 053, Loss: 0.5139
Epoch 054, Loss: 0.5595
Epoch 055, Loss: 0.5785
Epoch 056, Loss: 0.5510
Epoch 057, Loss: 0.5304
Epoch 058, Loss: 0.5873
Epoch 059, Loss: 0.5284
Epoch 060, Loss: 0.5454
Epoch 061, Loss: 0.5261
Epoch 062, Loss: 0.5312
Epoch 063, Loss: 0.5451
Epoch 064, Loss: 0.5345
Epoch 065, Loss: 0.5140
Epoch 066, Loss: 0.5380
Epoch 067, Loss: 0.5370
Epoch 068, Loss: 0.5099
Epoch 069, Loss: 0.5169
Epoch 070, Loss: 0.4964
Epoch 071, Loss: 0.5099
Epoch 072, Loss: 0.5180
Epoch 073, Loss: 0.5214
Epoch 074, Loss: 0.4972
Epoch 075, Loss: 0.5543
Epoch 076, Loss: 0.5391
Epoch 077, Loss: 0.5135
Epoch 078, Loss: 0.5000
Epoch 079, Loss: 0.5137
Epoch 080, Loss: 0.5196
Epoch 081, Loss: 0.5298
Epoch 082, Loss: 0.5056
Epoch 083, Loss: 0.5021
Epoch 084, Loss: 0.5587
Epoch 085, Loss: 0.4954
Epoch 086, Loss: 0.5225
Epoch 087, Loss: 0.5081
Epoch 088, Loss: 0.5406
Epoch 089, Loss: 0.5011
Epoch 090, Loss: 0.4801
Epoch 091, Loss: 0.5260
Epoch 092, Loss: 0.4735
Epoch 093, Loss: 0.4821
Epoch 094, Loss: 0.4711
Epoch 095, Loss: 0.4930
Epoch 096, Loss: 0.5164
Epoch 097, Loss: 0.4894
Epoch 098, Loss: 0.5108
Epoch 099, Loss: 0.4919
Epoch 100, Loss: 0.4826

Test RMSE: 0.8573
Test MAPE: 196461551681536.0000
Training time: 64.61 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.634671 2.300409e-01      12.133043   GNN_model_10.pkl
       12   Q_values        0.2 0.606847 1.671894e-01      12.356466   GNN_model_12.pkl
       15   Q_values        0.2 0.777688 2.017160e-01      12.624885   GNN_model_15.pkl
       20   Q_values        0.2 1.090512 2.744435e-01      13.141994   GNN_model_20.pkl
       25   Q_values        0.2 1.560922 2.423879e-01      13.753849   GNN_model_25.pkl
     full   Q_values        0.2 0.857263 1.964616e+14      64.609710 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 20%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
