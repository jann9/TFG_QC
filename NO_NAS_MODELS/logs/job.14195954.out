
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59720
 Mean Absolute Percentage Error: 0.25521
 Training time:  0.07960
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.54753
 Mean Absolute Percentage Error: 0.38591
 Training time:  0.07338
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71543
 Mean Absolute Percentage Error: 0.57741
 Training time:  0.13491
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86471
 Mean Absolute Percentage Error: 0.54158
 Training time:  0.03915
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70508
 Mean Absolute Percentage Error: 0.30344
 Training time:  0.07166
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.53407
 Mean Absolute Percentage Error: 0.17112
 Training time:  0.09991
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60408
 Mean Absolute Percentage Error: 0.22403
 Training time:  0.09747
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61231
 Mean Absolute Percentage Error: 0.25117
 Training time:  0.09595
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53453
 Mean Absolute Percentage Error: 0.17464
 Training time:  0.16433
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.68447
 Mean Absolute Percentage Error: 0.21475
 Training time:  0.02605
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61768
 Mean Absolute Percentage Error: 0.23741
 Training time:  0.16246
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65993
 Mean Absolute Percentage Error: 0.28788
 Training time:  0.01940
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.59933
  MAPE on 10 nodes subset: 0.26531

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71274
  MAPE on 12 nodes subset: 0.56691

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68293
  MAPE on 15 nodes subset: 0.28777

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58539
  MAPE on 20 nodes subset: 0.22488

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52853
  MAPE on 25 nodes subset: 0.18300

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597202 0.255210       0.079601       True             4                       MLP_model_10.pkl       40
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.547530 0.385915       0.073380       True             3               MLP_model_10_Circuit.pkl       40
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715434 0.577411       0.134907       True             4                       MLP_model_12.pkl       40
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.864711 0.541578       0.039146       True             4               MLP_model_12_Circuit.pkl       40
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705075 0.303439       0.071658       True             4                       MLP_model_15.pkl       40
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534067 0.171120       0.099906       True             3               MLP_model_15_Circuit.pkl       40
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604080 0.224031       0.097467       True             3                       MLP_model_20.pkl       40
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.612305 0.251169       0.095947       True             3               MLP_model_20_Circuit.pkl       40
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.534529 0.174639       0.164326       True             4                       MLP_model_25.pkl       40
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.684469 0.214750       0.026054       True             3               MLP_model_25_Circuit.pkl       40
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617681 0.237412       0.162461       True             4                     MLP_model_full.pkl       40
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.659929 0.287879       0.019400       True             3             MLP_model_full_Circuit.pkl       40
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.599334 0.265312       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       40
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.712744 0.566911       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       40
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.682932 0.287768       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       40
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585394 0.224877       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       40
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.528530 0.182998       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       40

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59401
 Mean Absolute Percentage Error: 0.43370
 Training time:  0.37435
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75777
 Mean Absolute Percentage Error: 0.39224
 Training time:  0.24384
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98528
 Mean Absolute Percentage Error: 0.67209
 Training time:  0.37212
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10948
 Mean Absolute Percentage Error: 0.66134
 Training time:  0.25137
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.58637
 Mean Absolute Percentage Error: 0.18300
 Training time:  0.44676
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79346
 Mean Absolute Percentage Error: 0.22667
 Training time:  0.24107
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.63950
 Mean Absolute Percentage Error: 0.26714
 Training time:  0.61805
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85060
 Mean Absolute Percentage Error: 0.32936
 Training time:  0.24302
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73448
 Mean Absolute Percentage Error: 0.22691
 Training time:  0.73086
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69855
 Mean Absolute Percentage Error: 0.18431
 Training time:  0.24556
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72381
 Mean Absolute Percentage Error: 0.30676
 Training time:  2.97018
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75294
 Mean Absolute Percentage Error: 0.30073
 Training time:  0.30828
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22539
  MAPE on 10 nodes subset: 0.02758

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.35289
  MAPE on 12 nodes subset: 0.26848

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.11411
  MAPE on 15 nodes subset: 0.01408

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40091
  MAPE on 20 nodes subset: 0.09517

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.20798
  MAPE on 25 nodes subset: 0.02627

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.594008 0.433701       0.374350                           xgboost_model_10.pkl       13
       10             Circuit            50           5          4 0.757769 0.392244       0.243840                   xgboost_model_10_Circuit.pkl       13
       12            Q_values            50          78          4 0.985282 0.672094       0.372122                           xgboost_model_12.pkl       13
       12             Circuit            50           5          4 1.109481 0.661343       0.251366                   xgboost_model_12_Circuit.pkl       13
       15            Q_values            50         120          4 0.586368 0.183004       0.446757                           xgboost_model_15.pkl       13
       15             Circuit            50           5          4 0.793463 0.226672       0.241073                   xgboost_model_15_Circuit.pkl       13
       20            Q_values            50         210          4 0.639498 0.267140       0.618053                           xgboost_model_20.pkl       13
       20             Circuit            50           5          4 0.850598 0.329363       0.243019                   xgboost_model_20_Circuit.pkl       13
       25            Q_values            50         325          4 0.734479 0.226913       0.730861                           xgboost_model_25.pkl       13
       25             Circuit            50           5          4 0.698545 0.184313       0.245561                   xgboost_model_25_Circuit.pkl       13
     full            Q_values           250         325          4 0.723814 0.306755       2.970183                         xgboost_model_full.pkl       13
     full             Circuit           250           5          4 0.752935 0.300732       0.308276                 xgboost_model_full_Circuit.pkl       13
       10 Q_values_full_model            50         325          4 0.225387 0.027578       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       12 Q_values_full_model            50         325          4 0.352891 0.268481       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       15 Q_values_full_model            50         325          4 0.114109 0.014077       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       20 Q_values_full_model            50         325          4 0.400908 0.095170       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13
       25 Q_values_full_model            50         325          4 0.207977 0.026266       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       13

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.8669
Epoch 002, Loss: 0.5700
Epoch 003, Loss: 0.5574
Epoch 004, Loss: 0.5654
Epoch 005, Loss: 0.5559
Epoch 006, Loss: 0.5968
Epoch 007, Loss: 0.5877
Epoch 008, Loss: 0.6160
Epoch 009, Loss: 0.5913
Epoch 010, Loss: 0.5656
Epoch 011, Loss: 0.5396
Epoch 012, Loss: 0.6041
Epoch 013, Loss: 0.5831
Epoch 014, Loss: 0.5755
Epoch 015, Loss: 0.5833
Epoch 016, Loss: 0.5566
Epoch 017, Loss: 0.5616
Epoch 018, Loss: 0.6022
Epoch 019, Loss: 0.6596
Epoch 020, Loss: 0.5463
Epoch 021, Loss: 0.5597
Epoch 022, Loss: 0.5788
Epoch 023, Loss: 0.5579
Epoch 024, Loss: 0.5597
Epoch 025, Loss: 0.5978
Epoch 026, Loss: 0.5472
Epoch 027, Loss: 0.5656
Epoch 028, Loss: 0.6080
Epoch 029, Loss: 0.5804
Epoch 030, Loss: 0.5723
Epoch 031, Loss: 0.5437
Epoch 032, Loss: 0.5342
Epoch 033, Loss: 0.5756
Epoch 034, Loss: 0.5385
Epoch 035, Loss: 0.5428
Epoch 036, Loss: 0.5457
Epoch 037, Loss: 0.5829
Epoch 038, Loss: 0.6079
Epoch 039, Loss: 0.5268
Epoch 040, Loss: 0.5558
Epoch 041, Loss: 0.5522
Epoch 042, Loss: 0.5355
Epoch 043, Loss: 0.5473
Epoch 044, Loss: 0.5644
Epoch 045, Loss: 0.5169
Epoch 046, Loss: 0.5050
Epoch 047, Loss: 0.5227
Epoch 048, Loss: 0.5937
Epoch 049, Loss: 0.5361
Epoch 050, Loss: 0.5175
Epoch 051, Loss: 0.5152
Epoch 052, Loss: 0.5183
Epoch 053, Loss: 0.5354
Epoch 054, Loss: 0.5311
Epoch 055, Loss: 0.5233
Epoch 056, Loss: 0.5163
Epoch 057, Loss: 0.5108
Epoch 058, Loss: 0.4891
Epoch 059, Loss: 0.4833
Epoch 060, Loss: 0.5259
Epoch 061, Loss: 0.5424
Epoch 062, Loss: 0.4855
Epoch 063, Loss: 0.4823
Epoch 064, Loss: 0.5012
Epoch 065, Loss: 0.4990
Epoch 066, Loss: 0.4764
Epoch 067, Loss: 0.4968
Epoch 068, Loss: 0.4782
Epoch 069, Loss: 0.4745
Epoch 070, Loss: 0.4595
Epoch 071, Loss: 0.4740
Epoch 072, Loss: 0.4704
Epoch 073, Loss: 0.4570
Epoch 074, Loss: 0.4550
Epoch 075, Loss: 0.4675
Epoch 076, Loss: 0.4717
Epoch 077, Loss: 0.4545
Epoch 078, Loss: 0.4756
Epoch 079, Loss: 0.4922
Epoch 080, Loss: 0.4604
Epoch 081, Loss: 0.4390
Epoch 082, Loss: 0.4308
Epoch 083, Loss: 0.4301
Epoch 084, Loss: 0.4516
Epoch 085, Loss: 0.4642
Epoch 086, Loss: 0.4237
Epoch 087, Loss: 0.4267
Epoch 088, Loss: 0.4354
Epoch 089, Loss: 0.4327
Epoch 090, Loss: 0.4571
Epoch 091, Loss: 0.4204
Epoch 092, Loss: 0.4214
Epoch 093, Loss: 0.4105
Epoch 094, Loss: 0.4365
Epoch 095, Loss: 0.4252
Epoch 096, Loss: 0.4246
Epoch 097, Loss: 0.4178
Epoch 098, Loss: 0.4099
Epoch 099, Loss: 0.4170
Epoch 100, Loss: 0.4061

Test RMSE: 0.6081
Test MAPE: 0.2023
Training time: 12.43 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.5880
Epoch 002, Loss: 0.9114
Epoch 003, Loss: 0.9064
Epoch 004, Loss: 0.8944
Epoch 005, Loss: 0.8540
Epoch 006, Loss: 0.8695
Epoch 007, Loss: 0.9069
Epoch 008, Loss: 0.8545
Epoch 009, Loss: 0.8351
Epoch 010, Loss: 0.8865
Epoch 011, Loss: 0.8787
Epoch 012, Loss: 0.8833
Epoch 013, Loss: 0.9747
Epoch 014, Loss: 0.9123
Epoch 015, Loss: 0.8198
Epoch 016, Loss: 0.9768
Epoch 017, Loss: 0.8207
Epoch 018, Loss: 0.8985
Epoch 019, Loss: 0.9400
Epoch 020, Loss: 0.8321
Epoch 021, Loss: 0.8455
Epoch 022, Loss: 0.8747
Epoch 023, Loss: 0.9059
Epoch 024, Loss: 0.8639
Epoch 025, Loss: 0.8821
Epoch 026, Loss: 0.8359
Epoch 027, Loss: 0.8277
Epoch 028, Loss: 0.8988
Epoch 029, Loss: 0.8598
Epoch 030, Loss: 0.8043
Epoch 031, Loss: 0.8839
Epoch 032, Loss: 0.8515
Epoch 033, Loss: 0.7935
Epoch 034, Loss: 0.8818
Epoch 035, Loss: 0.8465
Epoch 036, Loss: 0.8131
Epoch 037, Loss: 0.7909
Epoch 038, Loss: 0.8283
Epoch 039, Loss: 0.8450
Epoch 040, Loss: 0.8030
Epoch 041, Loss: 0.8183
Epoch 042, Loss: 0.8030
Epoch 043, Loss: 0.8229
Epoch 044, Loss: 0.7990
Epoch 045, Loss: 0.8549
Epoch 046, Loss: 0.7540
Epoch 047, Loss: 0.8979
Epoch 048, Loss: 0.8056
Epoch 049, Loss: 0.8051
Epoch 050, Loss: 0.7874
Epoch 051, Loss: 0.7844
Epoch 052, Loss: 0.7806
Epoch 053, Loss: 0.7764
Epoch 054, Loss: 0.7384
Epoch 055, Loss: 0.7888
Epoch 056, Loss: 0.7906
Epoch 057, Loss: 0.7676
Epoch 058, Loss: 0.7428
Epoch 059, Loss: 0.6942
Epoch 060, Loss: 0.7381
Epoch 061, Loss: 0.7222
Epoch 062, Loss: 0.7253
Epoch 063, Loss: 0.7381
Epoch 064, Loss: 0.6882
Epoch 065, Loss: 0.7057
Epoch 066, Loss: 0.7224
Epoch 067, Loss: 0.6778
Epoch 068, Loss: 0.6877
Epoch 069, Loss: 0.6520
Epoch 070, Loss: 0.6511
Epoch 071, Loss: 0.6640
Epoch 072, Loss: 0.6933
Epoch 073, Loss: 0.6618
Epoch 074, Loss: 0.6582
Epoch 075, Loss: 0.6656
Epoch 076, Loss: 0.6263
Epoch 077, Loss: 0.6424
Epoch 078, Loss: 0.6345
Epoch 079, Loss: 0.6279
Epoch 080, Loss: 0.6792
Epoch 081, Loss: 0.6166
Epoch 082, Loss: 0.6533
Epoch 083, Loss: 0.6308
Epoch 084, Loss: 0.6475
Epoch 085, Loss: 0.5987
Epoch 086, Loss: 0.6207
Epoch 087, Loss: 0.5806
Epoch 088, Loss: 0.6503
Epoch 089, Loss: 0.5860
Epoch 090, Loss: 0.5864
Epoch 091, Loss: 0.5802
Epoch 092, Loss: 0.5631
Epoch 093, Loss: 0.6132
Epoch 094, Loss: 0.5924
Epoch 095, Loss: 0.5697
Epoch 096, Loss: 0.5630
Epoch 097, Loss: 0.5601
Epoch 098, Loss: 0.5623
Epoch 099, Loss: 0.5610
Epoch 100, Loss: 0.5643

Test RMSE: 0.6238
Test MAPE: 0.1819
Training time: 12.38 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 5.1878
Epoch 002, Loss: 1.0106
Epoch 003, Loss: 0.9707
Epoch 004, Loss: 1.0003
Epoch 005, Loss: 0.9275
Epoch 006, Loss: 0.9109
Epoch 007, Loss: 1.0052
Epoch 008, Loss: 0.9411
Epoch 009, Loss: 0.9511
Epoch 010, Loss: 0.9944
Epoch 011, Loss: 0.9645
Epoch 012, Loss: 1.0070
Epoch 013, Loss: 0.8977
Epoch 014, Loss: 1.0351
Epoch 015, Loss: 0.9418
Epoch 016, Loss: 0.9091
Epoch 017, Loss: 0.9692
Epoch 018, Loss: 0.9784
Epoch 019, Loss: 0.9395
Epoch 020, Loss: 0.8523
Epoch 021, Loss: 0.9432
Epoch 022, Loss: 0.9077
Epoch 023, Loss: 0.9236
Epoch 024, Loss: 0.8812
Epoch 025, Loss: 0.9171
Epoch 026, Loss: 0.9108
Epoch 027, Loss: 1.0080
Epoch 028, Loss: 0.8801
Epoch 029, Loss: 0.9214
Epoch 030, Loss: 0.8705
Epoch 031, Loss: 0.9140
Epoch 032, Loss: 0.9510
Epoch 033, Loss: 0.8876
Epoch 034, Loss: 0.9621
Epoch 035, Loss: 0.9255
Epoch 036, Loss: 0.9319
Epoch 037, Loss: 0.8282
Epoch 038, Loss: 0.8677
Epoch 039, Loss: 0.9004
Epoch 040, Loss: 0.8356
Epoch 041, Loss: 0.8228
Epoch 042, Loss: 0.8802
Epoch 043, Loss: 1.0003
Epoch 044, Loss: 0.8337
Epoch 045, Loss: 0.8042
Epoch 046, Loss: 0.8688
Epoch 047, Loss: 0.7906
Epoch 048, Loss: 0.8145
Epoch 049, Loss: 0.8104
Epoch 050, Loss: 0.8191
Epoch 051, Loss: 0.7917
Epoch 052, Loss: 0.9084
Epoch 053, Loss: 0.7603
Epoch 054, Loss: 0.7757
Epoch 055, Loss: 0.7606
Epoch 056, Loss: 0.7640
Epoch 057, Loss: 0.8091
Epoch 058, Loss: 0.7046
Epoch 059, Loss: 0.7744
Epoch 060, Loss: 0.7125
Epoch 061, Loss: 0.7003
Epoch 062, Loss: 0.6776
Epoch 063, Loss: 0.7073
Epoch 064, Loss: 0.6730
Epoch 065, Loss: 0.7302
Epoch 066, Loss: 0.6130
Epoch 067, Loss: 0.6526
Epoch 068, Loss: 0.7118
Epoch 069, Loss: 0.6249
Epoch 070, Loss: 0.6160
Epoch 071, Loss: 0.6881
Epoch 072, Loss: 0.6705
Epoch 073, Loss: 0.5731
Epoch 074, Loss: 0.6437
Epoch 075, Loss: 0.6994
Epoch 076, Loss: 0.6035
Epoch 077, Loss: 0.5834
Epoch 078, Loss: 0.5881
Epoch 079, Loss: 0.5960
Epoch 080, Loss: 0.6021
Epoch 081, Loss: 0.6149
Epoch 082, Loss: 0.5895
Epoch 083, Loss: 0.5553
Epoch 084, Loss: 0.6475
Epoch 085, Loss: 0.5626
Epoch 086, Loss: 0.5472
Epoch 087, Loss: 0.5886
Epoch 088, Loss: 0.5365
Epoch 089, Loss: 0.6309
Epoch 090, Loss: 0.5963
Epoch 091, Loss: 0.5786
Epoch 092, Loss: 0.5789
Epoch 093, Loss: 0.5517
Epoch 094, Loss: 0.5785
Epoch 095, Loss: 0.5686
Epoch 096, Loss: 0.5304
Epoch 097, Loss: 0.6056
Epoch 098, Loss: 0.5693
Epoch 099, Loss: 0.5268
Epoch 100, Loss: 0.5152

Test RMSE: 0.8804
Test MAPE: 0.2085
Training time: 12.58 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 5.9842
Epoch 002, Loss: 1.3812
Epoch 003, Loss: 1.3338
Epoch 004, Loss: 1.1984
Epoch 005, Loss: 1.2769
Epoch 006, Loss: 1.3230
Epoch 007, Loss: 1.2020
Epoch 008, Loss: 1.3179
Epoch 009, Loss: 1.2670
Epoch 010, Loss: 1.3171
Epoch 011, Loss: 1.4791
Epoch 012, Loss: 1.3130
Epoch 013, Loss: 1.2983
Epoch 014, Loss: 1.1663
Epoch 015, Loss: 1.3841
Epoch 016, Loss: 1.3019
Epoch 017, Loss: 1.1455
Epoch 018, Loss: 1.3528
Epoch 019, Loss: 1.2157
Epoch 020, Loss: 1.1999
Epoch 021, Loss: 1.2743
Epoch 022, Loss: 1.2131
Epoch 023, Loss: 1.2431
Epoch 024, Loss: 1.3758
Epoch 025, Loss: 1.3500
Epoch 026, Loss: 1.3854
Epoch 027, Loss: 1.3396
Epoch 028, Loss: 1.2815
Epoch 029, Loss: 1.1842
Epoch 030, Loss: 1.2701
Epoch 031, Loss: 1.2132
Epoch 032, Loss: 1.2321
Epoch 033, Loss: 1.1249
Epoch 034, Loss: 1.4054
Epoch 035, Loss: 1.3213
Epoch 036, Loss: 1.2013
Epoch 037, Loss: 1.2451
Epoch 038, Loss: 1.1325
Epoch 039, Loss: 1.4204
Epoch 040, Loss: 1.2005
Epoch 041, Loss: 1.2090
Epoch 042, Loss: 1.1843
Epoch 043, Loss: 1.1980
Epoch 044, Loss: 1.2012
Epoch 045, Loss: 1.1056
Epoch 046, Loss: 1.2602
Epoch 047, Loss: 1.2782
Epoch 048, Loss: 1.1678
Epoch 049, Loss: 1.1536
Epoch 050, Loss: 1.5168
Epoch 051, Loss: 1.0682
Epoch 052, Loss: 1.0822
Epoch 053, Loss: 1.1581
Epoch 054, Loss: 1.1035
Epoch 055, Loss: 1.2610
Epoch 056, Loss: 1.0461
Epoch 057, Loss: 0.9703
Epoch 058, Loss: 1.0463
Epoch 059, Loss: 1.0475
Epoch 060, Loss: 1.1153
Epoch 061, Loss: 0.9809
Epoch 062, Loss: 1.0168
Epoch 063, Loss: 0.9905
Epoch 064, Loss: 0.9171
Epoch 065, Loss: 1.0075
Epoch 066, Loss: 0.9061
Epoch 067, Loss: 0.8208
Epoch 068, Loss: 0.9262
Epoch 069, Loss: 0.9113
Epoch 070, Loss: 0.9101
Epoch 071, Loss: 0.9316
Epoch 072, Loss: 0.8797
Epoch 073, Loss: 0.9716
Epoch 074, Loss: 0.8224
Epoch 075, Loss: 0.8479
Epoch 076, Loss: 0.7572
Epoch 077, Loss: 0.7648
Epoch 078, Loss: 0.8406
Epoch 079, Loss: 0.7244
Epoch 080, Loss: 0.7026
Epoch 081, Loss: 0.7443
Epoch 082, Loss: 0.7257
Epoch 083, Loss: 0.7453
Epoch 084, Loss: 0.6896
Epoch 085, Loss: 0.7672
Epoch 086, Loss: 0.6489
Epoch 087, Loss: 0.7028
Epoch 088, Loss: 0.6710
Epoch 089, Loss: 0.6150
Epoch 090, Loss: 0.6151
Epoch 091, Loss: 0.6563
Epoch 092, Loss: 0.5619
Epoch 093, Loss: 0.5822
Epoch 094, Loss: 0.5964
Epoch 095, Loss: 0.6222
Epoch 096, Loss: 0.5295
Epoch 097, Loss: 0.6206
Epoch 098, Loss: 0.5741
Epoch 099, Loss: 0.5042
Epoch 100, Loss: 0.5291

Test RMSE: 1.0183
Test MAPE: 0.2629
Training time: 13.01 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 9.9346
Epoch 002, Loss: 1.7743
Epoch 003, Loss: 1.6286
Epoch 004, Loss: 1.6916
Epoch 005, Loss: 1.5700
Epoch 006, Loss: 1.5132
Epoch 007, Loss: 1.8410
Epoch 008, Loss: 1.6096
Epoch 009, Loss: 1.5219
Epoch 010, Loss: 1.5303
Epoch 011, Loss: 1.5950
Epoch 012, Loss: 1.8801
Epoch 013, Loss: 1.8193
Epoch 014, Loss: 1.5545
Epoch 015, Loss: 1.5601
Epoch 016, Loss: 1.5104
Epoch 017, Loss: 1.5611
Epoch 018, Loss: 1.5982
Epoch 019, Loss: 1.5341
Epoch 020, Loss: 1.5377
Epoch 021, Loss: 1.6870
Epoch 022, Loss: 1.5528
Epoch 023, Loss: 1.5217
Epoch 024, Loss: 1.5422
Epoch 025, Loss: 1.5536
Epoch 026, Loss: 1.5207
Epoch 027, Loss: 1.5851
Epoch 028, Loss: 1.6118
Epoch 029, Loss: 1.4156
Epoch 030, Loss: 1.8239
Epoch 031, Loss: 1.6243
Epoch 032, Loss: 1.4723
Epoch 033, Loss: 1.7612
Epoch 034, Loss: 1.5237
Epoch 035, Loss: 1.5455
Epoch 036, Loss: 1.5256
Epoch 037, Loss: 1.6175
Epoch 038, Loss: 1.5738
Epoch 039, Loss: 1.4720
Epoch 040, Loss: 1.5031
Epoch 041, Loss: 1.7803
Epoch 042, Loss: 1.7624
Epoch 043, Loss: 1.7880
Epoch 044, Loss: 1.5321
Epoch 045, Loss: 1.4387
Epoch 046, Loss: 1.5534
Epoch 047, Loss: 1.4599
Epoch 048, Loss: 1.6048
Epoch 049, Loss: 1.5821
Epoch 050, Loss: 1.6764
Epoch 051, Loss: 1.5401
Epoch 052, Loss: 1.5245
Epoch 053, Loss: 1.4860
Epoch 054, Loss: 1.5536
Epoch 055, Loss: 1.3772
Epoch 056, Loss: 1.7964
Epoch 057, Loss: 1.4968
Epoch 058, Loss: 1.5653
Epoch 059, Loss: 1.5274
Epoch 060, Loss: 1.8303
Epoch 061, Loss: 1.5273
Epoch 062, Loss: 1.4890
Epoch 063, Loss: 1.4231
Epoch 064, Loss: 1.4059
Epoch 065, Loss: 1.4273
Epoch 066, Loss: 1.8289
Epoch 067, Loss: 1.3753
Epoch 068, Loss: 1.4830
Epoch 069, Loss: 1.3693
Epoch 070, Loss: 1.4076
Epoch 071, Loss: 1.5599
Epoch 072, Loss: 1.4524
Epoch 073, Loss: 1.2917
Epoch 074, Loss: 1.5448
Epoch 075, Loss: 1.5983
Epoch 076, Loss: 1.4940
Epoch 077, Loss: 1.4241
Epoch 078, Loss: 1.4712
Epoch 079, Loss: 1.4825
Epoch 080, Loss: 1.4320
Epoch 081, Loss: 1.4611
Epoch 082, Loss: 1.4970
Epoch 083, Loss: 1.5242
Epoch 084, Loss: 1.4952
Epoch 085, Loss: 1.3495
Epoch 086, Loss: 1.5566
Epoch 087, Loss: 1.4869
Epoch 088, Loss: 1.5534
Epoch 089, Loss: 1.5155
Epoch 090, Loss: 1.4812
Epoch 091, Loss: 1.4800
Epoch 092, Loss: 1.3898
Epoch 093, Loss: 1.4154
Epoch 094, Loss: 1.5024
Epoch 095, Loss: 1.4830
Epoch 096, Loss: 1.5719
Epoch 097, Loss: 1.3821
Epoch 098, Loss: 1.3728
Epoch 099, Loss: 1.5015
Epoch 100, Loss: 1.4958

Test RMSE: 1.4543
Test MAPE: 0.1957
Training time: 13.32 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8920
Epoch 002, Loss: 3.1491
Epoch 003, Loss: 2.2412
Epoch 004, Loss: 1.1222
Epoch 005, Loss: 0.8611
Epoch 006, Loss: 0.7250
Epoch 007, Loss: 0.7489
Epoch 008, Loss: 0.7012
Epoch 009, Loss: 0.6876
Epoch 010, Loss: 0.6695
Epoch 011, Loss: 0.6574
Epoch 012, Loss: 0.6149
Epoch 013, Loss: 0.6711
Epoch 014, Loss: 0.6172
Epoch 015, Loss: 0.6407
Epoch 016, Loss: 0.6531
Epoch 017, Loss: 0.6459
Epoch 018, Loss: 0.6460
Epoch 019, Loss: 0.5956
Epoch 020, Loss: 0.6744
Epoch 021, Loss: 0.5983
Epoch 022, Loss: 0.5844
Epoch 023, Loss: 0.6195
Epoch 024, Loss: 0.6116
Epoch 025, Loss: 0.6903
Epoch 026, Loss: 0.6499
Epoch 027, Loss: 0.5993
Epoch 028, Loss: 0.6276
Epoch 029, Loss: 0.6472
Epoch 030, Loss: 0.5919
Epoch 031, Loss: 0.6158
Epoch 032, Loss: 0.5935
Epoch 033, Loss: 0.6099
Epoch 034, Loss: 0.6020
Epoch 035, Loss: 0.5413
Epoch 036, Loss: 0.6313
Epoch 037, Loss: 0.6216
Epoch 038, Loss: 0.5588
Epoch 039, Loss: 0.5786
Epoch 040, Loss: 0.5655
Epoch 041, Loss: 0.5875
Epoch 042, Loss: 0.5590
Epoch 043, Loss: 0.5262
Epoch 044, Loss: 0.5950
Epoch 045, Loss: 0.5868
Epoch 046, Loss: 0.5792
Epoch 047, Loss: 0.6200
Epoch 048, Loss: 0.5737
Epoch 049, Loss: 0.5523
Epoch 050, Loss: 0.5715
Epoch 051, Loss: 0.5875
Epoch 052, Loss: 0.5887
Epoch 053, Loss: 0.5699
Epoch 054, Loss: 0.5474
Epoch 055, Loss: 0.5994
Epoch 056, Loss: 0.5333
Epoch 057, Loss: 0.5363
Epoch 058, Loss: 0.5507
Epoch 059, Loss: 0.5775
Epoch 060, Loss: 0.5667
Epoch 061, Loss: 0.5694
Epoch 062, Loss: 0.5509
Epoch 063, Loss: 0.5315
Epoch 064, Loss: 0.5209
Epoch 065, Loss: 0.5578
Epoch 066, Loss: 0.5539
Epoch 067, Loss: 0.5610
Epoch 068, Loss: 0.5508
Epoch 069, Loss: 0.5214
Epoch 070, Loss: 0.5442
Epoch 071, Loss: 0.5264
Epoch 072, Loss: 0.5223
Epoch 073, Loss: 0.5420
Epoch 074, Loss: 0.5064
Epoch 075, Loss: 0.5044
Epoch 076, Loss: 0.5133
Epoch 077, Loss: 0.5122
Epoch 078, Loss: 0.4860
Epoch 079, Loss: 0.5116
Epoch 080, Loss: 0.5181
Epoch 081, Loss: 0.5711
Epoch 082, Loss: 0.5204
Epoch 083, Loss: 0.4838
Epoch 084, Loss: 0.4756
Epoch 085, Loss: 0.5081
Epoch 086, Loss: 0.5332
Epoch 087, Loss: 0.6231
Epoch 088, Loss: 0.4894
Epoch 089, Loss: 0.4880
Epoch 090, Loss: 0.5122
Epoch 091, Loss: 0.5217
Epoch 092, Loss: 0.4828
Epoch 093, Loss: 0.4856
Epoch 094, Loss: 0.4853
Epoch 095, Loss: 0.4811
Epoch 096, Loss: 0.4719
Epoch 097, Loss: 0.5164
Epoch 098, Loss: 0.4516
Epoch 099, Loss: 0.4907
Epoch 100, Loss: 0.4881

Test RMSE: 0.7483
Test MAPE: 251383529865216.0000
Training time: 64.84 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.608074 2.022864e-01      12.426100   GNN_model_10.pkl
       12   Q_values        0.2 0.623780 1.819459e-01      12.381444   GNN_model_12.pkl
       15   Q_values        0.2 0.880432 2.084891e-01      12.575135   GNN_model_15.pkl
       20   Q_values        0.2 1.018326 2.629161e-01      13.009245   GNN_model_20.pkl
       25   Q_values        0.2 1.454274 1.956639e-01      13.321226   GNN_model_25.pkl
     full   Q_values        0.2 0.748273 2.513835e+14      64.839010 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 74%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
