
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59770
 Mean Absolute Percentage Error: 0.25497
 Training time:  0.07950
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55181
 Mean Absolute Percentage Error: 0.39635
 Training time:  0.07867
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71638
 Mean Absolute Percentage Error: 0.57797
 Training time:  0.13039
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86119
 Mean Absolute Percentage Error: 0.53689
 Training time:  0.01633
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70512
 Mean Absolute Percentage Error: 0.30313
 Training time:  0.03409
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52331
 Mean Absolute Percentage Error: 0.17636
 Training time:  0.04972
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60434
 Mean Absolute Percentage Error: 0.22703
 Training time:  0.04904
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61113
 Mean Absolute Percentage Error: 0.25834
 Training time:  0.05135
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53812
 Mean Absolute Percentage Error: 0.17846
 Training time:  0.09887
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67632
 Mean Absolute Percentage Error: 0.21806
 Training time:  0.01634
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61708
 Mean Absolute Percentage Error: 0.23960
 Training time:  0.10416
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65551
 Mean Absolute Percentage Error: 0.29526
 Training time:  0.02048
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60158
  MAPE on 10 nodes subset: 0.26723

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71113
  MAPE on 12 nodes subset: 0.57148

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68700
  MAPE on 15 nodes subset: 0.29286

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58637
  MAPE on 20 nodes subset: 0.22837

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53059
  MAPE on 25 nodes subset: 0.18541

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597699 0.254974       0.079504       True             4                       MLP_model_10.pkl       64
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.551809 0.396347       0.078671       True             4               MLP_model_10_Circuit.pkl       64
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.716381 0.577971       0.130392       True             4                       MLP_model_12.pkl       64
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.861185 0.536888       0.016335       True             4               MLP_model_12_Circuit.pkl       64
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705120 0.303134       0.034092       True             4                       MLP_model_15.pkl       64
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.523309 0.176357       0.049715       True             4               MLP_model_15_Circuit.pkl       64
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604336 0.227034       0.049041       True             4                       MLP_model_20.pkl       64
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611130 0.258344       0.051348       True             4               MLP_model_20_Circuit.pkl       64
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.538120 0.178464       0.098869       True             4                       MLP_model_25.pkl       64
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.676324 0.218064       0.016343       True             4               MLP_model_25_Circuit.pkl       64
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617081 0.239595       0.104156       True             4                     MLP_model_full.pkl       64
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.655512 0.295261       0.020478       True             4             MLP_model_full_Circuit.pkl       64
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601580 0.267227       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       64
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.711125 0.571477       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       64
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686997 0.292859       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       64
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586365 0.228373       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       64
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.530591 0.185406       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       64

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.62788
 Mean Absolute Percentage Error: 0.46279
 Training time:  0.36492
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.75221
 Mean Absolute Percentage Error: 0.39305
 Training time:  0.24292
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.02637
 Mean Absolute Percentage Error: 0.68700
 Training time:  0.37466
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10098
 Mean Absolute Percentage Error: 0.66066
 Training time:  0.24246
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.60445
 Mean Absolute Percentage Error: 0.18979
 Training time:  0.44188
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79293
 Mean Absolute Percentage Error: 0.22753
 Training time:  0.24060
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65063
 Mean Absolute Percentage Error: 0.27899
 Training time:  0.64775
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84965
 Mean Absolute Percentage Error: 0.33119
 Training time:  0.24460
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.76769
 Mean Absolute Percentage Error: 0.23120
 Training time:  0.70643
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70140
 Mean Absolute Percentage Error: 0.18329
 Training time:  0.24091
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72044
 Mean Absolute Percentage Error: 0.30720
 Training time:  2.98918
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75175
 Mean Absolute Percentage Error: 0.30024
 Training time:  0.29954
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24193
  MAPE on 10 nodes subset: 0.02341

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.33874
  MAPE on 12 nodes subset: 0.25914

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.17470
  MAPE on 15 nodes subset: 0.02049

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39839
  MAPE on 20 nodes subset: 0.09313

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.21880
  MAPE on 25 nodes subset: 0.02808

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.627878 0.462787       0.364924                           xgboost_model_10.pkl       26
       10             Circuit            50           5          4 0.752209 0.393052       0.242921                   xgboost_model_10_Circuit.pkl       26
       12            Q_values            50          78          4 1.026366 0.686996       0.374665                           xgboost_model_12.pkl       26
       12             Circuit            50           5          4 1.100981 0.660664       0.242463                   xgboost_model_12_Circuit.pkl       26
       15            Q_values            50         120          4 0.604454 0.189793       0.441881                           xgboost_model_15.pkl       26
       15             Circuit            50           5          4 0.792931 0.227525       0.240596                   xgboost_model_15_Circuit.pkl       26
       20            Q_values            50         210          4 0.650633 0.278987       0.647752                           xgboost_model_20.pkl       26
       20             Circuit            50           5          4 0.849647 0.331191       0.244596                   xgboost_model_20_Circuit.pkl       26
       25            Q_values            50         325          4 0.767692 0.231205       0.706433                           xgboost_model_25.pkl       26
       25             Circuit            50           5          4 0.701404 0.183288       0.240911                   xgboost_model_25_Circuit.pkl       26
     full            Q_values           250         325          4 0.720442 0.307205       2.989184                         xgboost_model_full.pkl       26
     full             Circuit           250           5          4 0.751749 0.300236       0.299541                 xgboost_model_full_Circuit.pkl       26
       10 Q_values_full_model            50         325          4 0.241929 0.023408       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       26
       12 Q_values_full_model            50         325          4 0.338744 0.259142       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       26
       15 Q_values_full_model            50         325          4 0.174703 0.020485       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       26
       20 Q_values_full_model            50         325          4 0.398394 0.093126       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       26
       25 Q_values_full_model            50         325          4 0.218803 0.028079       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       26

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.6275
Epoch 002, Loss: 0.6543
Epoch 003, Loss: 0.6342
Epoch 004, Loss: 0.6080
Epoch 005, Loss: 0.5848
Epoch 006, Loss: 0.5915
Epoch 007, Loss: 0.6123
Epoch 008, Loss: 0.5824
Epoch 009, Loss: 0.6092
Epoch 010, Loss: 0.5701
Epoch 011, Loss: 0.5830
Epoch 012, Loss: 0.6113
Epoch 013, Loss: 0.5798
Epoch 014, Loss: 0.5413
Epoch 015, Loss: 0.5915
Epoch 016, Loss: 0.5336
Epoch 017, Loss: 0.5738
Epoch 018, Loss: 0.5788
Epoch 019, Loss: 0.5667
Epoch 020, Loss: 0.5546
Epoch 021, Loss: 0.5857
Epoch 022, Loss: 0.5537
Epoch 023, Loss: 0.5668
Epoch 024, Loss: 0.5467
Epoch 025, Loss: 0.5412
Epoch 026, Loss: 0.5594
Epoch 027, Loss: 0.5412
Epoch 028, Loss: 0.5611
Epoch 029, Loss: 0.5372
Epoch 030, Loss: 0.5369
Epoch 031, Loss: 0.5352
Epoch 032, Loss: 0.5280
Epoch 033, Loss: 0.5885
Epoch 034, Loss: 0.5469
Epoch 035, Loss: 0.5483
Epoch 036, Loss: 0.5305
Epoch 037, Loss: 0.5291
Epoch 038, Loss: 0.5308
Epoch 039, Loss: 0.5777
Epoch 040, Loss: 0.5374
Epoch 041, Loss: 0.5069
Epoch 042, Loss: 0.5332
Epoch 043, Loss: 0.5346
Epoch 044, Loss: 0.5225
Epoch 045, Loss: 0.5346
Epoch 046, Loss: 0.5202
Epoch 047, Loss: 0.5687
Epoch 048, Loss: 0.5453
Epoch 049, Loss: 0.5267
Epoch 050, Loss: 0.5092
Epoch 051, Loss: 0.5564
Epoch 052, Loss: 0.5423
Epoch 053, Loss: 0.4979
Epoch 054, Loss: 0.5012
Epoch 055, Loss: 0.5170
Epoch 056, Loss: 0.5226
Epoch 057, Loss: 0.4991
Epoch 058, Loss: 0.5009
Epoch 059, Loss: 0.5066
Epoch 060, Loss: 0.4926
Epoch 061, Loss: 0.5039
Epoch 062, Loss: 0.5153
Epoch 063, Loss: 0.4949
Epoch 064, Loss: 0.4858
Epoch 065, Loss: 0.4994
Epoch 066, Loss: 0.5013
Epoch 067, Loss: 0.4963
Epoch 068, Loss: 0.5037
Epoch 069, Loss: 0.5009
Epoch 070, Loss: 0.4810
Epoch 071, Loss: 0.4870
Epoch 072, Loss: 0.4962
Epoch 073, Loss: 0.4984
Epoch 074, Loss: 0.4818
Epoch 075, Loss: 0.4841
Epoch 076, Loss: 0.4791
Epoch 077, Loss: 0.4734
Epoch 078, Loss: 0.4928
Epoch 079, Loss: 0.4812
Epoch 080, Loss: 0.4747
Epoch 081, Loss: 0.4889
Epoch 082, Loss: 0.4658
Epoch 083, Loss: 0.4834
Epoch 084, Loss: 0.4596
Epoch 085, Loss: 0.4827
Epoch 086, Loss: 0.4448
Epoch 087, Loss: 0.4724
Epoch 088, Loss: 0.4956
Epoch 089, Loss: 0.5010
Epoch 090, Loss: 0.4538
Epoch 091, Loss: 0.4702
Epoch 092, Loss: 0.4483
Epoch 093, Loss: 0.4570
Epoch 094, Loss: 0.4463
Epoch 095, Loss: 0.4554
Epoch 096, Loss: 0.4433
Epoch 097, Loss: 0.4390
Epoch 098, Loss: 0.4394
Epoch 099, Loss: 0.4326
Epoch 100, Loss: 0.4436

Test RMSE: 0.6070
Test MAPE: 0.2218
Training time: 12.36 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.5111
Epoch 002, Loss: 0.8923
Epoch 003, Loss: 0.9205
Epoch 004, Loss: 0.7994
Epoch 005, Loss: 0.8838
Epoch 006, Loss: 0.8431
Epoch 007, Loss: 1.0144
Epoch 008, Loss: 0.9441
Epoch 009, Loss: 0.9319
Epoch 010, Loss: 0.9351
Epoch 011, Loss: 0.8441
Epoch 012, Loss: 0.8890
Epoch 013, Loss: 0.8542
Epoch 014, Loss: 0.8728
Epoch 015, Loss: 0.8945
Epoch 016, Loss: 1.0940
Epoch 017, Loss: 0.8468
Epoch 018, Loss: 0.8642
Epoch 019, Loss: 0.9084
Epoch 020, Loss: 0.8209
Epoch 021, Loss: 0.8549
Epoch 022, Loss: 0.8252
Epoch 023, Loss: 0.7982
Epoch 024, Loss: 0.8077
Epoch 025, Loss: 0.8427
Epoch 026, Loss: 0.8413
Epoch 027, Loss: 0.8917
Epoch 028, Loss: 1.0016
Epoch 029, Loss: 0.8692
Epoch 030, Loss: 0.8728
Epoch 031, Loss: 0.7875
Epoch 032, Loss: 0.9360
Epoch 033, Loss: 0.8300
Epoch 034, Loss: 0.8385
Epoch 035, Loss: 0.8197
Epoch 036, Loss: 0.7885
Epoch 037, Loss: 0.8303
Epoch 038, Loss: 0.7655
Epoch 039, Loss: 0.8749
Epoch 040, Loss: 0.8075
Epoch 041, Loss: 0.8125
Epoch 042, Loss: 0.7874
Epoch 043, Loss: 0.7945
Epoch 044, Loss: 0.7920
Epoch 045, Loss: 0.7528
Epoch 046, Loss: 0.8051
Epoch 047, Loss: 0.7687
Epoch 048, Loss: 0.7646
Epoch 049, Loss: 0.7694
Epoch 050, Loss: 0.7897
Epoch 051, Loss: 0.7728
Epoch 052, Loss: 0.7721
Epoch 053, Loss: 0.7531
Epoch 054, Loss: 0.7411
Epoch 055, Loss: 0.7999
Epoch 056, Loss: 0.7482
Epoch 057, Loss: 0.7705
Epoch 058, Loss: 0.7388
Epoch 059, Loss: 0.7284
Epoch 060, Loss: 0.7429
Epoch 061, Loss: 0.7222
Epoch 062, Loss: 0.7242
Epoch 063, Loss: 0.7386
Epoch 064, Loss: 0.7031
Epoch 065, Loss: 0.7244
Epoch 066, Loss: 0.7414
Epoch 067, Loss: 0.6948
Epoch 068, Loss: 0.6843
Epoch 069, Loss: 0.6777
Epoch 070, Loss: 0.7415
Epoch 071, Loss: 0.6475
Epoch 072, Loss: 0.6811
Epoch 073, Loss: 0.6788
Epoch 074, Loss: 0.7040
Epoch 075, Loss: 0.7237
Epoch 076, Loss: 0.7141
Epoch 077, Loss: 0.6544
Epoch 078, Loss: 0.6745
Epoch 079, Loss: 0.6231
Epoch 080, Loss: 0.6240
Epoch 081, Loss: 0.6937
Epoch 082, Loss: 0.6710
Epoch 083, Loss: 0.6349
Epoch 084, Loss: 0.6785
Epoch 085, Loss: 0.6201
Epoch 086, Loss: 0.6127
Epoch 087, Loss: 0.6118
Epoch 088, Loss: 0.6061
Epoch 089, Loss: 0.6248
Epoch 090, Loss: 0.6255
Epoch 091, Loss: 0.6023
Epoch 092, Loss: 0.6040
Epoch 093, Loss: 0.5856
Epoch 094, Loss: 0.5900
Epoch 095, Loss: 0.5879
Epoch 096, Loss: 0.6012
Epoch 097, Loss: 0.6159
Epoch 098, Loss: 0.5957
Epoch 099, Loss: 0.6084
Epoch 100, Loss: 0.5818

Test RMSE: 0.6669
Test MAPE: 0.1941
Training time: 12.26 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.6982
Epoch 002, Loss: 0.9986
Epoch 003, Loss: 0.9034
Epoch 004, Loss: 0.9365
Epoch 005, Loss: 0.9281
Epoch 006, Loss: 0.9700
Epoch 007, Loss: 0.9664
Epoch 008, Loss: 0.9003
Epoch 009, Loss: 0.9162
Epoch 010, Loss: 0.9821
Epoch 011, Loss: 0.9900
Epoch 012, Loss: 0.9459
Epoch 013, Loss: 1.0272
Epoch 014, Loss: 0.9725
Epoch 015, Loss: 1.0703
Epoch 016, Loss: 0.8983
Epoch 017, Loss: 0.9614
Epoch 018, Loss: 1.0844
Epoch 019, Loss: 0.9745
Epoch 020, Loss: 0.9223
Epoch 021, Loss: 0.9506
Epoch 022, Loss: 0.9323
Epoch 023, Loss: 0.9064
Epoch 024, Loss: 0.9775
Epoch 025, Loss: 0.8991
Epoch 026, Loss: 0.8883
Epoch 027, Loss: 0.9810
Epoch 028, Loss: 0.9375
Epoch 029, Loss: 0.9030
Epoch 030, Loss: 0.8897
Epoch 031, Loss: 0.9133
Epoch 032, Loss: 0.8935
Epoch 033, Loss: 0.9703
Epoch 034, Loss: 0.8869
Epoch 035, Loss: 0.8493
Epoch 036, Loss: 0.9296
Epoch 037, Loss: 0.8491
Epoch 038, Loss: 0.8420
Epoch 039, Loss: 0.8960
Epoch 040, Loss: 0.9002
Epoch 041, Loss: 0.8954
Epoch 042, Loss: 0.8512
Epoch 043, Loss: 0.8618
Epoch 044, Loss: 0.8585
Epoch 045, Loss: 0.9157
Epoch 046, Loss: 0.8108
Epoch 047, Loss: 0.8541
Epoch 048, Loss: 0.8006
Epoch 049, Loss: 0.8393
Epoch 050, Loss: 0.7585
Epoch 051, Loss: 0.7902
Epoch 052, Loss: 0.8522
Epoch 053, Loss: 0.8250
Epoch 054, Loss: 0.7828
Epoch 055, Loss: 0.7555
Epoch 056, Loss: 0.7313
Epoch 057, Loss: 0.7768
Epoch 058, Loss: 0.7741
Epoch 059, Loss: 0.8032
Epoch 060, Loss: 0.7227
Epoch 061, Loss: 0.7225
Epoch 062, Loss: 0.7259
Epoch 063, Loss: 0.7132
Epoch 064, Loss: 0.6676
Epoch 065, Loss: 0.7505
Epoch 066, Loss: 0.6774
Epoch 067, Loss: 0.6829
Epoch 068, Loss: 0.7031
Epoch 069, Loss: 0.6912
Epoch 070, Loss: 0.6739
Epoch 071, Loss: 0.6844
Epoch 072, Loss: 0.6589
Epoch 073, Loss: 0.7044
Epoch 074, Loss: 0.7201
Epoch 075, Loss: 0.6478
Epoch 076, Loss: 0.6630
Epoch 077, Loss: 0.6758
Epoch 078, Loss: 0.6564
Epoch 079, Loss: 0.6922
Epoch 080, Loss: 0.6406
Epoch 081, Loss: 0.6763
Epoch 082, Loss: 0.6037
Epoch 083, Loss: 0.6242
Epoch 084, Loss: 0.6245
Epoch 085, Loss: 0.6177
Epoch 086, Loss: 0.6250
Epoch 087, Loss: 0.5942
Epoch 088, Loss: 0.6274
Epoch 089, Loss: 0.5809
Epoch 090, Loss: 0.5637
Epoch 091, Loss: 0.5788
Epoch 092, Loss: 0.5775
Epoch 093, Loss: 0.5983
Epoch 094, Loss: 0.6852
Epoch 095, Loss: 0.6372
Epoch 096, Loss: 0.6290
Epoch 097, Loss: 0.6726
Epoch 098, Loss: 0.6200
Epoch 099, Loss: 0.5823
Epoch 100, Loss: 0.5551

Test RMSE: 0.9537
Test MAPE: 0.2374
Training time: 12.47 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.7507
Epoch 002, Loss: 1.2543
Epoch 003, Loss: 1.2375
Epoch 004, Loss: 1.2498
Epoch 005, Loss: 1.2824
Epoch 006, Loss: 1.2436
Epoch 007, Loss: 1.2302
Epoch 008, Loss: 1.1729
Epoch 009, Loss: 1.2037
Epoch 010, Loss: 1.2594
Epoch 011, Loss: 1.2041
Epoch 012, Loss: 1.3839
Epoch 013, Loss: 1.2840
Epoch 014, Loss: 1.2686
Epoch 015, Loss: 1.2778
Epoch 016, Loss: 1.3092
Epoch 017, Loss: 1.0889
Epoch 018, Loss: 1.3500
Epoch 019, Loss: 1.2254
Epoch 020, Loss: 1.1337
Epoch 021, Loss: 1.3053
Epoch 022, Loss: 1.1772
Epoch 023, Loss: 1.1980
Epoch 024, Loss: 1.2037
Epoch 025, Loss: 1.1631
Epoch 026, Loss: 1.5420
Epoch 027, Loss: 1.2662
Epoch 028, Loss: 1.4789
Epoch 029, Loss: 1.1459
Epoch 030, Loss: 1.2873
Epoch 031, Loss: 1.1465
Epoch 032, Loss: 1.2950
Epoch 033, Loss: 1.2436
Epoch 034, Loss: 1.2118
Epoch 035, Loss: 1.2705
Epoch 036, Loss: 1.2805
Epoch 037, Loss: 1.1446
Epoch 038, Loss: 1.2107
Epoch 039, Loss: 1.1956
Epoch 040, Loss: 1.1366
Epoch 041, Loss: 1.2693
Epoch 042, Loss: 1.2764
Epoch 043, Loss: 1.0729
Epoch 044, Loss: 1.1283
Epoch 045, Loss: 1.1756
Epoch 046, Loss: 1.0509
Epoch 047, Loss: 1.1270
Epoch 048, Loss: 1.1157
Epoch 049, Loss: 0.9859
Epoch 050, Loss: 1.0026
Epoch 051, Loss: 0.9529
Epoch 052, Loss: 1.0787
Epoch 053, Loss: 0.9730
Epoch 054, Loss: 0.9136
Epoch 055, Loss: 0.8371
Epoch 056, Loss: 0.8933
Epoch 057, Loss: 0.8159
Epoch 058, Loss: 0.9235
Epoch 059, Loss: 0.7966
Epoch 060, Loss: 0.8006
Epoch 061, Loss: 0.8805
Epoch 062, Loss: 0.8295
Epoch 063, Loss: 0.7768
Epoch 064, Loss: 0.7709
Epoch 065, Loss: 0.7828
Epoch 066, Loss: 0.7524
Epoch 067, Loss: 0.8180
Epoch 068, Loss: 0.9072
Epoch 069, Loss: 0.8060
Epoch 070, Loss: 0.7087
Epoch 071, Loss: 0.7966
Epoch 072, Loss: 0.7301
Epoch 073, Loss: 0.7297
Epoch 074, Loss: 0.7089
Epoch 075, Loss: 0.7438
Epoch 076, Loss: 0.7346
Epoch 077, Loss: 0.7071
Epoch 078, Loss: 0.7509
Epoch 079, Loss: 0.7010
Epoch 080, Loss: 0.6492
Epoch 081, Loss: 0.7211
Epoch 082, Loss: 0.7030
Epoch 083, Loss: 0.7121
Epoch 084, Loss: 0.6403
Epoch 085, Loss: 0.7024
Epoch 086, Loss: 0.7026
Epoch 087, Loss: 0.6917
Epoch 088, Loss: 0.6646
Epoch 089, Loss: 0.6995
Epoch 090, Loss: 0.7810
Epoch 091, Loss: 0.6379
Epoch 092, Loss: 0.6648
Epoch 093, Loss: 0.7253
Epoch 094, Loss: 0.7001
Epoch 095, Loss: 0.6549
Epoch 096, Loss: 0.7428
Epoch 097, Loss: 0.6914
Epoch 098, Loss: 0.6809
Epoch 099, Loss: 0.6336
Epoch 100, Loss: 0.5669

Test RMSE: 0.8863
Test MAPE: 0.2053
Training time: 12.96 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.7484
Epoch 002, Loss: 2.1128
Epoch 003, Loss: 1.6823
Epoch 004, Loss: 1.8457
Epoch 005, Loss: 1.5810
Epoch 006, Loss: 1.5613
Epoch 007, Loss: 1.5066
Epoch 008, Loss: 2.1062
Epoch 009, Loss: 1.6041
Epoch 010, Loss: 1.6326
Epoch 011, Loss: 1.5086
Epoch 012, Loss: 1.7850
Epoch 013, Loss: 1.6469
Epoch 014, Loss: 1.7316
Epoch 015, Loss: 1.7280
Epoch 016, Loss: 1.5822
Epoch 017, Loss: 1.5008
Epoch 018, Loss: 1.7699
Epoch 019, Loss: 1.6566
Epoch 020, Loss: 1.8526
Epoch 021, Loss: 1.6740
Epoch 022, Loss: 1.5987
Epoch 023, Loss: 1.5305
Epoch 024, Loss: 1.5051
Epoch 025, Loss: 1.4883
Epoch 026, Loss: 1.9285
Epoch 027, Loss: 1.6405
Epoch 028, Loss: 1.5773
Epoch 029, Loss: 1.5575
Epoch 030, Loss: 1.6861
Epoch 031, Loss: 1.6168
Epoch 032, Loss: 1.5187
Epoch 033, Loss: 1.5786
Epoch 034, Loss: 1.6572
Epoch 035, Loss: 1.4738
Epoch 036, Loss: 1.6296
Epoch 037, Loss: 1.4752
Epoch 038, Loss: 1.4961
Epoch 039, Loss: 1.5391
Epoch 040, Loss: 1.4608
Epoch 041, Loss: 1.5621
Epoch 042, Loss: 1.5401
Epoch 043, Loss: 1.5568
Epoch 044, Loss: 1.5430
Epoch 045, Loss: 1.6034
Epoch 046, Loss: 1.4834
Epoch 047, Loss: 1.4723
Epoch 048, Loss: 1.4377
Epoch 049, Loss: 1.4190
Epoch 050, Loss: 1.4964
Epoch 051, Loss: 1.6106
Epoch 052, Loss: 1.4127
Epoch 053, Loss: 1.5337
Epoch 054, Loss: 1.2860
Epoch 055, Loss: 1.4208
Epoch 056, Loss: 1.5411
Epoch 057, Loss: 1.3915
Epoch 058, Loss: 1.4035
Epoch 059, Loss: 1.4664
Epoch 060, Loss: 1.4115
Epoch 061, Loss: 1.6518
Epoch 062, Loss: 1.5760
Epoch 063, Loss: 1.5786
Epoch 064, Loss: 1.6365
Epoch 065, Loss: 1.4977
Epoch 066, Loss: 1.6418
Epoch 067, Loss: 1.4074
Epoch 068, Loss: 1.5152
Epoch 069, Loss: 1.4216
Epoch 070, Loss: 1.7120
Epoch 071, Loss: 1.3313
Epoch 072, Loss: 1.5382
Epoch 073, Loss: 1.4236
Epoch 074, Loss: 1.3212
Epoch 075, Loss: 1.4772
Epoch 076, Loss: 1.5626
Epoch 077, Loss: 1.3660
Epoch 078, Loss: 1.6026
Epoch 079, Loss: 1.5693
Epoch 080, Loss: 1.5399
Epoch 081, Loss: 1.5840
Epoch 082, Loss: 1.4062
Epoch 083, Loss: 1.3618
Epoch 084, Loss: 1.3609
Epoch 085, Loss: 1.3854
Epoch 086, Loss: 1.4606
Epoch 087, Loss: 1.6207
Epoch 088, Loss: 1.4211
Epoch 089, Loss: 1.2966
Epoch 090, Loss: 1.6691
Epoch 091, Loss: 1.6736
Epoch 092, Loss: 1.4879
Epoch 093, Loss: 1.7066
Epoch 094, Loss: 1.5840
Epoch 095, Loss: 1.5176
Epoch 096, Loss: 1.4490
Epoch 097, Loss: 1.6169
Epoch 098, Loss: 1.3710
Epoch 099, Loss: 1.3778
Epoch 100, Loss: 1.4151

Test RMSE: 1.6881
Test MAPE: 0.2258
Training time: 13.20 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7710
Epoch 002, Loss: 3.3481
Epoch 003, Loss: 2.5452
Epoch 004, Loss: 0.9656
Epoch 005, Loss: 0.7609
Epoch 006, Loss: 0.8192
Epoch 007, Loss: 0.7217
Epoch 008, Loss: 0.7700
Epoch 009, Loss: 0.6656
Epoch 010, Loss: 0.6842
Epoch 011, Loss: 0.6626
Epoch 012, Loss: 0.6117
Epoch 013, Loss: 0.6330
Epoch 014, Loss: 0.7101
Epoch 015, Loss: 0.6728
Epoch 016, Loss: 0.6228
Epoch 017, Loss: 0.5861
Epoch 018, Loss: 0.6087
Epoch 019, Loss: 0.5832
Epoch 020, Loss: 0.6079
Epoch 021, Loss: 0.6559
Epoch 022, Loss: 0.5872
Epoch 023, Loss: 0.5800
Epoch 024, Loss: 0.6667
Epoch 025, Loss: 0.5820
Epoch 026, Loss: 0.6075
Epoch 027, Loss: 0.5788
Epoch 028, Loss: 0.6126
Epoch 029, Loss: 0.6252
Epoch 030, Loss: 0.6480
Epoch 031, Loss: 0.5979
Epoch 032, Loss: 0.5723
Epoch 033, Loss: 0.5581
Epoch 034, Loss: 0.5596
Epoch 035, Loss: 0.5938
Epoch 036, Loss: 0.5748
Epoch 037, Loss: 0.6335
Epoch 038, Loss: 0.5728
Epoch 039, Loss: 0.5155
Epoch 040, Loss: 0.5594
Epoch 041, Loss: 0.5435
Epoch 042, Loss: 0.6001
Epoch 043, Loss: 0.5855
Epoch 044, Loss: 0.5974
Epoch 045, Loss: 0.5802
Epoch 046, Loss: 0.5674
Epoch 047, Loss: 0.6221
Epoch 048, Loss: 0.5657
Epoch 049, Loss: 0.5696
Epoch 050, Loss: 0.5635
Epoch 051, Loss: 0.5665
Epoch 052, Loss: 0.5556
Epoch 053, Loss: 0.5757
Epoch 054, Loss: 0.5611
Epoch 055, Loss: 0.5475
Epoch 056, Loss: 0.5487
Epoch 057, Loss: 0.5392
Epoch 058, Loss: 0.5518
Epoch 059, Loss: 0.6159
Epoch 060, Loss: 0.5696
Epoch 061, Loss: 0.5121
Epoch 062, Loss: 0.5351
Epoch 063, Loss: 0.5264
Epoch 064, Loss: 0.5294
Epoch 065, Loss: 0.6222
Epoch 066, Loss: 0.5355
Epoch 067, Loss: 0.4978
Epoch 068, Loss: 0.5658
Epoch 069, Loss: 0.5643
Epoch 070, Loss: 0.5416
Epoch 071, Loss: 0.4883
Epoch 072, Loss: 0.5336
Epoch 073, Loss: 0.5643
Epoch 074, Loss: 0.5053
Epoch 075, Loss: 0.5172
Epoch 076, Loss: 0.5378
Epoch 077, Loss: 0.4916
Epoch 078, Loss: 0.5242
Epoch 079, Loss: 0.5514
Epoch 080, Loss: 0.5074
Epoch 081, Loss: 0.5068
Epoch 082, Loss: 0.5130
Epoch 083, Loss: 0.4902
Epoch 084, Loss: 0.5414
Epoch 085, Loss: 0.5186
Epoch 086, Loss: 0.5600
Epoch 087, Loss: 0.5691
Epoch 088, Loss: 0.5158
Epoch 089, Loss: 0.5183
Epoch 090, Loss: 0.5325
Epoch 091, Loss: 0.4941
Epoch 092, Loss: 0.5174
Epoch 093, Loss: 0.5089
Epoch 094, Loss: 0.4937
Epoch 095, Loss: 0.5075
Epoch 096, Loss: 0.5598
Epoch 097, Loss: 0.4950
Epoch 098, Loss: 0.5069
Epoch 099, Loss: 0.5079
Epoch 100, Loss: 0.5037

Test RMSE: 0.6561
Test MAPE: 214184314798080.0000
Training time: 64.61 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.607048 2.218241e-01      12.362229   GNN_model_10.pkl
       12   Q_values        0.2 0.666934 1.940977e-01      12.262996   GNN_model_12.pkl
       15   Q_values        0.2 0.953682 2.373622e-01      12.472772   GNN_model_15.pkl
       20   Q_values        0.2 0.886318 2.053253e-01      12.957422   GNN_model_20.pkl
       25   Q_values        0.2 1.688092 2.258267e-01      13.195451   GNN_model_25.pkl
     full   Q_values        0.2 0.656109 2.141843e+14      64.610529 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 51%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
