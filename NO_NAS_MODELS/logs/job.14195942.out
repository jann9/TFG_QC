
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59827
 Mean Absolute Percentage Error: 0.25574
 Training time:  0.19637
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55337
 Mean Absolute Percentage Error: 0.39882
 Training time:  0.10740
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71686
 Mean Absolute Percentage Error: 0.57578
 Training time:  0.13470
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86322
 Mean Absolute Percentage Error: 0.54049
 Training time:  0.04754
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70467
 Mean Absolute Percentage Error: 0.30339
 Training time:  0.08329
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52136
 Mean Absolute Percentage Error: 0.17739
 Training time:  0.11698
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60427
 Mean Absolute Percentage Error: 0.22663
 Training time:  0.10944
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61151
 Mean Absolute Percentage Error: 0.26010
 Training time:  0.11755
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53785
 Mean Absolute Percentage Error: 0.17754
 Training time:  0.22905
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67460
 Mean Absolute Percentage Error: 0.21903
 Training time:  0.03791
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61761
 Mean Absolute Percentage Error: 0.23962
 Training time:  0.19576
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65476
 Mean Absolute Percentage Error: 0.29723
 Training time:  0.05449
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60189
  MAPE on 10 nodes subset: 0.26842

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71119
  MAPE on 12 nodes subset: 0.57036

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68548
  MAPE on 15 nodes subset: 0.29128

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58521
  MAPE on 20 nodes subset: 0.22724

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53021
  MAPE on 25 nodes subset: 0.18471

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.598270 0.255736       0.196373       True             4                       MLP_model_10.pkl       80
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553370 0.398824       0.107399       True             4               MLP_model_10_Circuit.pkl       80
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.716859 0.575777       0.134698       True             4                       MLP_model_12.pkl       80
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863216 0.540493       0.047541       True             4               MLP_model_12_Circuit.pkl       80
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704672 0.303391       0.083289       True             4                       MLP_model_15.pkl       80
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521362 0.177387       0.116975       True             4               MLP_model_15_Circuit.pkl       80
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604267 0.226626       0.109442       True             4                       MLP_model_20.pkl       80
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611511 0.260099       0.117555       True             4               MLP_model_20_Circuit.pkl       80
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.537852 0.177539       0.229052       True             4                       MLP_model_25.pkl       80
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674600 0.219029       0.037914       True             4               MLP_model_25_Circuit.pkl       80
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617606 0.239619       0.195758       True             4                     MLP_model_full.pkl       80
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654760 0.297228       0.054491       True             4             MLP_model_full_Circuit.pkl       80
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601886 0.268418       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       80
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.711195 0.570361       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       80
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.685480 0.291278       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       80
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585206 0.227237       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       80
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.530214 0.184710       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       80

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.60763
 Mean Absolute Percentage Error: 0.44661
 Training time:  0.53407
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.77623
 Mean Absolute Percentage Error: 0.40382
 Training time:  0.43051
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.98760
 Mean Absolute Percentage Error: 0.66756
 Training time:  0.53504
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10581
 Mean Absolute Percentage Error: 0.66194
 Training time:  0.41880
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.60492
 Mean Absolute Percentage Error: 0.18966
 Training time:  0.67349
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79830
 Mean Absolute Percentage Error: 0.22902
 Training time:  0.42252
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.64595
 Mean Absolute Percentage Error: 0.26920
 Training time:  0.90198
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84966
 Mean Absolute Percentage Error: 0.33072
 Training time:  0.43508
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.72191
 Mean Absolute Percentage Error: 0.21965
 Training time:  0.99753
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70458
 Mean Absolute Percentage Error: 0.18548
 Training time:  0.41423
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72713
 Mean Absolute Percentage Error: 0.30452
 Training time:  3.79252
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74965
 Mean Absolute Percentage Error: 0.30099
 Training time:  0.50565
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22091
  MAPE on 10 nodes subset: 0.02397

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.36060
  MAPE on 12 nodes subset: 0.27370

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.15532
  MAPE on 15 nodes subset: 0.01644

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40693
  MAPE on 20 nodes subset: 0.09190

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.20949
  MAPE on 25 nodes subset: 0.02622

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.607626 0.446605       0.534072                           xgboost_model_10.pkl       36
       10             Circuit            50           5          4 0.776233 0.403823       0.430510                   xgboost_model_10_Circuit.pkl       36
       12            Q_values            50          78          4 0.987599 0.667565       0.535040                           xgboost_model_12.pkl       36
       12             Circuit            50           5          4 1.105806 0.661939       0.418802                   xgboost_model_12_Circuit.pkl       36
       15            Q_values            50         120          4 0.604921 0.189660       0.673493                           xgboost_model_15.pkl       36
       15             Circuit            50           5          4 0.798296 0.229018       0.422523                   xgboost_model_15_Circuit.pkl       36
       20            Q_values            50         210          4 0.645950 0.269204       0.901983                           xgboost_model_20.pkl       36
       20             Circuit            50           5          4 0.849664 0.330723       0.435078                   xgboost_model_20_Circuit.pkl       36
       25            Q_values            50         325          4 0.721909 0.219646       0.997533                           xgboost_model_25.pkl       36
       25             Circuit            50           5          4 0.704583 0.185483       0.414234                   xgboost_model_25_Circuit.pkl       36
     full            Q_values           250         325          4 0.727135 0.304517       3.792520                         xgboost_model_full.pkl       36
     full             Circuit           250           5          4 0.749651 0.300985       0.505646                 xgboost_model_full_Circuit.pkl       36
       10 Q_values_full_model            50         325          4 0.220908 0.023973       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       36
       12 Q_values_full_model            50         325          4 0.360596 0.273704       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       36
       15 Q_values_full_model            50         325          4 0.155318 0.016435       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       36
       20 Q_values_full_model            50         325          4 0.406925 0.091905       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       36
       25 Q_values_full_model            50         325          4 0.209490 0.026218       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       36

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.4998
Epoch 002, Loss: 0.5829
Epoch 003, Loss: 0.5333
Epoch 004, Loss: 0.5331
Epoch 005, Loss: 0.6824
Epoch 006, Loss: 0.7201
Epoch 007, Loss: 0.5202
Epoch 008, Loss: 0.6553
Epoch 009, Loss: 0.5307
Epoch 010, Loss: 0.5290
Epoch 011, Loss: 0.6053
Epoch 012, Loss: 0.5624
Epoch 013, Loss: 0.6116
Epoch 014, Loss: 0.6180
Epoch 015, Loss: 0.5853
Epoch 016, Loss: 0.5727
Epoch 017, Loss: 0.5683
Epoch 018, Loss: 0.6033
Epoch 019, Loss: 0.5699
Epoch 020, Loss: 0.6252
Epoch 021, Loss: 0.5738
Epoch 022, Loss: 0.5470
Epoch 023, Loss: 0.5595
Epoch 024, Loss: 0.6035
Epoch 025, Loss: 0.6186
Epoch 026, Loss: 0.5322
Epoch 027, Loss: 0.5365
Epoch 028, Loss: 0.5454
Epoch 029, Loss: 0.5468
Epoch 030, Loss: 0.5306
Epoch 031, Loss: 0.5300
Epoch 032, Loss: 0.6055
Epoch 033, Loss: 0.5280
Epoch 034, Loss: 0.5481
Epoch 035, Loss: 0.5737
Epoch 036, Loss: 0.5418
Epoch 037, Loss: 0.5353
Epoch 038, Loss: 0.5892
Epoch 039, Loss: 0.5442
Epoch 040, Loss: 0.5231
Epoch 041, Loss: 0.5200
Epoch 042, Loss: 0.4954
Epoch 043, Loss: 0.5217
Epoch 044, Loss: 0.5173
Epoch 045, Loss: 0.5355
Epoch 046, Loss: 0.5052
Epoch 047, Loss: 0.5361
Epoch 048, Loss: 0.5482
Epoch 049, Loss: 0.5086
Epoch 050, Loss: 0.5366
Epoch 051, Loss: 0.5079
Epoch 052, Loss: 0.4985
Epoch 053, Loss: 0.5767
Epoch 054, Loss: 0.4989
Epoch 055, Loss: 0.5039
Epoch 056, Loss: 0.5148
Epoch 057, Loss: 0.5019
Epoch 058, Loss: 0.4976
Epoch 059, Loss: 0.4840
Epoch 060, Loss: 0.5063
Epoch 061, Loss: 0.5395
Epoch 062, Loss: 0.5075
Epoch 063, Loss: 0.4929
Epoch 064, Loss: 0.4826
Epoch 065, Loss: 0.4955
Epoch 066, Loss: 0.5132
Epoch 067, Loss: 0.4872
Epoch 068, Loss: 0.4896
Epoch 069, Loss: 0.4860
Epoch 070, Loss: 0.4792
Epoch 071, Loss: 0.5046
Epoch 072, Loss: 0.4915
Epoch 073, Loss: 0.5005
Epoch 074, Loss: 0.4977
Epoch 075, Loss: 0.4755
Epoch 076, Loss: 0.4832
Epoch 077, Loss: 0.4593
Epoch 078, Loss: 0.4683
Epoch 079, Loss: 0.4675
Epoch 080, Loss: 0.4545
Epoch 081, Loss: 0.4482
Epoch 082, Loss: 0.4648
Epoch 083, Loss: 0.4577
Epoch 084, Loss: 0.4719
Epoch 085, Loss: 0.4490
Epoch 086, Loss: 0.4493
Epoch 087, Loss: 0.4841
Epoch 088, Loss: 0.4677
Epoch 089, Loss: 0.4283
Epoch 090, Loss: 0.4522
Epoch 091, Loss: 0.4415
Epoch 092, Loss: 0.4580
Epoch 093, Loss: 0.4377
Epoch 094, Loss: 0.4250
Epoch 095, Loss: 0.4464
Epoch 096, Loss: 0.4301
Epoch 097, Loss: 0.4450
Epoch 098, Loss: 0.4288
Epoch 099, Loss: 0.4305
Epoch 100, Loss: 0.4410

Test RMSE: 0.6251
Test MAPE: 0.2090
Training time: 19.92 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.5895
Epoch 002, Loss: 0.8600
Epoch 003, Loss: 0.8761
Epoch 004, Loss: 0.9125
Epoch 005, Loss: 0.9611
Epoch 006, Loss: 0.8351
Epoch 007, Loss: 0.8861
Epoch 008, Loss: 0.8979
Epoch 009, Loss: 0.8403
Epoch 010, Loss: 0.8230
Epoch 011, Loss: 0.8586
Epoch 012, Loss: 0.9276
Epoch 013, Loss: 0.9631
Epoch 014, Loss: 0.8713
Epoch 015, Loss: 0.8643
Epoch 016, Loss: 0.9133
Epoch 017, Loss: 0.8669
Epoch 018, Loss: 0.8613
Epoch 019, Loss: 0.9661
Epoch 020, Loss: 0.8814
Epoch 021, Loss: 0.8542
Epoch 022, Loss: 0.8803
Epoch 023, Loss: 0.8884
Epoch 024, Loss: 0.8626
Epoch 025, Loss: 0.8382
Epoch 026, Loss: 0.8357
Epoch 027, Loss: 0.8963
Epoch 028, Loss: 0.8229
Epoch 029, Loss: 0.9143
Epoch 030, Loss: 0.8382
Epoch 031, Loss: 0.8093
Epoch 032, Loss: 0.8779
Epoch 033, Loss: 0.7933
Epoch 034, Loss: 0.8250
Epoch 035, Loss: 0.7968
Epoch 036, Loss: 0.8134
Epoch 037, Loss: 0.7949
Epoch 038, Loss: 0.8196
Epoch 039, Loss: 0.8660
Epoch 040, Loss: 0.8448
Epoch 041, Loss: 0.8124
Epoch 042, Loss: 0.9104
Epoch 043, Loss: 0.8244
Epoch 044, Loss: 0.8571
Epoch 045, Loss: 0.8275
Epoch 046, Loss: 0.8685
Epoch 047, Loss: 0.8197
Epoch 048, Loss: 0.8258
Epoch 049, Loss: 0.8294
Epoch 050, Loss: 0.7980
Epoch 051, Loss: 0.7884
Epoch 052, Loss: 0.7799
Epoch 053, Loss: 0.8239
Epoch 054, Loss: 0.8588
Epoch 055, Loss: 0.7637
Epoch 056, Loss: 0.8591
Epoch 057, Loss: 0.8248
Epoch 058, Loss: 0.8163
Epoch 059, Loss: 0.8420
Epoch 060, Loss: 0.8006
Epoch 061, Loss: 0.8547
Epoch 062, Loss: 0.7974
Epoch 063, Loss: 0.8074
Epoch 064, Loss: 0.8031
Epoch 065, Loss: 0.7872
Epoch 066, Loss: 0.7807
Epoch 067, Loss: 0.8149
Epoch 068, Loss: 0.8067
Epoch 069, Loss: 0.7883
Epoch 070, Loss: 0.7791
Epoch 071, Loss: 0.8241
Epoch 072, Loss: 0.8158
Epoch 073, Loss: 0.8160
Epoch 074, Loss: 0.8177
Epoch 075, Loss: 0.7695
Epoch 076, Loss: 0.7842
Epoch 077, Loss: 0.7445
Epoch 078, Loss: 0.7893
Epoch 079, Loss: 0.7560
Epoch 080, Loss: 0.7738
Epoch 081, Loss: 0.7777
Epoch 082, Loss: 0.7558
Epoch 083, Loss: 0.7383
Epoch 084, Loss: 0.7551
Epoch 085, Loss: 0.7523
Epoch 086, Loss: 0.7411
Epoch 087, Loss: 0.7715
Epoch 088, Loss: 0.7447
Epoch 089, Loss: 0.7172
Epoch 090, Loss: 0.7055
Epoch 091, Loss: 0.7059
Epoch 092, Loss: 0.7095
Epoch 093, Loss: 0.6937
Epoch 094, Loss: 0.6811
Epoch 095, Loss: 0.6877
Epoch 096, Loss: 0.7011
Epoch 097, Loss: 0.7060
Epoch 098, Loss: 0.6788
Epoch 099, Loss: 0.6797
Epoch 100, Loss: 0.6804

Test RMSE: 0.6987
Test MAPE: 0.2216
Training time: 20.20 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.2652
Epoch 002, Loss: 0.9047
Epoch 003, Loss: 0.9121
Epoch 004, Loss: 0.9353
Epoch 005, Loss: 0.9586
Epoch 006, Loss: 1.0249
Epoch 007, Loss: 0.9875
Epoch 008, Loss: 1.0096
Epoch 009, Loss: 0.9358
Epoch 010, Loss: 0.9210
Epoch 011, Loss: 0.9132
Epoch 012, Loss: 0.9059
Epoch 013, Loss: 0.8591
Epoch 014, Loss: 0.9852
Epoch 015, Loss: 0.8832
Epoch 016, Loss: 0.9973
Epoch 017, Loss: 1.0095
Epoch 018, Loss: 0.8701
Epoch 019, Loss: 0.8732
Epoch 020, Loss: 0.9110
Epoch 021, Loss: 0.9622
Epoch 022, Loss: 0.9758
Epoch 023, Loss: 0.9369
Epoch 024, Loss: 0.9081
Epoch 025, Loss: 0.9684
Epoch 026, Loss: 1.0230
Epoch 027, Loss: 1.0120
Epoch 028, Loss: 0.9589
Epoch 029, Loss: 0.9679
Epoch 030, Loss: 1.0843
Epoch 031, Loss: 0.9078
Epoch 032, Loss: 0.9671
Epoch 033, Loss: 0.8677
Epoch 034, Loss: 0.8973
Epoch 035, Loss: 0.9276
Epoch 036, Loss: 0.8862
Epoch 037, Loss: 0.8730
Epoch 038, Loss: 0.9394
Epoch 039, Loss: 0.8998
Epoch 040, Loss: 0.8909
Epoch 041, Loss: 0.8788
Epoch 042, Loss: 0.8965
Epoch 043, Loss: 0.9170
Epoch 044, Loss: 0.9087
Epoch 045, Loss: 0.9029
Epoch 046, Loss: 0.8477
Epoch 047, Loss: 0.8552
Epoch 048, Loss: 0.9358
Epoch 049, Loss: 0.8703
Epoch 050, Loss: 0.8163
Epoch 051, Loss: 0.8704
Epoch 052, Loss: 0.9001
Epoch 053, Loss: 0.8481
Epoch 054, Loss: 0.8754
Epoch 055, Loss: 1.0338
Epoch 056, Loss: 0.9726
Epoch 057, Loss: 0.8213
Epoch 058, Loss: 0.8356
Epoch 059, Loss: 0.8430
Epoch 060, Loss: 0.8081
Epoch 061, Loss: 0.8270
Epoch 062, Loss: 0.8020
Epoch 063, Loss: 0.8384
Epoch 064, Loss: 0.8149
Epoch 065, Loss: 0.7508
Epoch 066, Loss: 0.8743
Epoch 067, Loss: 0.7968
Epoch 068, Loss: 0.8008
Epoch 069, Loss: 0.7461
Epoch 070, Loss: 0.7317
Epoch 071, Loss: 0.7899
Epoch 072, Loss: 0.8135
Epoch 073, Loss: 0.7386
Epoch 074, Loss: 0.7798
Epoch 075, Loss: 0.6799
Epoch 076, Loss: 0.7328
Epoch 077, Loss: 0.6838
Epoch 078, Loss: 0.7014
Epoch 079, Loss: 0.6582
Epoch 080, Loss: 0.7341
Epoch 081, Loss: 0.6434
Epoch 082, Loss: 0.7043
Epoch 083, Loss: 0.6484
Epoch 084, Loss: 0.6079
Epoch 085, Loss: 0.6543
Epoch 086, Loss: 0.7138
Epoch 087, Loss: 0.5872
Epoch 088, Loss: 0.5925
Epoch 089, Loss: 0.5902
Epoch 090, Loss: 0.6068
Epoch 091, Loss: 0.5507
Epoch 092, Loss: 0.6558
Epoch 093, Loss: 0.5493
Epoch 094, Loss: 0.5903
Epoch 095, Loss: 0.6088
Epoch 096, Loss: 0.6383
Epoch 097, Loss: 0.6474
Epoch 098, Loss: 0.5937
Epoch 099, Loss: 0.5996
Epoch 100, Loss: 0.5701

Test RMSE: 0.8628
Test MAPE: 0.2090
Training time: 16.53 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.7767
Epoch 002, Loss: 1.3703
Epoch 003, Loss: 1.4356
Epoch 004, Loss: 1.4690
Epoch 005, Loss: 1.4167
Epoch 006, Loss: 1.2197
Epoch 007, Loss: 1.2642
Epoch 008, Loss: 1.4338
Epoch 009, Loss: 1.6434
Epoch 010, Loss: 1.2353
Epoch 011, Loss: 1.2463
Epoch 012, Loss: 1.2099
Epoch 013, Loss: 1.5700
Epoch 014, Loss: 1.3133
Epoch 015, Loss: 1.4365
Epoch 016, Loss: 1.2947
Epoch 017, Loss: 1.3432
Epoch 018, Loss: 1.3550
Epoch 019, Loss: 1.2192
Epoch 020, Loss: 1.1938
Epoch 021, Loss: 1.2710
Epoch 022, Loss: 1.4365
Epoch 023, Loss: 1.2396
Epoch 024, Loss: 1.3233
Epoch 025, Loss: 1.1692
Epoch 026, Loss: 1.2157
Epoch 027, Loss: 1.2484
Epoch 028, Loss: 1.1849
Epoch 029, Loss: 1.3139
Epoch 030, Loss: 1.2856
Epoch 031, Loss: 1.1671
Epoch 032, Loss: 1.1640
Epoch 033, Loss: 1.2017
Epoch 034, Loss: 1.6471
Epoch 035, Loss: 1.2529
Epoch 036, Loss: 1.2302
Epoch 037, Loss: 1.2737
Epoch 038, Loss: 1.1943
Epoch 039, Loss: 1.2882
Epoch 040, Loss: 1.1878
Epoch 041, Loss: 1.1889
Epoch 042, Loss: 1.1840
Epoch 043, Loss: 1.2163
Epoch 044, Loss: 1.0799
Epoch 045, Loss: 1.2775
Epoch 046, Loss: 1.2134
Epoch 047, Loss: 1.1347
Epoch 048, Loss: 1.2359
Epoch 049, Loss: 1.1190
Epoch 050, Loss: 1.1868
Epoch 051, Loss: 1.2192
Epoch 052, Loss: 1.0919
Epoch 053, Loss: 1.1224
Epoch 054, Loss: 1.1514
Epoch 055, Loss: 1.1163
Epoch 056, Loss: 1.0696
Epoch 057, Loss: 0.9774
Epoch 058, Loss: 1.0702
Epoch 059, Loss: 0.9193
Epoch 060, Loss: 0.9440
Epoch 061, Loss: 0.9100
Epoch 062, Loss: 0.9839
Epoch 063, Loss: 1.0256
Epoch 064, Loss: 0.8626
Epoch 065, Loss: 0.9284
Epoch 066, Loss: 0.9534
Epoch 067, Loss: 0.8218
Epoch 068, Loss: 0.7917
Epoch 069, Loss: 0.9044
Epoch 070, Loss: 0.7927
Epoch 071, Loss: 0.8595
Epoch 072, Loss: 0.8745
Epoch 073, Loss: 0.7914
Epoch 074, Loss: 0.8172
Epoch 075, Loss: 0.7927
Epoch 076, Loss: 0.7355
Epoch 077, Loss: 0.8335
Epoch 078, Loss: 0.7650
Epoch 079, Loss: 0.7411
Epoch 080, Loss: 0.7760
Epoch 081, Loss: 0.6917
Epoch 082, Loss: 0.7634
Epoch 083, Loss: 0.7611
Epoch 084, Loss: 0.7107
Epoch 085, Loss: 0.7079
Epoch 086, Loss: 0.6503
Epoch 087, Loss: 0.7333
Epoch 088, Loss: 0.6589
Epoch 089, Loss: 0.7764
Epoch 090, Loss: 0.7463
Epoch 091, Loss: 0.6750
Epoch 092, Loss: 0.6615
Epoch 093, Loss: 0.6662
Epoch 094, Loss: 0.7735
Epoch 095, Loss: 0.7316
Epoch 096, Loss: 0.6709
Epoch 097, Loss: 0.6831
Epoch 098, Loss: 0.6232
Epoch 099, Loss: 0.6997
Epoch 100, Loss: 0.6214

Test RMSE: 0.9396
Test MAPE: 0.2090
Training time: 17.16 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 11.1405
Epoch 002, Loss: 1.5118
Epoch 003, Loss: 1.5413
Epoch 004, Loss: 1.6998
Epoch 005, Loss: 1.6991
Epoch 006, Loss: 1.6067
Epoch 007, Loss: 1.6254
Epoch 008, Loss: 1.5078
Epoch 009, Loss: 1.5478
Epoch 010, Loss: 1.7901
Epoch 011, Loss: 1.6678
Epoch 012, Loss: 1.5478
Epoch 013, Loss: 1.5704
Epoch 014, Loss: 1.7528
Epoch 015, Loss: 1.6699
Epoch 016, Loss: 1.6593
Epoch 017, Loss: 1.5209
Epoch 018, Loss: 1.6142
Epoch 019, Loss: 1.6152
Epoch 020, Loss: 1.6566
Epoch 021, Loss: 1.5836
Epoch 022, Loss: 1.5626
Epoch 023, Loss: 1.6158
Epoch 024, Loss: 1.7017
Epoch 025, Loss: 1.6250
Epoch 026, Loss: 1.4863
Epoch 027, Loss: 1.4291
Epoch 028, Loss: 1.7862
Epoch 029, Loss: 1.4877
Epoch 030, Loss: 1.7356
Epoch 031, Loss: 1.6788
Epoch 032, Loss: 1.5770
Epoch 033, Loss: 1.6232
Epoch 034, Loss: 1.4396
Epoch 035, Loss: 1.7004
Epoch 036, Loss: 1.5154
Epoch 037, Loss: 1.6233
Epoch 038, Loss: 1.5358
Epoch 039, Loss: 1.3924
Epoch 040, Loss: 1.5871
Epoch 041, Loss: 1.6219
Epoch 042, Loss: 1.5147
Epoch 043, Loss: 1.4679
Epoch 044, Loss: 1.4662
Epoch 045, Loss: 1.4947
Epoch 046, Loss: 1.4549
Epoch 047, Loss: 1.5193
Epoch 048, Loss: 1.4596
Epoch 049, Loss: 1.4351
Epoch 050, Loss: 1.3232
Epoch 051, Loss: 1.2002
Epoch 052, Loss: 1.3143
Epoch 053, Loss: 1.2685
Epoch 054, Loss: 1.3001
Epoch 055, Loss: 1.2704
Epoch 056, Loss: 1.2609
Epoch 057, Loss: 1.2157
Epoch 058, Loss: 1.2025
Epoch 059, Loss: 1.1783
Epoch 060, Loss: 1.2361
Epoch 061, Loss: 1.0669
Epoch 062, Loss: 1.1487
Epoch 063, Loss: 1.2496
Epoch 064, Loss: 1.0198
Epoch 065, Loss: 1.2250
Epoch 066, Loss: 1.0297
Epoch 067, Loss: 1.0000
Epoch 068, Loss: 1.0563
Epoch 069, Loss: 0.9819
Epoch 070, Loss: 0.9768
Epoch 071, Loss: 1.1130
Epoch 072, Loss: 0.9541
Epoch 073, Loss: 1.1617
Epoch 074, Loss: 0.9808
Epoch 075, Loss: 1.0624
Epoch 076, Loss: 0.8541
Epoch 077, Loss: 0.8824
Epoch 078, Loss: 0.8619
Epoch 079, Loss: 1.0559
Epoch 080, Loss: 0.8838
Epoch 081, Loss: 0.9397
Epoch 082, Loss: 0.9293
Epoch 083, Loss: 0.9556
Epoch 084, Loss: 0.8590
Epoch 085, Loss: 0.9145
Epoch 086, Loss: 0.8223
Epoch 087, Loss: 0.9053
Epoch 088, Loss: 0.8429
Epoch 089, Loss: 0.8705
Epoch 090, Loss: 0.8493
Epoch 091, Loss: 0.9220
Epoch 092, Loss: 0.7334
Epoch 093, Loss: 0.9480
Epoch 094, Loss: 0.9450
Epoch 095, Loss: 0.7543
Epoch 096, Loss: 0.8743
Epoch 097, Loss: 0.8212
Epoch 098, Loss: 0.7618
Epoch 099, Loss: 0.8243
Epoch 100, Loss: 0.8038

Test RMSE: 1.4041
Test MAPE: 0.2067
Training time: 17.53 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.9872
Epoch 002, Loss: 3.3342
Epoch 003, Loss: 3.1734
Epoch 004, Loss: 2.0535
Epoch 005, Loss: 0.8738
Epoch 006, Loss: 0.7977
Epoch 007, Loss: 0.7178
Epoch 008, Loss: 0.7731
Epoch 009, Loss: 0.6774
Epoch 010, Loss: 0.6510
Epoch 011, Loss: 0.7099
Epoch 012, Loss: 0.7491
Epoch 013, Loss: 0.6805
Epoch 014, Loss: 0.6765
Epoch 015, Loss: 0.6634
Epoch 016, Loss: 0.6578
Epoch 017, Loss: 0.6041
Epoch 018, Loss: 0.6107
Epoch 019, Loss: 0.6854
Epoch 020, Loss: 0.6141
Epoch 021, Loss: 0.6131
Epoch 022, Loss: 0.5841
Epoch 023, Loss: 0.6218
Epoch 024, Loss: 0.6541
Epoch 025, Loss: 0.5928
Epoch 026, Loss: 0.5815
Epoch 027, Loss: 0.5845
Epoch 028, Loss: 0.6266
Epoch 029, Loss: 0.5628
Epoch 030, Loss: 0.6210
Epoch 031, Loss: 0.6098
Epoch 032, Loss: 0.6298
Epoch 033, Loss: 0.5760
Epoch 034, Loss: 0.5620
Epoch 035, Loss: 0.6317
Epoch 036, Loss: 0.5281
Epoch 037, Loss: 0.5802
Epoch 038, Loss: 0.5645
Epoch 039, Loss: 0.6246
Epoch 040, Loss: 0.5319
Epoch 041, Loss: 0.5506
Epoch 042, Loss: 0.5487
Epoch 043, Loss: 0.5739
Epoch 044, Loss: 0.5645
Epoch 045, Loss: 0.5620
Epoch 046, Loss: 0.5644
Epoch 047, Loss: 0.6099
Epoch 048, Loss: 0.5723
Epoch 049, Loss: 0.5786
Epoch 050, Loss: 0.5615
Epoch 051, Loss: 0.5723
Epoch 052, Loss: 0.5402
Epoch 053, Loss: 0.5451
Epoch 054, Loss: 0.5188
Epoch 055, Loss: 0.5411
Epoch 056, Loss: 0.5435
Epoch 057, Loss: 0.5351
Epoch 058, Loss: 0.5308
Epoch 059, Loss: 0.5491
Epoch 060, Loss: 0.6438
Epoch 061, Loss: 0.5771
Epoch 062, Loss: 0.5002
Epoch 063, Loss: 0.5140
Epoch 064, Loss: 0.5222
Epoch 065, Loss: 0.5388
Epoch 066, Loss: 0.5754
Epoch 067, Loss: 0.4900
Epoch 068, Loss: 0.5634
Epoch 069, Loss: 0.5285
Epoch 070, Loss: 0.5441
Epoch 071, Loss: 0.5215
Epoch 072, Loss: 0.5466
Epoch 073, Loss: 0.4947
Epoch 074, Loss: 0.5459
Epoch 075, Loss: 0.4930
Epoch 076, Loss: 0.4981
Epoch 077, Loss: 0.5433
Epoch 078, Loss: 0.4967
Epoch 079, Loss: 0.5345
Epoch 080, Loss: 0.5405
Epoch 081, Loss: 0.5328
Epoch 082, Loss: 0.5251
Epoch 083, Loss: 0.4925
Epoch 084, Loss: 0.5386
Epoch 085, Loss: 0.5108
Epoch 086, Loss: 0.5140
Epoch 087, Loss: 0.5234
Epoch 088, Loss: 0.5175
Epoch 089, Loss: 0.5049
Epoch 090, Loss: 0.5209
Epoch 091, Loss: 0.5161
Epoch 092, Loss: 0.5538
Epoch 093, Loss: 0.5144
Epoch 094, Loss: 0.4911
Epoch 095, Loss: 0.4867
Epoch 096, Loss: 0.5012
Epoch 097, Loss: 0.5390
Epoch 098, Loss: 0.5106
Epoch 099, Loss: 0.5205
Epoch 100, Loss: 0.4968

Test RMSE: 0.7025
Test MAPE: 261708228591616.0000
Training time: 90.92 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.625092 2.090308e-01      19.921241   GNN_model_10.pkl
       12   Q_values        0.2 0.698712 2.215985e-01      20.200805   GNN_model_12.pkl
       15   Q_values        0.2 0.862821 2.090465e-01      16.530071   GNN_model_15.pkl
       20   Q_values        0.2 0.939627 2.090364e-01      17.159542   GNN_model_20.pkl
       25   Q_values        0.2 1.404097 2.067358e-01      17.530947   GNN_model_25.pkl
     full   Q_values        0.2 0.702498 2.617082e+14      90.924604 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 74%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 69%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
