
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59800
 Mean Absolute Percentage Error: 0.25531
 Training time:  0.10635
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55119
 Mean Absolute Percentage Error: 0.39484
 Training time:  0.03549
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71550
 Mean Absolute Percentage Error: 0.57735
 Training time:  0.11659
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86066
 Mean Absolute Percentage Error: 0.53566
 Training time:  0.03791
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70190
 Mean Absolute Percentage Error: 0.30224
 Training time:  0.06639
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52294
 Mean Absolute Percentage Error: 0.17605
 Training time:  0.10673
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60342
 Mean Absolute Percentage Error: 0.22735
 Training time:  0.10137
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61103
 Mean Absolute Percentage Error: 0.25720
 Training time:  0.09060
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53187
 Mean Absolute Percentage Error: 0.17158
 Training time:  0.17593
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67726
 Mean Absolute Percentage Error: 0.21753
 Training time:  0.05045
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61777
 Mean Absolute Percentage Error: 0.23430
 Training time:  0.13551
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65584
 Mean Absolute Percentage Error: 0.29426
 Training time:  0.01748
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.59714
  MAPE on 10 nodes subset: 0.26148

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71549
  MAPE on 12 nodes subset: 0.56201

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68290
  MAPE on 15 nodes subset: 0.28515

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58738
  MAPE on 20 nodes subset: 0.22166

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52567
  MAPE on 25 nodes subset: 0.18072

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.598002 0.255315       0.106347       True             4                       MLP_model_10.pkl       30
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.551188 0.394840       0.035489       True             3               MLP_model_10_Circuit.pkl       30
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715505 0.577350       0.116587       True             4                       MLP_model_12.pkl       30
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.860662 0.535658       0.037914       True             3               MLP_model_12_Circuit.pkl       30
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.701904 0.302241       0.066391       True             4                       MLP_model_15.pkl       30
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522940 0.176054       0.106729       True             3               MLP_model_15_Circuit.pkl       30
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.603423 0.227346       0.101373       True             4                       MLP_model_20.pkl       30
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611031 0.257202       0.090602       True             3               MLP_model_20_Circuit.pkl       30
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.531866 0.171584       0.175933       True             3                       MLP_model_25.pkl       30
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.677260 0.217531       0.050446       True             3               MLP_model_25_Circuit.pkl       30
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617766 0.234297       0.135509       True             3                     MLP_model_full.pkl       30
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.655843 0.294264       0.017483       True             3             MLP_model_full_Circuit.pkl       30
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597139 0.261483       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       30
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715494 0.562010       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       30
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.682901 0.285150       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       30
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.587377 0.221655       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       30
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.525669 0.180722       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       30

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.62163
 Mean Absolute Percentage Error: 0.44942
 Training time:  0.40715
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76159
 Mean Absolute Percentage Error: 0.39985
 Training time:  0.23723
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.01613
 Mean Absolute Percentage Error: 0.68039
 Training time:  0.35787
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10809
 Mean Absolute Percentage Error: 0.66075
 Training time:  0.24317
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62842
 Mean Absolute Percentage Error: 0.19493
 Training time:  0.44054
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80543
 Mean Absolute Percentage Error: 0.23109
 Training time:  0.24006
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.64778
 Mean Absolute Percentage Error: 0.28266
 Training time:  0.61486
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84920
 Mean Absolute Percentage Error: 0.32861
 Training time:  0.23730
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74726
 Mean Absolute Percentage Error: 0.22498
 Training time:  0.70664
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69869
 Mean Absolute Percentage Error: 0.18673
 Training time:  0.23605
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71895
 Mean Absolute Percentage Error: 0.30565
 Training time:  2.90654
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75259
 Mean Absolute Percentage Error: 0.30074
 Training time:  0.29805
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.24468
  MAPE on 10 nodes subset: 0.02410

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34574
  MAPE on 12 nodes subset: 0.27766

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.14326
  MAPE on 15 nodes subset: 0.01609

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.40588
  MAPE on 20 nodes subset: 0.09659

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.18373
  MAPE on 25 nodes subset: 0.02403

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.621634 0.449421       0.407150                           xgboost_model_10.pkl       28
       10             Circuit            50           5          4 0.761589 0.399852       0.237230                   xgboost_model_10_Circuit.pkl       28
       12            Q_values            50          78          4 1.016129 0.680388       0.357866                           xgboost_model_12.pkl       28
       12             Circuit            50           5          4 1.108086 0.660755       0.243171                   xgboost_model_12_Circuit.pkl       28
       15            Q_values            50         120          4 0.628422 0.194932       0.440537                           xgboost_model_15.pkl       28
       15             Circuit            50           5          4 0.805432 0.231086       0.240056                   xgboost_model_15_Circuit.pkl       28
       20            Q_values            50         210          4 0.647776 0.282661       0.614855                           xgboost_model_20.pkl       28
       20             Circuit            50           5          4 0.849200 0.328607       0.237298                   xgboost_model_20_Circuit.pkl       28
       25            Q_values            50         325          4 0.747259 0.224982       0.706637                           xgboost_model_25.pkl       28
       25             Circuit            50           5          4 0.698685 0.186735       0.236048                   xgboost_model_25_Circuit.pkl       28
     full            Q_values           250         325          4 0.718947 0.305652       2.906535                         xgboost_model_full.pkl       28
     full             Circuit           250           5          4 0.752590 0.300742       0.298046                 xgboost_model_full_Circuit.pkl       28
       10 Q_values_full_model            50         325          4 0.244683 0.024101       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       12 Q_values_full_model            50         325          4 0.345745 0.277660       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       15 Q_values_full_model            50         325          4 0.143263 0.016093       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       20 Q_values_full_model            50         325          4 0.405882 0.096586       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28
       25 Q_values_full_model            50         325          4 0.183734 0.024031       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       28

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 3.0296
Epoch 002, Loss: 0.5601
Epoch 003, Loss: 0.5684
Epoch 004, Loss: 0.6255
Epoch 005, Loss: 0.5426
Epoch 006, Loss: 0.5581
Epoch 007, Loss: 0.5539
Epoch 008, Loss: 0.5845
Epoch 009, Loss: 0.5616
Epoch 010, Loss: 0.6117
Epoch 011, Loss: 0.5666
Epoch 012, Loss: 0.5548
Epoch 013, Loss: 0.5446
Epoch 014, Loss: 0.6082
Epoch 015, Loss: 0.6848
Epoch 016, Loss: 0.5665
Epoch 017, Loss: 0.5485
Epoch 018, Loss: 0.5601
Epoch 019, Loss: 0.5755
Epoch 020, Loss: 0.5213
Epoch 021, Loss: 0.5668
Epoch 022, Loss: 0.6287
Epoch 023, Loss: 0.5779
Epoch 024, Loss: 0.5589
Epoch 025, Loss: 0.5318
Epoch 026, Loss: 0.5447
Epoch 027, Loss: 0.5504
Epoch 028, Loss: 0.6022
Epoch 029, Loss: 0.5504
Epoch 030, Loss: 0.5048
Epoch 031, Loss: 0.5981
Epoch 032, Loss: 0.5376
Epoch 033, Loss: 0.4998
Epoch 034, Loss: 0.5121
Epoch 035, Loss: 0.5106
Epoch 036, Loss: 0.5282
Epoch 037, Loss: 0.5253
Epoch 038, Loss: 0.4873
Epoch 039, Loss: 0.5238
Epoch 040, Loss: 0.5262
Epoch 041, Loss: 0.5040
Epoch 042, Loss: 0.5172
Epoch 043, Loss: 0.5173
Epoch 044, Loss: 0.5208
Epoch 045, Loss: 0.5099
Epoch 046, Loss: 0.5295
Epoch 047, Loss: 0.5065
Epoch 048, Loss: 0.5074
Epoch 049, Loss: 0.5258
Epoch 050, Loss: 0.5048
Epoch 051, Loss: 0.4905
Epoch 052, Loss: 0.4823
Epoch 053, Loss: 0.4823
Epoch 054, Loss: 0.5111
Epoch 055, Loss: 0.5173
Epoch 056, Loss: 0.5218
Epoch 057, Loss: 0.5240
Epoch 058, Loss: 0.4979
Epoch 059, Loss: 0.4931
Epoch 060, Loss: 0.5272
Epoch 061, Loss: 0.5280
Epoch 062, Loss: 0.4907
Epoch 063, Loss: 0.4966
Epoch 064, Loss: 0.4773
Epoch 065, Loss: 0.4888
Epoch 066, Loss: 0.4768
Epoch 067, Loss: 0.5000
Epoch 068, Loss: 0.4931
Epoch 069, Loss: 0.4726
Epoch 070, Loss: 0.4863
Epoch 071, Loss: 0.5191
Epoch 072, Loss: 0.4959
Epoch 073, Loss: 0.4865
Epoch 074, Loss: 0.4800
Epoch 075, Loss: 0.4853
Epoch 076, Loss: 0.4866
Epoch 077, Loss: 0.4962
Epoch 078, Loss: 0.4588
Epoch 079, Loss: 0.4557
Epoch 080, Loss: 0.4481
Epoch 081, Loss: 0.4779
Epoch 082, Loss: 0.4479
Epoch 083, Loss: 0.4591
Epoch 084, Loss: 0.4777
Epoch 085, Loss: 0.4297
Epoch 086, Loss: 0.4675
Epoch 087, Loss: 0.4725
Epoch 088, Loss: 0.4738
Epoch 089, Loss: 0.4796
Epoch 090, Loss: 0.4776
Epoch 091, Loss: 0.4452
Epoch 092, Loss: 0.4409
Epoch 093, Loss: 0.4305
Epoch 094, Loss: 0.4322
Epoch 095, Loss: 0.4442
Epoch 096, Loss: 0.4575
Epoch 097, Loss: 0.4189
Epoch 098, Loss: 0.4433
Epoch 099, Loss: 0.4772
Epoch 100, Loss: 0.4204

Test RMSE: 0.6204
Test MAPE: 0.2192
Training time: 12.15 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.9591
Epoch 002, Loss: 0.9076
Epoch 003, Loss: 0.8430
Epoch 004, Loss: 0.8964
Epoch 005, Loss: 0.8902
Epoch 006, Loss: 0.8401
Epoch 007, Loss: 0.9249
Epoch 008, Loss: 0.8428
Epoch 009, Loss: 0.8472
Epoch 010, Loss: 0.8880
Epoch 011, Loss: 0.8677
Epoch 012, Loss: 0.8799
Epoch 013, Loss: 0.8611
Epoch 014, Loss: 0.8332
Epoch 015, Loss: 0.8324
Epoch 016, Loss: 0.8582
Epoch 017, Loss: 0.8736
Epoch 018, Loss: 0.8395
Epoch 019, Loss: 0.8447
Epoch 020, Loss: 0.8597
Epoch 021, Loss: 0.8982
Epoch 022, Loss: 0.8186
Epoch 023, Loss: 0.8041
Epoch 024, Loss: 0.8227
Epoch 025, Loss: 0.8121
Epoch 026, Loss: 0.8170
Epoch 027, Loss: 0.8452
Epoch 028, Loss: 0.8289
Epoch 029, Loss: 0.8594
Epoch 030, Loss: 0.8231
Epoch 031, Loss: 0.8391
Epoch 032, Loss: 0.8236
Epoch 033, Loss: 0.8619
Epoch 034, Loss: 0.8462
Epoch 035, Loss: 0.8339
Epoch 036, Loss: 0.8337
Epoch 037, Loss: 0.8368
Epoch 038, Loss: 0.8378
Epoch 039, Loss: 0.8117
Epoch 040, Loss: 0.8397
Epoch 041, Loss: 0.7748
Epoch 042, Loss: 0.7924
Epoch 043, Loss: 0.7840
Epoch 044, Loss: 0.8589
Epoch 045, Loss: 0.8777
Epoch 046, Loss: 0.8490
Epoch 047, Loss: 0.8256
Epoch 048, Loss: 0.8030
Epoch 049, Loss: 0.8181
Epoch 050, Loss: 0.8049
Epoch 051, Loss: 0.7902
Epoch 052, Loss: 0.7824
Epoch 053, Loss: 0.8231
Epoch 054, Loss: 0.8022
Epoch 055, Loss: 0.7540
Epoch 056, Loss: 0.7733
Epoch 057, Loss: 0.8847
Epoch 058, Loss: 0.7688
Epoch 059, Loss: 0.8204
Epoch 060, Loss: 0.7558
Epoch 061, Loss: 0.7527
Epoch 062, Loss: 0.7448
Epoch 063, Loss: 0.7649
Epoch 064, Loss: 0.7685
Epoch 065, Loss: 0.8341
Epoch 066, Loss: 0.7621
Epoch 067, Loss: 0.7399
Epoch 068, Loss: 0.7584
Epoch 069, Loss: 0.7561
Epoch 070, Loss: 0.7759
Epoch 071, Loss: 0.7313
Epoch 072, Loss: 0.7643
Epoch 073, Loss: 0.7064
Epoch 074, Loss: 0.7163
Epoch 075, Loss: 0.7408
Epoch 076, Loss: 0.7201
Epoch 077, Loss: 0.7313
Epoch 078, Loss: 0.6986
Epoch 079, Loss: 0.7189
Epoch 080, Loss: 0.7134
Epoch 081, Loss: 0.6925
Epoch 082, Loss: 0.6752
Epoch 083, Loss: 0.7513
Epoch 084, Loss: 0.7367
Epoch 085, Loss: 0.7049
Epoch 086, Loss: 0.6807
Epoch 087, Loss: 0.6625
Epoch 088, Loss: 0.6906
Epoch 089, Loss: 0.6576
Epoch 090, Loss: 0.6892
Epoch 091, Loss: 0.6775
Epoch 092, Loss: 0.6863
Epoch 093, Loss: 0.6356
Epoch 094, Loss: 0.6219
Epoch 095, Loss: 0.6428
Epoch 096, Loss: 0.6354
Epoch 097, Loss: 0.6620
Epoch 098, Loss: 0.6239
Epoch 099, Loss: 0.6002
Epoch 100, Loss: 0.6696

Test RMSE: 0.6626
Test MAPE: 0.2009
Training time: 12.09 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.7836
Epoch 002, Loss: 0.9728
Epoch 003, Loss: 0.9707
Epoch 004, Loss: 0.9276
Epoch 005, Loss: 0.9127
Epoch 006, Loss: 1.0306
Epoch 007, Loss: 1.0389
Epoch 008, Loss: 0.9685
Epoch 009, Loss: 0.9558
Epoch 010, Loss: 0.9719
Epoch 011, Loss: 0.9811
Epoch 012, Loss: 1.0268
Epoch 013, Loss: 1.0162
Epoch 014, Loss: 0.9944
Epoch 015, Loss: 1.0075
Epoch 016, Loss: 0.9241
Epoch 017, Loss: 0.9316
Epoch 018, Loss: 0.8532
Epoch 019, Loss: 0.9139
Epoch 020, Loss: 0.9094
Epoch 021, Loss: 0.8770
Epoch 022, Loss: 1.0326
Epoch 023, Loss: 0.9789
Epoch 024, Loss: 0.9152
Epoch 025, Loss: 0.8905
Epoch 026, Loss: 0.8927
Epoch 027, Loss: 0.9359
Epoch 028, Loss: 0.8562
Epoch 029, Loss: 0.9585
Epoch 030, Loss: 0.9078
Epoch 031, Loss: 0.8825
Epoch 032, Loss: 0.9944
Epoch 033, Loss: 0.9703
Epoch 034, Loss: 0.9202
Epoch 035, Loss: 0.8880
Epoch 036, Loss: 0.8822
Epoch 037, Loss: 0.9196
Epoch 038, Loss: 0.8860
Epoch 039, Loss: 0.8893
Epoch 040, Loss: 0.9034
Epoch 041, Loss: 0.8225
Epoch 042, Loss: 0.8608
Epoch 043, Loss: 0.8164
Epoch 044, Loss: 0.8230
Epoch 045, Loss: 0.8022
Epoch 046, Loss: 0.9386
Epoch 047, Loss: 0.8016
Epoch 048, Loss: 0.8173
Epoch 049, Loss: 0.8113
Epoch 050, Loss: 0.7130
Epoch 051, Loss: 0.8278
Epoch 052, Loss: 0.7940
Epoch 053, Loss: 0.7567
Epoch 054, Loss: 0.7217
Epoch 055, Loss: 0.8238
Epoch 056, Loss: 0.7255
Epoch 057, Loss: 0.7795
Epoch 058, Loss: 0.7059
Epoch 059, Loss: 0.7152
Epoch 060, Loss: 0.6308
Epoch 061, Loss: 0.6615
Epoch 062, Loss: 0.6772
Epoch 063, Loss: 0.6216
Epoch 064, Loss: 0.7129
Epoch 065, Loss: 0.6161
Epoch 066, Loss: 0.6657
Epoch 067, Loss: 0.5907
Epoch 068, Loss: 0.6550
Epoch 069, Loss: 0.7000
Epoch 070, Loss: 0.6608
Epoch 071, Loss: 0.6308
Epoch 072, Loss: 0.5939
Epoch 073, Loss: 0.5842
Epoch 074, Loss: 0.5713
Epoch 075, Loss: 0.5843
Epoch 076, Loss: 0.5767
Epoch 077, Loss: 0.6294
Epoch 078, Loss: 0.5557
Epoch 079, Loss: 0.5940
Epoch 080, Loss: 0.5428
Epoch 081, Loss: 0.5687
Epoch 082, Loss: 0.5785
Epoch 083, Loss: 0.5877
Epoch 084, Loss: 0.5747
Epoch 085, Loss: 0.5950
Epoch 086, Loss: 0.5829
Epoch 087, Loss: 0.5277
Epoch 088, Loss: 0.5523
Epoch 089, Loss: 0.6059
Epoch 090, Loss: 0.5765
Epoch 091, Loss: 0.5617
Epoch 092, Loss: 0.5602
Epoch 093, Loss: 0.5409
Epoch 094, Loss: 0.5273
Epoch 095, Loss: 0.5102
Epoch 096, Loss: 0.5131
Epoch 097, Loss: 0.4867
Epoch 098, Loss: 0.4986
Epoch 099, Loss: 0.5579
Epoch 100, Loss: 0.5970

Test RMSE: 0.7764
Test MAPE: 0.2014
Training time: 12.19 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 6.8571
Epoch 002, Loss: 1.3521
Epoch 003, Loss: 1.1865
Epoch 004, Loss: 1.3260
Epoch 005, Loss: 1.3056
Epoch 006, Loss: 1.2344
Epoch 007, Loss: 1.1800
Epoch 008, Loss: 1.1710
Epoch 009, Loss: 1.4047
Epoch 010, Loss: 1.4124
Epoch 011, Loss: 1.4032
Epoch 012, Loss: 1.1934
Epoch 013, Loss: 1.1980
Epoch 014, Loss: 1.3274
Epoch 015, Loss: 1.2459
Epoch 016, Loss: 1.2068
Epoch 017, Loss: 1.5666
Epoch 018, Loss: 1.2954
Epoch 019, Loss: 1.2280
Epoch 020, Loss: 1.3627
Epoch 021, Loss: 1.2598
Epoch 022, Loss: 1.3605
Epoch 023, Loss: 1.4200
Epoch 024, Loss: 1.0761
Epoch 025, Loss: 1.0497
Epoch 026, Loss: 1.0742
Epoch 027, Loss: 1.0879
Epoch 028, Loss: 1.0146
Epoch 029, Loss: 0.9854
Epoch 030, Loss: 1.0477
Epoch 031, Loss: 0.9535
Epoch 032, Loss: 1.0272
Epoch 033, Loss: 0.9696
Epoch 034, Loss: 0.8931
Epoch 035, Loss: 0.8878
Epoch 036, Loss: 0.9008
Epoch 037, Loss: 0.8092
Epoch 038, Loss: 1.0045
Epoch 039, Loss: 0.8286
Epoch 040, Loss: 0.7994
Epoch 041, Loss: 0.8015
Epoch 042, Loss: 0.8787
Epoch 043, Loss: 0.8013
Epoch 044, Loss: 0.8455
Epoch 045, Loss: 0.8651
Epoch 046, Loss: 0.8664
Epoch 047, Loss: 0.7450
Epoch 048, Loss: 0.7554
Epoch 049, Loss: 0.7435
Epoch 050, Loss: 0.8738
Epoch 051, Loss: 0.7420
Epoch 052, Loss: 0.7358
Epoch 053, Loss: 0.7405
Epoch 054, Loss: 0.6597
Epoch 055, Loss: 0.7233
Epoch 056, Loss: 0.6721
Epoch 057, Loss: 0.6446
Epoch 058, Loss: 0.8749
Epoch 059, Loss: 0.8241
Epoch 060, Loss: 0.5997
Epoch 061, Loss: 0.6935
Epoch 062, Loss: 0.6656
Epoch 063, Loss: 0.6180
Epoch 064, Loss: 0.7945
Epoch 065, Loss: 0.6734
Epoch 066, Loss: 0.6547
Epoch 067, Loss: 0.6169
Epoch 068, Loss: 0.5868
Epoch 069, Loss: 0.7768
Epoch 070, Loss: 0.5837
Epoch 071, Loss: 0.5851
Epoch 072, Loss: 0.6631
Epoch 073, Loss: 0.5837
Epoch 074, Loss: 0.6020
Epoch 075, Loss: 0.5733
Epoch 076, Loss: 0.5389
Epoch 077, Loss: 0.5623
Epoch 078, Loss: 0.5367
Epoch 079, Loss: 0.5830
Epoch 080, Loss: 0.5311
Epoch 081, Loss: 0.5494
Epoch 082, Loss: 0.5717
Epoch 083, Loss: 0.6417
Epoch 084, Loss: 0.5962
Epoch 085, Loss: 0.5309
Epoch 086, Loss: 0.4880
Epoch 087, Loss: 0.4906
Epoch 088, Loss: 0.5341
Epoch 089, Loss: 0.5017
Epoch 090, Loss: 0.5086
Epoch 091, Loss: 0.5464
Epoch 092, Loss: 0.5866
Epoch 093, Loss: 0.4761
Epoch 094, Loss: 0.5287
Epoch 095, Loss: 0.5196
Epoch 096, Loss: 0.4927
Epoch 097, Loss: 0.4508
Epoch 098, Loss: 0.5494
Epoch 099, Loss: 0.4665
Epoch 100, Loss: 0.4677

Test RMSE: 1.0476
Test MAPE: 0.2608
Training time: 12.71 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 12.5390
Epoch 002, Loss: 1.7251
Epoch 003, Loss: 1.4625
Epoch 004, Loss: 1.9172
Epoch 005, Loss: 1.5833
Epoch 006, Loss: 1.7867
Epoch 007, Loss: 1.6578
Epoch 008, Loss: 1.6242
Epoch 009, Loss: 1.6992
Epoch 010, Loss: 1.5651
Epoch 011, Loss: 1.5315
Epoch 012, Loss: 1.6224
Epoch 013, Loss: 1.5987
Epoch 014, Loss: 1.6034
Epoch 015, Loss: 1.5317
Epoch 016, Loss: 1.5919
Epoch 017, Loss: 1.5483
Epoch 018, Loss: 1.6340
Epoch 019, Loss: 1.6419
Epoch 020, Loss: 1.5854
Epoch 021, Loss: 1.5898
Epoch 022, Loss: 1.6687
Epoch 023, Loss: 1.4739
Epoch 024, Loss: 1.4976
Epoch 025, Loss: 1.5144
Epoch 026, Loss: 1.5919
Epoch 027, Loss: 1.4509
Epoch 028, Loss: 1.7769
Epoch 029, Loss: 1.5068
Epoch 030, Loss: 1.7694
Epoch 031, Loss: 2.0164
Epoch 032, Loss: 1.5817
Epoch 033, Loss: 1.6564
Epoch 034, Loss: 1.4733
Epoch 035, Loss: 1.4947
Epoch 036, Loss: 1.6368
Epoch 037, Loss: 1.4778
Epoch 038, Loss: 1.4315
Epoch 039, Loss: 1.5297
Epoch 040, Loss: 1.6481
Epoch 041, Loss: 1.5674
Epoch 042, Loss: 1.6059
Epoch 043, Loss: 1.5192
Epoch 044, Loss: 1.5718
Epoch 045, Loss: 1.5095
Epoch 046, Loss: 1.4346
Epoch 047, Loss: 1.6010
Epoch 048, Loss: 1.4752
Epoch 049, Loss: 1.5466
Epoch 050, Loss: 1.6284
Epoch 051, Loss: 1.4551
Epoch 052, Loss: 1.6969
Epoch 053, Loss: 1.6415
Epoch 054, Loss: 1.3991
Epoch 055, Loss: 1.4316
Epoch 056, Loss: 1.4696
Epoch 057, Loss: 1.7123
Epoch 058, Loss: 1.5541
Epoch 059, Loss: 1.4183
Epoch 060, Loss: 1.4713
Epoch 061, Loss: 1.5395
Epoch 062, Loss: 1.4317
Epoch 063, Loss: 1.5464
Epoch 064, Loss: 1.7751
Epoch 065, Loss: 1.3824
Epoch 066, Loss: 1.4851
Epoch 067, Loss: 1.4394
Epoch 068, Loss: 1.4864
Epoch 069, Loss: 1.6158
Epoch 070, Loss: 1.3628
Epoch 071, Loss: 1.5007
Epoch 072, Loss: 1.3387
Epoch 073, Loss: 1.3285
Epoch 074, Loss: 1.2167
Epoch 075, Loss: 1.5951
Epoch 076, Loss: 1.2949
Epoch 077, Loss: 1.3277
Epoch 078, Loss: 1.5174
Epoch 079, Loss: 1.3957
Epoch 080, Loss: 1.1768
Epoch 081, Loss: 1.1799
Epoch 082, Loss: 1.1852
Epoch 083, Loss: 1.1903
Epoch 084, Loss: 1.0028
Epoch 085, Loss: 1.0409
Epoch 086, Loss: 0.9990
Epoch 087, Loss: 1.0965
Epoch 088, Loss: 1.0723
Epoch 089, Loss: 0.9426
Epoch 090, Loss: 0.9585
Epoch 091, Loss: 0.9805
Epoch 092, Loss: 0.9083
Epoch 093, Loss: 0.9119
Epoch 094, Loss: 1.0223
Epoch 095, Loss: 0.9137
Epoch 096, Loss: 0.8604
Epoch 097, Loss: 0.9140
Epoch 098, Loss: 0.8373
Epoch 099, Loss: 0.8580
Epoch 100, Loss: 0.7824

Test RMSE: 1.4964
Test MAPE: 0.2352
Training time: 13.02 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7973
Epoch 002, Loss: 3.1484
Epoch 003, Loss: 1.6299
Epoch 004, Loss: 0.8134
Epoch 005, Loss: 0.7649
Epoch 006, Loss: 0.7579
Epoch 007, Loss: 0.7769
Epoch 008, Loss: 0.7188
Epoch 009, Loss: 0.6806
Epoch 010, Loss: 0.7019
Epoch 011, Loss: 0.6782
Epoch 012, Loss: 0.6889
Epoch 013, Loss: 0.6618
Epoch 014, Loss: 0.6724
Epoch 015, Loss: 0.6396
Epoch 016, Loss: 0.6072
Epoch 017, Loss: 0.7390
Epoch 018, Loss: 0.5941
Epoch 019, Loss: 0.5974
Epoch 020, Loss: 0.5909
Epoch 021, Loss: 0.6489
Epoch 022, Loss: 0.7165
Epoch 023, Loss: 0.5792
Epoch 024, Loss: 0.6406
Epoch 025, Loss: 0.6139
Epoch 026, Loss: 0.6078
Epoch 027, Loss: 0.5592
Epoch 028, Loss: 0.6651
Epoch 029, Loss: 0.5946
Epoch 030, Loss: 0.5827
Epoch 031, Loss: 0.6269
Epoch 032, Loss: 0.5825
Epoch 033, Loss: 0.6307
Epoch 034, Loss: 0.6074
Epoch 035, Loss: 0.5824
Epoch 036, Loss: 0.5500
Epoch 037, Loss: 0.5451
Epoch 038, Loss: 0.6437
Epoch 039, Loss: 0.5721
Epoch 040, Loss: 0.5478
Epoch 041, Loss: 0.5340
Epoch 042, Loss: 0.5242
Epoch 043, Loss: 0.5357
Epoch 044, Loss: 0.5546
Epoch 045, Loss: 0.6054
Epoch 046, Loss: 0.5364
Epoch 047, Loss: 0.5162
Epoch 048, Loss: 0.5925
Epoch 049, Loss: 0.5883
Epoch 050, Loss: 0.5764
Epoch 051, Loss: 0.5498
Epoch 052, Loss: 0.5429
Epoch 053, Loss: 0.5178
Epoch 054, Loss: 0.5705
Epoch 055, Loss: 0.5672
Epoch 056, Loss: 0.5445
Epoch 057, Loss: 0.5673
Epoch 058, Loss: 0.5693
Epoch 059, Loss: 0.5499
Epoch 060, Loss: 0.5784
Epoch 061, Loss: 0.5772
Epoch 062, Loss: 0.5271
Epoch 063, Loss: 0.5049
Epoch 064, Loss: 0.5756
Epoch 065, Loss: 0.5150
Epoch 066, Loss: 0.5882
Epoch 067, Loss: 0.5935
Epoch 068, Loss: 0.5328
Epoch 069, Loss: 0.5503
Epoch 070, Loss: 0.5210
Epoch 071, Loss: 0.5088
Epoch 072, Loss: 0.5116
Epoch 073, Loss: 0.5191
Epoch 074, Loss: 0.5377
Epoch 075, Loss: 0.5436
Epoch 076, Loss: 0.5202
Epoch 077, Loss: 0.5200
Epoch 078, Loss: 0.5007
Epoch 079, Loss: 0.5560
Epoch 080, Loss: 0.5383
Epoch 081, Loss: 0.5422
Epoch 082, Loss: 0.5332
Epoch 083, Loss: 0.5059
Epoch 084, Loss: 0.5620
Epoch 085, Loss: 0.5176
Epoch 086, Loss: 0.4963
Epoch 087, Loss: 0.4980
Epoch 088, Loss: 0.5201
Epoch 089, Loss: 0.5379
Epoch 090, Loss: 0.5138
Epoch 091, Loss: 0.5040
Epoch 092, Loss: 0.5154
Epoch 093, Loss: 0.5774
Epoch 094, Loss: 0.5314
Epoch 095, Loss: 0.5000
Epoch 096, Loss: 0.5104
Epoch 097, Loss: 0.5270
Epoch 098, Loss: 0.5423
Epoch 099, Loss: 0.5018
Epoch 100, Loss: 0.5031

Test RMSE: 0.7373
Test MAPE: 266170095632384.0000
Training time: 63.04 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.620433 2.191541e-01      12.146434   GNN_model_10.pkl
       12   Q_values        0.2 0.662559 2.009023e-01      12.091381   GNN_model_12.pkl
       15   Q_values        0.2 0.776362 2.013594e-01      12.187190   GNN_model_15.pkl
       20   Q_values        0.2 1.047606 2.608058e-01      12.706905   GNN_model_20.pkl
       25   Q_values        0.2 1.496390 2.352448e-01      13.024652   GNN_model_25.pkl
     full   Q_values        0.2 0.737338 2.661701e+14      63.043162 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
