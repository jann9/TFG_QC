
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59789
 Mean Absolute Percentage Error: 0.25554
 Training time:  0.03307
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.54740
 Mean Absolute Percentage Error: 0.38731
 Training time:  0.01647
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71552
 Mean Absolute Percentage Error: 0.57736
 Training time:  0.06008
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86414
 Mean Absolute Percentage Error: 0.54136
 Training time:  0.01717
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70670
 Mean Absolute Percentage Error: 0.30462
 Training time:  0.03541
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.53361
 Mean Absolute Percentage Error: 0.17233
 Training time:  0.01571
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60412
 Mean Absolute Percentage Error: 0.22811
 Training time:  0.08027
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61189
 Mean Absolute Percentage Error: 0.25130
 Training time:  0.01574
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53879
 Mean Absolute Percentage Error: 0.17757
 Training time:  0.16766
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.68552
 Mean Absolute Percentage Error: 0.21493
 Training time:  0.03070
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61694
 Mean Absolute Percentage Error: 0.23919
 Training time:  0.19134
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.66099
 Mean Absolute Percentage Error: 0.28823
 Training time:  0.04499
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60236
  MAPE on 10 nodes subset: 0.26849

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70988
  MAPE on 12 nodes subset: 0.56954

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68746
  MAPE on 15 nodes subset: 0.29197

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58523
  MAPE on 20 nodes subset: 0.22626

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53204
  MAPE on 25 nodes subset: 0.18530

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597892 0.255539       0.033065       True             4                       MLP_model_10.pkl       35
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.547404 0.387312       0.016467       True             3               MLP_model_10_Circuit.pkl       35
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715516 0.577356       0.060076       True             4                       MLP_model_12.pkl       35
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.864137 0.541364       0.017169       True             4               MLP_model_12_Circuit.pkl       35
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.706698 0.304615       0.035409       True             4                       MLP_model_15.pkl       35
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.533615 0.172329       0.015710       True             3               MLP_model_15_Circuit.pkl       35
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604120 0.228114       0.080273       True             4                       MLP_model_20.pkl       35
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611891 0.251296       0.015738       True             3               MLP_model_20_Circuit.pkl       35
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.538791 0.177570       0.167660       True             4                       MLP_model_25.pkl       35
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.685515 0.214935       0.030699       True             3               MLP_model_25_Circuit.pkl       35
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616939 0.239190       0.191340       True             4                     MLP_model_full.pkl       35
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.660988 0.288234       0.044991       True             3             MLP_model_full_Circuit.pkl       35
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602357 0.268488       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       35
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709880 0.569540       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       35
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.687461 0.291968       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       35
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.585232 0.226256       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       35
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.532036 0.185300       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       35

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.60649
 Mean Absolute Percentage Error: 0.43268
 Training time:  0.36688
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.77082
 Mean Absolute Percentage Error: 0.40716
 Training time:  0.25976
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.99523
 Mean Absolute Percentage Error: 0.66055
 Training time:  0.38228
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.11482
 Mean Absolute Percentage Error: 0.66411
 Training time:  0.27027
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.60336
 Mean Absolute Percentage Error: 0.18878
 Training time:  0.47345
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80318
 Mean Absolute Percentage Error: 0.23517
 Training time:  0.26538
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.62837
 Mean Absolute Percentage Error: 0.27035
 Training time:  0.66659
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.84499
 Mean Absolute Percentage Error: 0.32891
 Training time:  0.26426
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.75604
 Mean Absolute Percentage Error: 0.23293
 Training time:  0.75827
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69545
 Mean Absolute Percentage Error: 0.18443
 Training time:  0.25951
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.70160
 Mean Absolute Percentage Error: 0.30144
 Training time:  3.08579
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75019
 Mean Absolute Percentage Error: 0.30040
 Training time:  0.31922
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.21705
  MAPE on 10 nodes subset: 0.02350

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.32818
  MAPE on 12 nodes subset: 0.27922

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.12244
  MAPE on 15 nodes subset: 0.01345

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.36109
  MAPE on 20 nodes subset: 0.08344

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19191
  MAPE on 25 nodes subset: 0.02621

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.606489 0.432675       0.366876                           xgboost_model_10.pkl       67
       10             Circuit            50           5          4 0.770824 0.407164       0.259763                   xgboost_model_10_Circuit.pkl       67
       12            Q_values            50          78          4 0.995228 0.660547       0.382282                           xgboost_model_12.pkl       67
       12             Circuit            50           5          4 1.114823 0.664105       0.270267                   xgboost_model_12_Circuit.pkl       67
       15            Q_values            50         120          4 0.603357 0.188782       0.473449                           xgboost_model_15.pkl       67
       15             Circuit            50           5          4 0.803180 0.235174       0.265382                   xgboost_model_15_Circuit.pkl       67
       20            Q_values            50         210          4 0.628374 0.270351       0.666587                           xgboost_model_20.pkl       67
       20             Circuit            50           5          4 0.844988 0.328912       0.264255                   xgboost_model_20_Circuit.pkl       67
       25            Q_values            50         325          4 0.756037 0.232928       0.758272                           xgboost_model_25.pkl       67
       25             Circuit            50           5          4 0.695445 0.184428       0.259513                   xgboost_model_25_Circuit.pkl       67
     full            Q_values           250         325          4 0.701604 0.301440       3.085790                         xgboost_model_full.pkl       67
     full             Circuit           250           5          4 0.750192 0.300401       0.319219                 xgboost_model_full_Circuit.pkl       67
       10 Q_values_full_model            50         325          4 0.217046 0.023500       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       67
       12 Q_values_full_model            50         325          4 0.328176 0.279221       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       67
       15 Q_values_full_model            50         325          4 0.122441 0.013453       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       67
       20 Q_values_full_model            50         325          4 0.361091 0.083438       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       67
       25 Q_values_full_model            50         325          4 0.191911 0.026209       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       67

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.3554
Epoch 002, Loss: 0.6178
Epoch 003, Loss: 0.5759
Epoch 004, Loss: 0.5922
Epoch 005, Loss: 0.5642
Epoch 006, Loss: 0.5735
Epoch 007, Loss: 0.5984
Epoch 008, Loss: 0.5988
Epoch 009, Loss: 0.5542
Epoch 010, Loss: 0.5766
Epoch 011, Loss: 0.6096
Epoch 012, Loss: 0.5633
Epoch 013, Loss: 0.5878
Epoch 014, Loss: 0.5798
Epoch 015, Loss: 0.5999
Epoch 016, Loss: 0.6031
Epoch 017, Loss: 0.5683
Epoch 018, Loss: 0.5724
Epoch 019, Loss: 0.5832
Epoch 020, Loss: 0.6729
Epoch 021, Loss: 0.5655
Epoch 022, Loss: 0.5419
Epoch 023, Loss: 0.5747
Epoch 024, Loss: 0.5810
Epoch 025, Loss: 0.6077
Epoch 026, Loss: 0.5495
Epoch 027, Loss: 0.6232
Epoch 028, Loss: 0.5980
Epoch 029, Loss: 0.5437
Epoch 030, Loss: 0.5678
Epoch 031, Loss: 0.5475
Epoch 032, Loss: 0.5476
Epoch 033, Loss: 0.5517
Epoch 034, Loss: 0.6010
Epoch 035, Loss: 0.5521
Epoch 036, Loss: 0.5716
Epoch 037, Loss: 0.5648
Epoch 038, Loss: 0.5594
Epoch 039, Loss: 0.5489
Epoch 040, Loss: 0.5634
Epoch 041, Loss: 0.5581
Epoch 042, Loss: 0.6294
Epoch 043, Loss: 0.5684
Epoch 044, Loss: 0.5426
Epoch 045, Loss: 0.5376
Epoch 046, Loss: 0.5431
Epoch 047, Loss: 0.5138
Epoch 048, Loss: 0.5162
Epoch 049, Loss: 0.5129
Epoch 050, Loss: 0.5168
Epoch 051, Loss: 0.5993
Epoch 052, Loss: 0.5204
Epoch 053, Loss: 0.5017
Epoch 054, Loss: 0.5423
Epoch 055, Loss: 0.5135
Epoch 056, Loss: 0.4814
Epoch 057, Loss: 0.4957
Epoch 058, Loss: 0.5071
Epoch 059, Loss: 0.4864
Epoch 060, Loss: 0.5118
Epoch 061, Loss: 0.5050
Epoch 062, Loss: 0.5449
Epoch 063, Loss: 0.5181
Epoch 064, Loss: 0.5041
Epoch 065, Loss: 0.5001
Epoch 066, Loss: 0.4963
Epoch 067, Loss: 0.5025
Epoch 068, Loss: 0.5015
Epoch 069, Loss: 0.4841
Epoch 070, Loss: 0.5045
Epoch 071, Loss: 0.4774
Epoch 072, Loss: 0.4929
Epoch 073, Loss: 0.4758
Epoch 074, Loss: 0.4960
Epoch 075, Loss: 0.4917
Epoch 076, Loss: 0.4760
Epoch 077, Loss: 0.4896
Epoch 078, Loss: 0.4701
Epoch 079, Loss: 0.4773
Epoch 080, Loss: 0.4700
Epoch 081, Loss: 0.5028
Epoch 082, Loss: 0.4817
Epoch 083, Loss: 0.4726
Epoch 084, Loss: 0.4653
Epoch 085, Loss: 0.4496
Epoch 086, Loss: 0.4475
Epoch 087, Loss: 0.4386
Epoch 088, Loss: 0.4581
Epoch 089, Loss: 0.4486
Epoch 090, Loss: 0.4569
Epoch 091, Loss: 0.4354
Epoch 092, Loss: 0.4554
Epoch 093, Loss: 0.4899
Epoch 094, Loss: 0.4504
Epoch 095, Loss: 0.4351
Epoch 096, Loss: 0.4551
Epoch 097, Loss: 0.4599
Epoch 098, Loss: 0.4548
Epoch 099, Loss: 0.4224
Epoch 100, Loss: 0.4349

Test RMSE: 0.6434
Test MAPE: 0.2426
Training time: 13.79 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.1955
Epoch 002, Loss: 0.9432
Epoch 003, Loss: 0.8781
Epoch 004, Loss: 0.9704
Epoch 005, Loss: 0.8813
Epoch 006, Loss: 0.8617
Epoch 007, Loss: 0.8982
Epoch 008, Loss: 0.8627
Epoch 009, Loss: 0.8489
Epoch 010, Loss: 0.9766
Epoch 011, Loss: 0.8437
Epoch 012, Loss: 0.8826
Epoch 013, Loss: 0.9156
Epoch 014, Loss: 0.9061
Epoch 015, Loss: 0.9135
Epoch 016, Loss: 0.8299
Epoch 017, Loss: 0.8833
Epoch 018, Loss: 0.8183
Epoch 019, Loss: 0.8261
Epoch 020, Loss: 0.8182
Epoch 021, Loss: 0.8128
Epoch 022, Loss: 0.8547
Epoch 023, Loss: 0.8895
Epoch 024, Loss: 0.8501
Epoch 025, Loss: 0.8225
Epoch 026, Loss: 0.8914
Epoch 027, Loss: 0.8372
Epoch 028, Loss: 0.8474
Epoch 029, Loss: 0.8471
Epoch 030, Loss: 0.8382
Epoch 031, Loss: 0.8856
Epoch 032, Loss: 0.8103
Epoch 033, Loss: 0.7983
Epoch 034, Loss: 0.8078
Epoch 035, Loss: 0.8298
Epoch 036, Loss: 0.7694
Epoch 037, Loss: 0.8223
Epoch 038, Loss: 0.8101
Epoch 039, Loss: 0.7766
Epoch 040, Loss: 0.7760
Epoch 041, Loss: 0.8085
Epoch 042, Loss: 0.7765
Epoch 043, Loss: 0.7808
Epoch 044, Loss: 0.7358
Epoch 045, Loss: 0.7703
Epoch 046, Loss: 0.7166
Epoch 047, Loss: 0.7173
Epoch 048, Loss: 0.7480
Epoch 049, Loss: 0.8129
Epoch 050, Loss: 0.7126
Epoch 051, Loss: 0.7058
Epoch 052, Loss: 0.7470
Epoch 053, Loss: 0.7485
Epoch 054, Loss: 0.7368
Epoch 055, Loss: 0.6916
Epoch 056, Loss: 0.6755
Epoch 057, Loss: 0.6634
Epoch 058, Loss: 0.6541
Epoch 059, Loss: 0.6687
Epoch 060, Loss: 0.6518
Epoch 061, Loss: 0.6859
Epoch 062, Loss: 0.6511
Epoch 063, Loss: 0.6689
Epoch 064, Loss: 0.6666
Epoch 065, Loss: 0.6239
Epoch 066, Loss: 0.6131
Epoch 067, Loss: 0.6663
Epoch 068, Loss: 0.6448
Epoch 069, Loss: 0.6748
Epoch 070, Loss: 0.6429
Epoch 071, Loss: 0.6203
Epoch 072, Loss: 0.6078
Epoch 073, Loss: 0.6069
Epoch 074, Loss: 0.6288
Epoch 075, Loss: 0.6105
Epoch 076, Loss: 0.5939
Epoch 077, Loss: 0.5888
Epoch 078, Loss: 0.6111
Epoch 079, Loss: 0.5843
Epoch 080, Loss: 0.6574
Epoch 081, Loss: 0.6127
Epoch 082, Loss: 0.5831
Epoch 083, Loss: 0.5694
Epoch 084, Loss: 0.6571
Epoch 085, Loss: 0.6105
Epoch 086, Loss: 0.5596
Epoch 087, Loss: 0.5668
Epoch 088, Loss: 0.6022
Epoch 089, Loss: 0.5608
Epoch 090, Loss: 0.5811
Epoch 091, Loss: 0.5539
Epoch 092, Loss: 0.5781
Epoch 093, Loss: 0.5793
Epoch 094, Loss: 0.5738
Epoch 095, Loss: 0.6304
Epoch 096, Loss: 0.5740
Epoch 097, Loss: 0.5693
Epoch 098, Loss: 0.5577
Epoch 099, Loss: 0.5465
Epoch 100, Loss: 0.5785

Test RMSE: 0.7249
Test MAPE: 0.1673
Training time: 13.99 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.9895
Epoch 002, Loss: 1.2693
Epoch 003, Loss: 0.9586
Epoch 004, Loss: 0.9351
Epoch 005, Loss: 0.9472
Epoch 006, Loss: 0.9378
Epoch 007, Loss: 1.0035
Epoch 008, Loss: 0.9473
Epoch 009, Loss: 0.9495
Epoch 010, Loss: 1.0156
Epoch 011, Loss: 1.0964
Epoch 012, Loss: 0.9374
Epoch 013, Loss: 0.9747
Epoch 014, Loss: 0.9671
Epoch 015, Loss: 1.0254
Epoch 016, Loss: 0.9496
Epoch 017, Loss: 0.9243
Epoch 018, Loss: 1.0163
Epoch 019, Loss: 0.9233
Epoch 020, Loss: 0.9010
Epoch 021, Loss: 0.9211
Epoch 022, Loss: 0.9652
Epoch 023, Loss: 0.8816
Epoch 024, Loss: 0.9141
Epoch 025, Loss: 0.9164
Epoch 026, Loss: 1.0818
Epoch 027, Loss: 1.0466
Epoch 028, Loss: 0.8599
Epoch 029, Loss: 0.9234
Epoch 030, Loss: 0.8789
Epoch 031, Loss: 0.8865
Epoch 032, Loss: 0.8972
Epoch 033, Loss: 0.8891
Epoch 034, Loss: 0.8583
Epoch 035, Loss: 0.9584
Epoch 036, Loss: 0.8617
Epoch 037, Loss: 0.8807
Epoch 038, Loss: 0.9099
Epoch 039, Loss: 0.8650
Epoch 040, Loss: 0.8715
Epoch 041, Loss: 0.9478
Epoch 042, Loss: 0.8699
Epoch 043, Loss: 0.9707
Epoch 044, Loss: 0.8924
Epoch 045, Loss: 0.8924
Epoch 046, Loss: 0.8212
Epoch 047, Loss: 0.8146
Epoch 048, Loss: 0.8169
Epoch 049, Loss: 0.7774
Epoch 050, Loss: 0.7973
Epoch 051, Loss: 0.7975
Epoch 052, Loss: 0.7930
Epoch 053, Loss: 0.8184
Epoch 054, Loss: 0.7434
Epoch 055, Loss: 0.7691
Epoch 056, Loss: 0.8382
Epoch 057, Loss: 0.7403
Epoch 058, Loss: 0.7467
Epoch 059, Loss: 0.7647
Epoch 060, Loss: 0.6864
Epoch 061, Loss: 0.7164
Epoch 062, Loss: 0.6566
Epoch 063, Loss: 0.7277
Epoch 064, Loss: 0.6514
Epoch 065, Loss: 0.7624
Epoch 066, Loss: 0.6979
Epoch 067, Loss: 0.6059
Epoch 068, Loss: 0.6521
Epoch 069, Loss: 0.6831
Epoch 070, Loss: 0.6745
Epoch 071, Loss: 0.6627
Epoch 072, Loss: 0.6068
Epoch 073, Loss: 0.6045
Epoch 074, Loss: 0.5763
Epoch 075, Loss: 0.6293
Epoch 076, Loss: 0.6134
Epoch 077, Loss: 0.5601
Epoch 078, Loss: 0.5342
Epoch 079, Loss: 0.5442
Epoch 080, Loss: 0.5166
Epoch 081, Loss: 0.6186
Epoch 082, Loss: 0.5567
Epoch 083, Loss: 0.6434
Epoch 084, Loss: 0.5968
Epoch 085, Loss: 0.5739
Epoch 086, Loss: 0.5318
Epoch 087, Loss: 0.5100
Epoch 088, Loss: 0.5977
Epoch 089, Loss: 0.5243
Epoch 090, Loss: 0.5360
Epoch 091, Loss: 0.5461
Epoch 092, Loss: 0.5632
Epoch 093, Loss: 0.5521
Epoch 094, Loss: 0.5145
Epoch 095, Loss: 0.5276
Epoch 096, Loss: 0.5556
Epoch 097, Loss: 0.5191
Epoch 098, Loss: 0.5333
Epoch 099, Loss: 0.5028
Epoch 100, Loss: 0.5285

Test RMSE: 0.8129
Test MAPE: 0.2061
Training time: 14.12 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 6.3227
Epoch 002, Loss: 1.3411
Epoch 003, Loss: 1.2492
Epoch 004, Loss: 1.2972
Epoch 005, Loss: 1.2465
Epoch 006, Loss: 1.3269
Epoch 007, Loss: 1.4319
Epoch 008, Loss: 1.3707
Epoch 009, Loss: 1.2433
Epoch 010, Loss: 1.4977
Epoch 011, Loss: 1.3568
Epoch 012, Loss: 1.3850
Epoch 013, Loss: 1.2802
Epoch 014, Loss: 1.1967
Epoch 015, Loss: 1.5737
Epoch 016, Loss: 1.3290
Epoch 017, Loss: 1.1723
Epoch 018, Loss: 1.4307
Epoch 019, Loss: 1.1721
Epoch 020, Loss: 1.2931
Epoch 021, Loss: 1.2706
Epoch 022, Loss: 1.4444
Epoch 023, Loss: 1.2639
Epoch 024, Loss: 1.1726
Epoch 025, Loss: 1.2228
Epoch 026, Loss: 1.2541
Epoch 027, Loss: 1.4264
Epoch 028, Loss: 1.3158
Epoch 029, Loss: 1.2511
Epoch 030, Loss: 1.1600
Epoch 031, Loss: 1.2182
Epoch 032, Loss: 1.2347
Epoch 033, Loss: 1.1570
Epoch 034, Loss: 1.5079
Epoch 035, Loss: 1.1725
Epoch 036, Loss: 1.2113
Epoch 037, Loss: 1.1800
Epoch 038, Loss: 1.1919
Epoch 039, Loss: 1.1783
Epoch 040, Loss: 1.2937
Epoch 041, Loss: 1.3989
Epoch 042, Loss: 1.2032
Epoch 043, Loss: 1.1817
Epoch 044, Loss: 1.2000
Epoch 045, Loss: 1.2574
Epoch 046, Loss: 1.3141
Epoch 047, Loss: 1.1233
Epoch 048, Loss: 1.0898
Epoch 049, Loss: 1.1892
Epoch 050, Loss: 1.1440
Epoch 051, Loss: 1.1104
Epoch 052, Loss: 1.2430
Epoch 053, Loss: 1.0330
Epoch 054, Loss: 1.1429
Epoch 055, Loss: 1.0035
Epoch 056, Loss: 0.9989
Epoch 057, Loss: 1.0290
Epoch 058, Loss: 0.9499
Epoch 059, Loss: 0.9735
Epoch 060, Loss: 1.0140
Epoch 061, Loss: 0.8893
Epoch 062, Loss: 0.9304
Epoch 063, Loss: 0.8761
Epoch 064, Loss: 0.9783
Epoch 065, Loss: 1.0298
Epoch 066, Loss: 0.9249
Epoch 067, Loss: 0.8206
Epoch 068, Loss: 0.9081
Epoch 069, Loss: 0.8557
Epoch 070, Loss: 0.7862
Epoch 071, Loss: 0.7062
Epoch 072, Loss: 0.7909
Epoch 073, Loss: 0.7960
Epoch 074, Loss: 0.7467
Epoch 075, Loss: 0.7878
Epoch 076, Loss: 0.7399
Epoch 077, Loss: 0.6941
Epoch 078, Loss: 0.7038
Epoch 079, Loss: 0.7264
Epoch 080, Loss: 0.7620
Epoch 081, Loss: 0.7223
Epoch 082, Loss: 0.6730
Epoch 083, Loss: 0.6844
Epoch 084, Loss: 0.6902
Epoch 085, Loss: 0.6319
Epoch 086, Loss: 0.8070
Epoch 087, Loss: 0.7168
Epoch 088, Loss: 0.6053
Epoch 089, Loss: 0.5921
Epoch 090, Loss: 0.6653
Epoch 091, Loss: 0.6741
Epoch 092, Loss: 0.6582
Epoch 093, Loss: 0.6183
Epoch 094, Loss: 0.6522
Epoch 095, Loss: 0.5905
Epoch 096, Loss: 0.5844
Epoch 097, Loss: 0.6149
Epoch 098, Loss: 0.6853
Epoch 099, Loss: 0.5752
Epoch 100, Loss: 0.6276

Test RMSE: 1.0023
Test MAPE: 0.2594
Training time: 14.40 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.5926
Epoch 002, Loss: 1.7975
Epoch 003, Loss: 1.8237
Epoch 004, Loss: 1.6413
Epoch 005, Loss: 1.6537
Epoch 006, Loss: 1.6503
Epoch 007, Loss: 1.5945
Epoch 008, Loss: 1.6127
Epoch 009, Loss: 1.6509
Epoch 010, Loss: 1.5948
Epoch 011, Loss: 1.5785
Epoch 012, Loss: 1.5236
Epoch 013, Loss: 1.5924
Epoch 014, Loss: 1.6515
Epoch 015, Loss: 1.5486
Epoch 016, Loss: 1.4812
Epoch 017, Loss: 1.5637
Epoch 018, Loss: 1.6111
Epoch 019, Loss: 1.4502
Epoch 020, Loss: 1.5422
Epoch 021, Loss: 1.6328
Epoch 022, Loss: 1.4327
Epoch 023, Loss: 1.7184
Epoch 024, Loss: 1.6189
Epoch 025, Loss: 1.5116
Epoch 026, Loss: 1.5689
Epoch 027, Loss: 1.5838
Epoch 028, Loss: 1.6179
Epoch 029, Loss: 1.5868
Epoch 030, Loss: 1.6424
Epoch 031, Loss: 1.4415
Epoch 032, Loss: 1.7908
Epoch 033, Loss: 1.5161
Epoch 034, Loss: 1.5853
Epoch 035, Loss: 1.7522
Epoch 036, Loss: 1.4581
Epoch 037, Loss: 1.8519
Epoch 038, Loss: 1.4972
Epoch 039, Loss: 1.5289
Epoch 040, Loss: 1.5186
Epoch 041, Loss: 1.4366
Epoch 042, Loss: 1.5272
Epoch 043, Loss: 1.7001
Epoch 044, Loss: 1.6602
Epoch 045, Loss: 1.7519
Epoch 046, Loss: 1.4137
Epoch 047, Loss: 1.6892
Epoch 048, Loss: 1.7766
Epoch 049, Loss: 1.8944
Epoch 050, Loss: 1.5637
Epoch 051, Loss: 1.3932
Epoch 052, Loss: 1.7972
Epoch 053, Loss: 1.5719
Epoch 054, Loss: 1.4666
Epoch 055, Loss: 1.4644
Epoch 056, Loss: 1.4164
Epoch 057, Loss: 1.5606
Epoch 058, Loss: 1.5151
Epoch 059, Loss: 1.4484
Epoch 060, Loss: 1.4029
Epoch 061, Loss: 1.4006
Epoch 062, Loss: 1.4815
Epoch 063, Loss: 1.6112
Epoch 064, Loss: 1.5509
Epoch 065, Loss: 1.3229
Epoch 066, Loss: 1.5099
Epoch 067, Loss: 1.6122
Epoch 068, Loss: 1.4695
Epoch 069, Loss: 1.4114
Epoch 070, Loss: 1.4828
Epoch 071, Loss: 1.4608
Epoch 072, Loss: 1.5719
Epoch 073, Loss: 1.4396
Epoch 074, Loss: 1.4949
Epoch 075, Loss: 1.4796
Epoch 076, Loss: 1.5241
Epoch 077, Loss: 1.3809
Epoch 078, Loss: 1.4109
Epoch 079, Loss: 1.5397
Epoch 080, Loss: 1.4232
Epoch 081, Loss: 1.4376
Epoch 082, Loss: 1.5198
Epoch 083, Loss: 1.4064
Epoch 084, Loss: 1.3939
Epoch 085, Loss: 1.3828
Epoch 086, Loss: 1.4998
Epoch 087, Loss: 1.5392
Epoch 088, Loss: 1.5939
Epoch 089, Loss: 1.3675
Epoch 090, Loss: 1.4239
Epoch 091, Loss: 1.4374
Epoch 092, Loss: 1.3845
Epoch 093, Loss: 1.3631
Epoch 094, Loss: 1.5859
Epoch 095, Loss: 1.4235
Epoch 096, Loss: 1.4263
Epoch 097, Loss: 1.4591
Epoch 098, Loss: 1.4625
Epoch 099, Loss: 1.3517
Epoch 100, Loss: 1.2150

Test RMSE: 1.8809
Test MAPE: 0.2448
Training time: 14.98 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7884
Epoch 002, Loss: 3.1402
Epoch 003, Loss: 1.7179
Epoch 004, Loss: 0.8073
Epoch 005, Loss: 0.7288
Epoch 006, Loss: 0.7399
Epoch 007, Loss: 0.9280
Epoch 008, Loss: 0.6974
Epoch 009, Loss: 0.6583
Epoch 010, Loss: 0.7552
Epoch 011, Loss: 0.6479
Epoch 012, Loss: 0.6571
Epoch 013, Loss: 0.7006
Epoch 014, Loss: 0.6464
Epoch 015, Loss: 0.6423
Epoch 016, Loss: 0.6364
Epoch 017, Loss: 0.6220
Epoch 018, Loss: 0.6168
Epoch 019, Loss: 0.5999
Epoch 020, Loss: 0.6079
Epoch 021, Loss: 0.5626
Epoch 022, Loss: 0.5672
Epoch 023, Loss: 0.5788
Epoch 024, Loss: 0.6074
Epoch 025, Loss: 0.7148
Epoch 026, Loss: 0.5831
Epoch 027, Loss: 0.5870
Epoch 028, Loss: 0.6090
Epoch 029, Loss: 0.5613
Epoch 030, Loss: 0.5540
Epoch 031, Loss: 0.5602
Epoch 032, Loss: 0.5523
Epoch 033, Loss: 0.6390
Epoch 034, Loss: 0.5580
Epoch 035, Loss: 0.6057
Epoch 036, Loss: 0.5690
Epoch 037, Loss: 0.5980
Epoch 038, Loss: 0.5829
Epoch 039, Loss: 0.5792
Epoch 040, Loss: 0.5411
Epoch 041, Loss: 0.5946
Epoch 042, Loss: 0.5944
Epoch 043, Loss: 0.5643
Epoch 044, Loss: 0.6112
Epoch 045, Loss: 0.5701
Epoch 046, Loss: 0.5704
Epoch 047, Loss: 0.5241
Epoch 048, Loss: 0.5811
Epoch 049, Loss: 0.5771
Epoch 050, Loss: 0.5518
Epoch 051, Loss: 0.5537
Epoch 052, Loss: 0.4954
Epoch 053, Loss: 0.5456
Epoch 054, Loss: 0.5670
Epoch 055, Loss: 0.5451
Epoch 056, Loss: 0.5430
Epoch 057, Loss: 0.5611
Epoch 058, Loss: 0.5535
Epoch 059, Loss: 0.4978
Epoch 060, Loss: 0.5476
Epoch 061, Loss: 0.5245
Epoch 062, Loss: 0.5425
Epoch 063, Loss: 0.5784
Epoch 064, Loss: 0.5088
Epoch 065, Loss: 0.5424
Epoch 066, Loss: 0.5445
Epoch 067, Loss: 0.5055
Epoch 068, Loss: 0.5195
Epoch 069, Loss: 0.5109
Epoch 070, Loss: 0.5085
Epoch 071, Loss: 0.5007
Epoch 072, Loss: 0.5577
Epoch 073, Loss: 0.4787
Epoch 074, Loss: 0.4929
Epoch 075, Loss: 0.5373
Epoch 076, Loss: 0.5563
Epoch 077, Loss: 0.4902
Epoch 078, Loss: 0.5301
Epoch 079, Loss: 0.4974
Epoch 080, Loss: 0.5872
Epoch 081, Loss: 0.4733
Epoch 082, Loss: 0.5535
Epoch 083, Loss: 0.5011
Epoch 084, Loss: 0.5476
Epoch 085, Loss: 0.4920
Epoch 086, Loss: 0.5184
Epoch 087, Loss: 0.5096
Epoch 088, Loss: 0.4684
Epoch 089, Loss: 0.4646
Epoch 090, Loss: 0.5469
Epoch 091, Loss: 0.5013
Epoch 092, Loss: 0.4866
Epoch 093, Loss: 0.4542
Epoch 094, Loss: 0.4975
Epoch 095, Loss: 0.4835
Epoch 096, Loss: 0.5034
Epoch 097, Loss: 0.4857
Epoch 098, Loss: 0.5102
Epoch 099, Loss: 0.5064
Epoch 100, Loss: 0.5071

Test RMSE: 0.7684
Test MAPE: 197509540478976.0000
Training time: 72.82 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.643388 2.426192e-01      13.785992   GNN_model_10.pkl
       12   Q_values        0.2 0.724930 1.672792e-01      13.985934   GNN_model_12.pkl
       15   Q_values        0.2 0.812868 2.060955e-01      14.115325   GNN_model_15.pkl
       20   Q_values        0.2 1.002315 2.594152e-01      14.395389   GNN_model_20.pkl
       25   Q_values        0.2 1.880862 2.448348e-01      14.981652   GNN_model_25.pkl
     full   Q_values        0.2 0.768403 1.975095e+14      72.824590 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 85%)
