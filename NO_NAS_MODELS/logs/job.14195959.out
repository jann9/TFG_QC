
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59774
 Mean Absolute Percentage Error: 0.25486
 Training time:  0.02811
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.54961
 Mean Absolute Percentage Error: 0.38378
 Training time:  0.01366
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71589
 Mean Absolute Percentage Error: 0.57781
 Training time:  0.04702
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86404
 Mean Absolute Percentage Error: 0.54142
 Training time:  0.01339
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70491
 Mean Absolute Percentage Error: 0.30302
 Training time:  0.02768
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52115
 Mean Absolute Percentage Error: 0.17748
 Training time:  0.01308
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60422
 Mean Absolute Percentage Error: 0.22650
 Training time:  0.06506
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61151
 Mean Absolute Percentage Error: 0.25275
 Training time:  0.01274
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53874
 Mean Absolute Percentage Error: 0.17863
 Training time:  0.13005
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69177
 Mean Absolute Percentage Error: 0.21564
 Training time:  0.03216
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61670
 Mean Absolute Percentage Error: 0.23984
 Training time:  0.16929
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.66595
 Mean Absolute Percentage Error: 0.28817
 Training time:  0.03995
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60201
  MAPE on 10 nodes subset: 0.26809

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70916
  MAPE on 12 nodes subset: 0.57095

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68681
  MAPE on 15 nodes subset: 0.29215

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58614
  MAPE on 20 nodes subset: 0.22844

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53001
  MAPE on 25 nodes subset: 0.18543

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597737 0.254863       0.028113       True             4                       MLP_model_10.pkl       86
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.549607 0.383776       0.013659       True             3               MLP_model_10_Circuit.pkl       86
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715893 0.577806       0.047020       True             4                       MLP_model_12.pkl       86
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.864043 0.541422       0.013390       True             4               MLP_model_12_Circuit.pkl       86
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704909 0.303019       0.027682       True             4                       MLP_model_15.pkl       86
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521153 0.177482       0.013084       True             4               MLP_model_15_Circuit.pkl       86
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604218 0.226500       0.065060       True             4                       MLP_model_20.pkl       86
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611509 0.252747       0.012743       True             3               MLP_model_20_Circuit.pkl       86
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.538741 0.178632       0.130054       True             4                       MLP_model_25.pkl       86
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.691768 0.215636       0.032163       True             3               MLP_model_25_Circuit.pkl       86
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616702 0.239841       0.169294       True             4                     MLP_model_full.pkl       86
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.665955 0.288175       0.039950       True             3             MLP_model_full_Circuit.pkl       86
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602008 0.268090       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       86
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709160 0.570946       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       86
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.686813 0.292150       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       86
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586135 0.228437       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       86
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.530009 0.185433       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       86

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61160
 Mean Absolute Percentage Error: 0.43595
 Training time:  0.36334
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76082
 Mean Absolute Percentage Error: 0.40360
 Training time:  0.26322
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.96701
 Mean Absolute Percentage Error: 0.66453
 Training time:  0.38958
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10980
 Mean Absolute Percentage Error: 0.66128
 Training time:  0.26230
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.60487
 Mean Absolute Percentage Error: 0.18279
 Training time:  0.47325
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79429
 Mean Absolute Percentage Error: 0.22773
 Training time:  0.26325
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.65573
 Mean Absolute Percentage Error: 0.27689
 Training time:  0.72611
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85008
 Mean Absolute Percentage Error: 0.33061
 Training time:  0.29422
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.73328
 Mean Absolute Percentage Error: 0.21823
 Training time:  0.86438
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69807
 Mean Absolute Percentage Error: 0.18649
 Training time:  0.27353
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71283
 Mean Absolute Percentage Error: 0.30509
 Training time:  3.60035
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.75271
 Mean Absolute Percentage Error: 0.30165
 Training time:  0.36128
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.21485
  MAPE on 10 nodes subset: 0.02706

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34624
  MAPE on 12 nodes subset: 0.27715

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13340
  MAPE on 15 nodes subset: 0.01390

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39731
  MAPE on 20 nodes subset: 0.09455

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.17620
  MAPE on 25 nodes subset: 0.02318

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.611602 0.435950       0.363337                           xgboost_model_10.pkl       80
       10             Circuit            50           5          4 0.760818 0.403600       0.263217                   xgboost_model_10_Circuit.pkl       80
       12            Q_values            50          78          4 0.967009 0.664526       0.389581                           xgboost_model_12.pkl       80
       12             Circuit            50           5          4 1.109798 0.661276       0.262301                   xgboost_model_12_Circuit.pkl       80
       15            Q_values            50         120          4 0.604875 0.182788       0.473250                           xgboost_model_15.pkl       80
       15             Circuit            50           5          4 0.794289 0.227733       0.263249                   xgboost_model_15_Circuit.pkl       80
       20            Q_values            50         210          4 0.655733 0.276886       0.726110                           xgboost_model_20.pkl       80
       20             Circuit            50           5          4 0.850080 0.330606       0.294217                   xgboost_model_20_Circuit.pkl       80
       25            Q_values            50         325          4 0.733276 0.218226       0.864378                           xgboost_model_25.pkl       80
       25             Circuit            50           5          4 0.698073 0.186487       0.273526                   xgboost_model_25_Circuit.pkl       80
     full            Q_values           250         325          4 0.712828 0.305091       3.600348                         xgboost_model_full.pkl       80
     full             Circuit           250           5          4 0.752711 0.301650       0.361285                 xgboost_model_full_Circuit.pkl       80
       10 Q_values_full_model            50         325          4 0.214848 0.027056       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       80
       12 Q_values_full_model            50         325          4 0.346239 0.277149       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       80
       15 Q_values_full_model            50         325          4 0.133400 0.013900       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       80
       20 Q_values_full_model            50         325          4 0.397308 0.094551       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       80
       25 Q_values_full_model            50         325          4 0.176198 0.023178       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       80

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 3.2138
Epoch 002, Loss: 0.5940
Epoch 003, Loss: 0.5915
Epoch 004, Loss: 0.6131
Epoch 005, Loss: 0.6188
Epoch 006, Loss: 0.6260
Epoch 007, Loss: 0.5634
Epoch 008, Loss: 0.5665
Epoch 009, Loss: 0.5533
Epoch 010, Loss: 0.5484
Epoch 011, Loss: 0.6086
Epoch 012, Loss: 0.5625
Epoch 013, Loss: 0.6105
Epoch 014, Loss: 0.5965
Epoch 015, Loss: 0.6046
Epoch 016, Loss: 0.6344
Epoch 017, Loss: 0.5618
Epoch 018, Loss: 0.6163
Epoch 019, Loss: 0.6678
Epoch 020, Loss: 0.5770
Epoch 021, Loss: 0.6081
Epoch 022, Loss: 0.5414
Epoch 023, Loss: 0.5473
Epoch 024, Loss: 0.5984
Epoch 025, Loss: 0.5457
Epoch 026, Loss: 0.5635
Epoch 027, Loss: 0.5462
Epoch 028, Loss: 0.5358
Epoch 029, Loss: 0.5692
Epoch 030, Loss: 0.5353
Epoch 031, Loss: 0.5601
Epoch 032, Loss: 0.5081
Epoch 033, Loss: 0.5484
Epoch 034, Loss: 0.5342
Epoch 035, Loss: 0.5430
Epoch 036, Loss: 0.5373
Epoch 037, Loss: 0.5599
Epoch 038, Loss: 0.5390
Epoch 039, Loss: 0.5056
Epoch 040, Loss: 0.5167
Epoch 041, Loss: 0.5152
Epoch 042, Loss: 0.5071
Epoch 043, Loss: 0.5411
Epoch 044, Loss: 0.5537
Epoch 045, Loss: 0.5466
Epoch 046, Loss: 0.5141
Epoch 047, Loss: 0.5175
Epoch 048, Loss: 0.5238
Epoch 049, Loss: 0.5150
Epoch 050, Loss: 0.5100
Epoch 051, Loss: 0.5213
Epoch 052, Loss: 0.4988
Epoch 053, Loss: 0.5323
Epoch 054, Loss: 0.4976
Epoch 055, Loss: 0.5161
Epoch 056, Loss: 0.5052
Epoch 057, Loss: 0.4857
Epoch 058, Loss: 0.4867
Epoch 059, Loss: 0.4738
Epoch 060, Loss: 0.4775
Epoch 061, Loss: 0.5011
Epoch 062, Loss: 0.4814
Epoch 063, Loss: 0.5457
Epoch 064, Loss: 0.4979
Epoch 065, Loss: 0.4989
Epoch 066, Loss: 0.4955
Epoch 067, Loss: 0.4757
Epoch 068, Loss: 0.4833
Epoch 069, Loss: 0.4972
Epoch 070, Loss: 0.4743
Epoch 071, Loss: 0.4687
Epoch 072, Loss: 0.4858
Epoch 073, Loss: 0.4523
Epoch 074, Loss: 0.4609
Epoch 075, Loss: 0.4734
Epoch 076, Loss: 0.4969
Epoch 077, Loss: 0.4503
Epoch 078, Loss: 0.4881
Epoch 079, Loss: 0.4520
Epoch 080, Loss: 0.4596
Epoch 081, Loss: 0.4572
Epoch 082, Loss: 0.4262
Epoch 083, Loss: 0.4604
Epoch 084, Loss: 0.4663
Epoch 085, Loss: 0.4600
Epoch 086, Loss: 0.4382
Epoch 087, Loss: 0.4492
Epoch 088, Loss: 0.4648
Epoch 089, Loss: 0.4361
Epoch 090, Loss: 0.4361
Epoch 091, Loss: 0.4312
Epoch 092, Loss: 0.4405
Epoch 093, Loss: 0.4354
Epoch 094, Loss: 0.4336
Epoch 095, Loss: 0.4421
Epoch 096, Loss: 0.4304
Epoch 097, Loss: 0.4442
Epoch 098, Loss: 0.4485
Epoch 099, Loss: 0.4362
Epoch 100, Loss: 0.4288

Test RMSE: 0.6302
Test MAPE: 0.2373
Training time: 13.64 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.8984
Epoch 002, Loss: 0.8683
Epoch 003, Loss: 0.9530
Epoch 004, Loss: 0.8550
Epoch 005, Loss: 0.8598
Epoch 006, Loss: 0.8233
Epoch 007, Loss: 0.8803
Epoch 008, Loss: 0.8738
Epoch 009, Loss: 0.8669
Epoch 010, Loss: 0.8255
Epoch 011, Loss: 0.8689
Epoch 012, Loss: 0.8826
Epoch 013, Loss: 0.8257
Epoch 014, Loss: 0.8594
Epoch 015, Loss: 0.8313
Epoch 016, Loss: 0.8514
Epoch 017, Loss: 0.8596
Epoch 018, Loss: 0.8984
Epoch 019, Loss: 0.8302
Epoch 020, Loss: 0.8862
Epoch 021, Loss: 0.8273
Epoch 022, Loss: 0.8522
Epoch 023, Loss: 0.8942
Epoch 024, Loss: 0.8947
Epoch 025, Loss: 0.7972
Epoch 026, Loss: 0.8297
Epoch 027, Loss: 0.8506
Epoch 028, Loss: 0.8318
Epoch 029, Loss: 0.8145
Epoch 030, Loss: 0.7942
Epoch 031, Loss: 0.8321
Epoch 032, Loss: 0.8149
Epoch 033, Loss: 0.8479
Epoch 034, Loss: 0.8085
Epoch 035, Loss: 0.8199
Epoch 036, Loss: 0.8299
Epoch 037, Loss: 0.8075
Epoch 038, Loss: 0.7952
Epoch 039, Loss: 0.8057
Epoch 040, Loss: 0.8330
Epoch 041, Loss: 0.8775
Epoch 042, Loss: 0.8421
Epoch 043, Loss: 0.8069
Epoch 044, Loss: 0.8273
Epoch 045, Loss: 0.8372
Epoch 046, Loss: 0.7853
Epoch 047, Loss: 0.7487
Epoch 048, Loss: 0.7461
Epoch 049, Loss: 0.7606
Epoch 050, Loss: 0.7337
Epoch 051, Loss: 0.7694
Epoch 052, Loss: 0.7765
Epoch 053, Loss: 0.7576
Epoch 054, Loss: 0.7573
Epoch 055, Loss: 0.7291
Epoch 056, Loss: 0.7305
Epoch 057, Loss: 0.7044
Epoch 058, Loss: 0.7561
Epoch 059, Loss: 0.7190
Epoch 060, Loss: 0.7055
Epoch 061, Loss: 0.7147
Epoch 062, Loss: 0.7219
Epoch 063, Loss: 0.6524
Epoch 064, Loss: 0.7464
Epoch 065, Loss: 0.6600
Epoch 066, Loss: 0.6956
Epoch 067, Loss: 0.6901
Epoch 068, Loss: 0.7035
Epoch 069, Loss: 0.6711
Epoch 070, Loss: 0.6941
Epoch 071, Loss: 0.6857
Epoch 072, Loss: 0.7020
Epoch 073, Loss: 0.6427
Epoch 074, Loss: 0.6622
Epoch 075, Loss: 0.6521
Epoch 076, Loss: 0.6427
Epoch 077, Loss: 0.6580
Epoch 078, Loss: 0.6696
Epoch 079, Loss: 0.6353
Epoch 080, Loss: 0.6881
Epoch 081, Loss: 0.6470
Epoch 082, Loss: 0.6205
Epoch 083, Loss: 0.6692
Epoch 084, Loss: 0.6498
Epoch 085, Loss: 0.6299
Epoch 086, Loss: 0.6090
Epoch 087, Loss: 0.6523
Epoch 088, Loss: 0.6087
Epoch 089, Loss: 0.6240
Epoch 090, Loss: 0.5936
Epoch 091, Loss: 0.6472
Epoch 092, Loss: 0.6345
Epoch 093, Loss: 0.6032
Epoch 094, Loss: 0.6038
Epoch 095, Loss: 0.5957
Epoch 096, Loss: 0.6322
Epoch 097, Loss: 0.6059
Epoch 098, Loss: 0.5946
Epoch 099, Loss: 0.5803
Epoch 100, Loss: 0.6531

Test RMSE: 0.6767
Test MAPE: 0.2179
Training time: 13.19 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.5252
Epoch 002, Loss: 1.0660
Epoch 003, Loss: 0.9842
Epoch 004, Loss: 1.0674
Epoch 005, Loss: 0.9424
Epoch 006, Loss: 0.9993
Epoch 007, Loss: 1.0866
Epoch 008, Loss: 0.9503
Epoch 009, Loss: 0.9748
Epoch 010, Loss: 0.9368
Epoch 011, Loss: 0.9962
Epoch 012, Loss: 0.9021
Epoch 013, Loss: 0.9483
Epoch 014, Loss: 0.9404
Epoch 015, Loss: 0.9706
Epoch 016, Loss: 0.9463
Epoch 017, Loss: 0.9401
Epoch 018, Loss: 0.9934
Epoch 019, Loss: 1.0548
Epoch 020, Loss: 0.9905
Epoch 021, Loss: 0.8999
Epoch 022, Loss: 0.9515
Epoch 023, Loss: 0.8976
Epoch 024, Loss: 0.9299
Epoch 025, Loss: 0.9421
Epoch 026, Loss: 1.0038
Epoch 027, Loss: 0.8916
Epoch 028, Loss: 0.8987
Epoch 029, Loss: 0.8893
Epoch 030, Loss: 0.9929
Epoch 031, Loss: 0.9075
Epoch 032, Loss: 0.8797
Epoch 033, Loss: 0.9388
Epoch 034, Loss: 0.9183
Epoch 035, Loss: 0.9133
Epoch 036, Loss: 0.9391
Epoch 037, Loss: 0.9121
Epoch 038, Loss: 0.8812
Epoch 039, Loss: 0.8983
Epoch 040, Loss: 0.8792
Epoch 041, Loss: 0.9969
Epoch 042, Loss: 0.8519
Epoch 043, Loss: 0.8076
Epoch 044, Loss: 0.8172
Epoch 045, Loss: 0.8391
Epoch 046, Loss: 0.7922
Epoch 047, Loss: 0.7938
Epoch 048, Loss: 0.8558
Epoch 049, Loss: 0.7903
Epoch 050, Loss: 0.7484
Epoch 051, Loss: 0.9474
Epoch 052, Loss: 0.8337
Epoch 053, Loss: 0.8546
Epoch 054, Loss: 0.7779
Epoch 055, Loss: 0.7406
Epoch 056, Loss: 0.8176
Epoch 057, Loss: 0.8089
Epoch 058, Loss: 0.7866
Epoch 059, Loss: 0.6945
Epoch 060, Loss: 0.6990
Epoch 061, Loss: 0.7068
Epoch 062, Loss: 0.6952
Epoch 063, Loss: 0.7751
Epoch 064, Loss: 0.7561
Epoch 065, Loss: 0.6881
Epoch 066, Loss: 0.6700
Epoch 067, Loss: 0.6425
Epoch 068, Loss: 0.6449
Epoch 069, Loss: 0.6461
Epoch 070, Loss: 0.6889
Epoch 071, Loss: 0.6679
Epoch 072, Loss: 0.6137
Epoch 073, Loss: 0.6733
Epoch 074, Loss: 0.6017
Epoch 075, Loss: 0.6448
Epoch 076, Loss: 0.6348
Epoch 077, Loss: 0.6272
Epoch 078, Loss: 0.6353
Epoch 079, Loss: 0.7955
Epoch 080, Loss: 0.6197
Epoch 081, Loss: 0.6392
Epoch 082, Loss: 0.6044
Epoch 083, Loss: 0.6140
Epoch 084, Loss: 0.5656
Epoch 085, Loss: 0.5833
Epoch 086, Loss: 0.6184
Epoch 087, Loss: 0.6240
Epoch 088, Loss: 0.6056
Epoch 089, Loss: 0.5744
Epoch 090, Loss: 0.6072
Epoch 091, Loss: 0.5677
Epoch 092, Loss: 0.5281
Epoch 093, Loss: 0.6423
Epoch 094, Loss: 0.5725
Epoch 095, Loss: 0.5698
Epoch 096, Loss: 0.5384
Epoch 097, Loss: 0.5803
Epoch 098, Loss: 0.5450
Epoch 099, Loss: 0.6109
Epoch 100, Loss: 0.5925

Test RMSE: 0.8449
Test MAPE: 0.1932
Training time: 12.57 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.1858
Epoch 002, Loss: 1.2791
Epoch 003, Loss: 1.1722
Epoch 004, Loss: 1.3725
Epoch 005, Loss: 1.1987
Epoch 006, Loss: 1.2756
Epoch 007, Loss: 1.2498
Epoch 008, Loss: 1.3093
Epoch 009, Loss: 1.2572
Epoch 010, Loss: 1.2516
Epoch 011, Loss: 1.3575
Epoch 012, Loss: 1.5337
Epoch 013, Loss: 1.3659
Epoch 014, Loss: 1.1904
Epoch 015, Loss: 1.3583
Epoch 016, Loss: 1.2404
Epoch 017, Loss: 1.1545
Epoch 018, Loss: 1.1951
Epoch 019, Loss: 1.3066
Epoch 020, Loss: 1.1801
Epoch 021, Loss: 1.2575
Epoch 022, Loss: 1.2057
Epoch 023, Loss: 1.3018
Epoch 024, Loss: 1.2226
Epoch 025, Loss: 1.1849
Epoch 026, Loss: 1.3712
Epoch 027, Loss: 1.1499
Epoch 028, Loss: 1.2322
Epoch 029, Loss: 1.1732
Epoch 030, Loss: 1.2124
Epoch 031, Loss: 1.3422
Epoch 032, Loss: 1.2095
Epoch 033, Loss: 1.1562
Epoch 034, Loss: 1.2102
Epoch 035, Loss: 1.1804
Epoch 036, Loss: 1.1342
Epoch 037, Loss: 1.2252
Epoch 038, Loss: 1.1622
Epoch 039, Loss: 1.1030
Epoch 040, Loss: 1.0749
Epoch 041, Loss: 1.0392
Epoch 042, Loss: 0.9799
Epoch 043, Loss: 1.1829
Epoch 044, Loss: 0.9865
Epoch 045, Loss: 1.0924
Epoch 046, Loss: 0.8932
Epoch 047, Loss: 0.8658
Epoch 048, Loss: 0.8844
Epoch 049, Loss: 0.8926
Epoch 050, Loss: 0.9458
Epoch 051, Loss: 0.8468
Epoch 052, Loss: 0.8218
Epoch 053, Loss: 0.8697
Epoch 054, Loss: 0.7583
Epoch 055, Loss: 0.7938
Epoch 056, Loss: 0.8113
Epoch 057, Loss: 0.8138
Epoch 058, Loss: 0.7674
Epoch 059, Loss: 0.7913
Epoch 060, Loss: 0.7589
Epoch 061, Loss: 0.8460
Epoch 062, Loss: 0.8031
Epoch 063, Loss: 0.7375
Epoch 064, Loss: 0.7342
Epoch 065, Loss: 0.7841
Epoch 066, Loss: 0.6526
Epoch 067, Loss: 0.7617
Epoch 068, Loss: 0.6852
Epoch 069, Loss: 0.7654
Epoch 070, Loss: 0.6461
Epoch 071, Loss: 0.6590
Epoch 072, Loss: 0.6304
Epoch 073, Loss: 0.5937
Epoch 074, Loss: 0.6504
Epoch 075, Loss: 0.5878
Epoch 076, Loss: 0.6492
Epoch 077, Loss: 0.5882
Epoch 078, Loss: 0.6702
Epoch 079, Loss: 0.6525
Epoch 080, Loss: 0.6246
Epoch 081, Loss: 0.6036
Epoch 082, Loss: 0.6481
Epoch 083, Loss: 0.5833
Epoch 084, Loss: 0.6926
Epoch 085, Loss: 0.5721
Epoch 086, Loss: 0.5623
Epoch 087, Loss: 0.5452
Epoch 088, Loss: 0.6568
Epoch 089, Loss: 0.6162
Epoch 090, Loss: 0.5954
Epoch 091, Loss: 0.5468
Epoch 092, Loss: 0.5343
Epoch 093, Loss: 0.6064
Epoch 094, Loss: 0.5503
Epoch 095, Loss: 0.5852
Epoch 096, Loss: 0.6290
Epoch 097, Loss: 0.5217
Epoch 098, Loss: 0.5388
Epoch 099, Loss: 0.5153
Epoch 100, Loss: 0.6172

Test RMSE: 0.8838
Test MAPE: 0.2657
Training time: 12.86 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 9.5099
Epoch 002, Loss: 1.6425
Epoch 003, Loss: 1.6275
Epoch 004, Loss: 1.6441
Epoch 005, Loss: 1.5368
Epoch 006, Loss: 1.5899
Epoch 007, Loss: 1.5158
Epoch 008, Loss: 1.6808
Epoch 009, Loss: 1.5747
Epoch 010, Loss: 1.8147
Epoch 011, Loss: 1.5037
Epoch 012, Loss: 1.7423
Epoch 013, Loss: 1.7714
Epoch 014, Loss: 1.8359
Epoch 015, Loss: 1.5885
Epoch 016, Loss: 1.5284
Epoch 017, Loss: 1.4535
Epoch 018, Loss: 1.7063
Epoch 019, Loss: 1.6270
Epoch 020, Loss: 1.7043
Epoch 021, Loss: 1.5195
Epoch 022, Loss: 1.5259
Epoch 023, Loss: 1.6006
Epoch 024, Loss: 1.7913
Epoch 025, Loss: 1.5677
Epoch 026, Loss: 1.5849
Epoch 027, Loss: 1.5380
Epoch 028, Loss: 1.5114
Epoch 029, Loss: 1.6342
Epoch 030, Loss: 1.7359
Epoch 031, Loss: 1.6667
Epoch 032, Loss: 1.6332
Epoch 033, Loss: 1.7319
Epoch 034, Loss: 1.4891
Epoch 035, Loss: 1.7124
Epoch 036, Loss: 1.5135
Epoch 037, Loss: 1.5986
Epoch 038, Loss: 1.4472
Epoch 039, Loss: 1.5229
Epoch 040, Loss: 1.6699
Epoch 041, Loss: 1.6517
Epoch 042, Loss: 1.5320
Epoch 043, Loss: 1.5355
Epoch 044, Loss: 1.9063
Epoch 045, Loss: 2.0590
Epoch 046, Loss: 1.4978
Epoch 047, Loss: 1.5326
Epoch 048, Loss: 1.4905
Epoch 049, Loss: 1.5210
Epoch 050, Loss: 1.5936
Epoch 051, Loss: 1.4406
Epoch 052, Loss: 1.5233
Epoch 053, Loss: 1.4321
Epoch 054, Loss: 1.4787
Epoch 055, Loss: 1.4480
Epoch 056, Loss: 1.7040
Epoch 057, Loss: 1.7679
Epoch 058, Loss: 1.4165
Epoch 059, Loss: 1.3955
Epoch 060, Loss: 1.4603
Epoch 061, Loss: 1.3985
Epoch 062, Loss: 1.3734
Epoch 063, Loss: 1.4576
Epoch 064, Loss: 1.3486
Epoch 065, Loss: 1.1717
Epoch 066, Loss: 1.8260
Epoch 067, Loss: 1.2567
Epoch 068, Loss: 1.3968
Epoch 069, Loss: 1.2435
Epoch 070, Loss: 1.3772
Epoch 071, Loss: 1.1078
Epoch 072, Loss: 1.1072
Epoch 073, Loss: 1.0962
Epoch 074, Loss: 0.9842
Epoch 075, Loss: 0.9693
Epoch 076, Loss: 0.9784
Epoch 077, Loss: 0.9837
Epoch 078, Loss: 0.9088
Epoch 079, Loss: 0.9975
Epoch 080, Loss: 1.0751
Epoch 081, Loss: 0.8694
Epoch 082, Loss: 0.9022
Epoch 083, Loss: 0.8347
Epoch 084, Loss: 0.8217
Epoch 085, Loss: 0.8136
Epoch 086, Loss: 0.8657
Epoch 087, Loss: 0.9346
Epoch 088, Loss: 0.7908
Epoch 089, Loss: 0.8460
Epoch 090, Loss: 0.7753
Epoch 091, Loss: 0.8702
Epoch 092, Loss: 0.8630
Epoch 093, Loss: 0.7146
Epoch 094, Loss: 0.7368
Epoch 095, Loss: 0.7560
Epoch 096, Loss: 0.7635
Epoch 097, Loss: 0.7439
Epoch 098, Loss: 0.7537
Epoch 099, Loss: 0.7459
Epoch 100, Loss: 0.7469

Test RMSE: 1.2601
Test MAPE: 0.1862
Training time: 15.19 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7411
Epoch 002, Loss: 3.4096
Epoch 003, Loss: 3.2755
Epoch 004, Loss: 2.8804
Epoch 005, Loss: 1.2997
Epoch 006, Loss: 0.7978
Epoch 007, Loss: 0.7401
Epoch 008, Loss: 0.6718
Epoch 009, Loss: 0.6718
Epoch 010, Loss: 0.7746
Epoch 011, Loss: 0.6514
Epoch 012, Loss: 0.6934
Epoch 013, Loss: 0.6712
Epoch 014, Loss: 0.6090
Epoch 015, Loss: 0.6300
Epoch 016, Loss: 0.6892
Epoch 017, Loss: 0.6524
Epoch 018, Loss: 0.5927
Epoch 019, Loss: 0.6174
Epoch 020, Loss: 0.5701
Epoch 021, Loss: 0.6046
Epoch 022, Loss: 0.5990
Epoch 023, Loss: 0.6320
Epoch 024, Loss: 0.5794
Epoch 025, Loss: 0.5948
Epoch 026, Loss: 0.5994
Epoch 027, Loss: 0.6059
Epoch 028, Loss: 0.5924
Epoch 029, Loss: 0.5717
Epoch 030, Loss: 0.5864
Epoch 031, Loss: 0.5473
Epoch 032, Loss: 0.6053
Epoch 033, Loss: 0.5848
Epoch 034, Loss: 0.5982
Epoch 035, Loss: 0.5694
Epoch 036, Loss: 0.6042
Epoch 037, Loss: 0.6225
Epoch 038, Loss: 0.5234
Epoch 039, Loss: 0.5462
Epoch 040, Loss: 0.5953
Epoch 041, Loss: 0.5674
Epoch 042, Loss: 0.5350
Epoch 043, Loss: 0.5255
Epoch 044, Loss: 0.5310
Epoch 045, Loss: 0.5936
Epoch 046, Loss: 0.5636
Epoch 047, Loss: 0.6575
Epoch 048, Loss: 0.5746
Epoch 049, Loss: 0.5487
Epoch 050, Loss: 0.5283
Epoch 051, Loss: 0.6096
Epoch 052, Loss: 0.5475
Epoch 053, Loss: 0.5298
Epoch 054, Loss: 0.5213
Epoch 055, Loss: 0.5429
Epoch 056, Loss: 0.5841
Epoch 057, Loss: 0.5282
Epoch 058, Loss: 0.5475
Epoch 059, Loss: 0.5253
Epoch 060, Loss: 0.5251
Epoch 061, Loss: 0.5271
Epoch 062, Loss: 0.5361
Epoch 063, Loss: 0.4972
Epoch 064, Loss: 0.5173
Epoch 065, Loss: 0.5333
Epoch 066, Loss: 0.5379
Epoch 067, Loss: 0.5220
Epoch 068, Loss: 0.5244
Epoch 069, Loss: 0.5763
Epoch 070, Loss: 0.5559
Epoch 071, Loss: 0.5745
Epoch 072, Loss: 0.5462
Epoch 073, Loss: 0.5760
Epoch 074, Loss: 0.5284
Epoch 075, Loss: 0.5112
Epoch 076, Loss: 0.5099
Epoch 077, Loss: 0.5904
Epoch 078, Loss: 0.5053
Epoch 079, Loss: 0.5160
Epoch 080, Loss: 0.4988
Epoch 081, Loss: 0.5271
Epoch 082, Loss: 0.5283
Epoch 083, Loss: 0.5431
Epoch 084, Loss: 0.5530
Epoch 085, Loss: 0.5163
Epoch 086, Loss: 0.4844
Epoch 087, Loss: 0.5411
Epoch 088, Loss: 0.4981
Epoch 089, Loss: 0.4872
Epoch 090, Loss: 0.4952
Epoch 091, Loss: 0.5246
Epoch 092, Loss: 0.5102
Epoch 093, Loss: 0.5640
Epoch 094, Loss: 0.5491
Epoch 095, Loss: 0.5213
Epoch 096, Loss: 0.5285
Epoch 097, Loss: 0.5075
Epoch 098, Loss: 0.5110
Epoch 099, Loss: 0.4924
Epoch 100, Loss: 0.5014

Test RMSE: 0.8404
Test MAPE: 416948110229504.0000
Training time: 69.89 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.630246 2.372585e-01      13.642593   GNN_model_10.pkl
       12   Q_values        0.2 0.676657 2.179245e-01      13.189866   GNN_model_12.pkl
       15   Q_values        0.2 0.844860 1.932036e-01      12.565539   GNN_model_15.pkl
       20   Q_values        0.2 0.883776 2.656539e-01      12.855332   GNN_model_20.pkl
       25   Q_values        0.2 1.260141 1.861665e-01      15.189045   GNN_model_25.pkl
     full   Q_values        0.2 0.840449 4.169481e+14      69.892703 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 19%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
