
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59767
 Mean Absolute Percentage Error: 0.25539
 Training time:  0.03010
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.54903
 Mean Absolute Percentage Error: 0.38755
 Training time:  0.01575
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71593
 Mean Absolute Percentage Error: 0.57631
 Training time:  0.05701
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86422
 Mean Absolute Percentage Error: 0.54209
 Training time:  0.01637
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70408
 Mean Absolute Percentage Error: 0.30303
 Training time:  0.03368
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.53100
 Mean Absolute Percentage Error: 0.17111
 Training time:  0.01549
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60461
 Mean Absolute Percentage Error: 0.22743
 Training time:  0.07802
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61264
 Mean Absolute Percentage Error: 0.25196
 Training time:  0.01519
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.52939
 Mean Absolute Percentage Error: 0.16919
 Training time:  0.15091
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.68824
 Mean Absolute Percentage Error: 0.21586
 Training time:  0.03018
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61874
 Mean Absolute Percentage Error: 0.23317
 Training time:  0.17579
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.66387
 Mean Absolute Percentage Error: 0.29013
 Training time:  0.04230
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.59624
  MAPE on 10 nodes subset: 0.25941

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71770
  MAPE on 12 nodes subset: 0.55974

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68213
  MAPE on 15 nodes subset: 0.28335

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58630
  MAPE on 20 nodes subset: 0.22217

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52337
  MAPE on 25 nodes subset: 0.17844

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.597672 0.255391       0.030101       True             4                       MLP_model_10.pkl       36
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.549029 0.387552       0.015746       True             3               MLP_model_10_Circuit.pkl       36
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715925 0.576312       0.057008       True             4                       MLP_model_12.pkl       36
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.864223 0.542090       0.016366       True             4               MLP_model_12_Circuit.pkl       36
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.704082 0.303026       0.033679       True             4                       MLP_model_15.pkl       36
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.531003 0.171107       0.015486       True             3               MLP_model_15_Circuit.pkl       36
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604615 0.227434       0.078021       True             4                       MLP_model_20.pkl       36
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.612642 0.251957       0.015187       True             3               MLP_model_20_Circuit.pkl       36
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.529388 0.169189       0.150913       True             3                       MLP_model_25.pkl       36
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.688241 0.215863       0.030181       True             3               MLP_model_25_Circuit.pkl       36
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.618743 0.233169       0.175790       True             3                     MLP_model_full.pkl       36
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.663871 0.290126       0.042305       True             3             MLP_model_full_Circuit.pkl       36
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.596243 0.259409       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       36
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.717703 0.559741       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       36
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.682125 0.283348       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       36
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586302 0.222172       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       36
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.523373 0.178444       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       36

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.61073
 Mean Absolute Percentage Error: 0.44427
 Training time:  0.34567
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76117
 Mean Absolute Percentage Error: 0.39690
 Training time:  0.24050
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.97971
 Mean Absolute Percentage Error: 0.66085
 Training time:  0.37865
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10337
 Mean Absolute Percentage Error: 0.66272
 Training time:  0.24984
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.61189
 Mean Absolute Percentage Error: 0.18952
 Training time:  0.47209
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.80337
 Mean Absolute Percentage Error: 0.23299
 Training time:  0.24362
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.62730
 Mean Absolute Percentage Error: 0.26165
 Training time:  0.65749
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85001
 Mean Absolute Percentage Error: 0.33010
 Training time:  0.24581
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74380
 Mean Absolute Percentage Error: 0.22788
 Training time:  0.78761
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69141
 Mean Absolute Percentage Error: 0.18255
 Training time:  0.24715
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.72566
 Mean Absolute Percentage Error: 0.30953
 Training time:  3.27914
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74950
 Mean Absolute Percentage Error: 0.29904
 Training time:  0.31025
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22107
  MAPE on 10 nodes subset: 0.02475

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.35830
  MAPE on 12 nodes subset: 0.26971

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13105
  MAPE on 15 nodes subset: 0.01357

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39694
  MAPE on 20 nodes subset: 0.08860

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.22282
  MAPE on 25 nodes subset: 0.02643

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.610734 0.444267       0.345671                           xgboost_model_10.pkl       25
       10             Circuit            50           5          4 0.761170 0.396901       0.240504                   xgboost_model_10_Circuit.pkl       25
       12            Q_values            50          78          4 0.979713 0.660845       0.378647                           xgboost_model_12.pkl       25
       12             Circuit            50           5          4 1.103367 0.662724       0.249839                   xgboost_model_12_Circuit.pkl       25
       15            Q_values            50         120          4 0.611887 0.189516       0.472095                           xgboost_model_15.pkl       25
       15             Circuit            50           5          4 0.803366 0.232988       0.243618                   xgboost_model_15_Circuit.pkl       25
       20            Q_values            50         210          4 0.627302 0.261650       0.657490                           xgboost_model_20.pkl       25
       20             Circuit            50           5          4 0.850007 0.330101       0.245809                   xgboost_model_20_Circuit.pkl       25
       25            Q_values            50         325          4 0.743796 0.227882       0.787607                           xgboost_model_25.pkl       25
       25             Circuit            50           5          4 0.691409 0.182549       0.247148                   xgboost_model_25_Circuit.pkl       25
     full            Q_values           250         325          4 0.725656 0.309527       3.279143                         xgboost_model_full.pkl       25
     full             Circuit           250           5          4 0.749502 0.299037       0.310251                 xgboost_model_full_Circuit.pkl       25
       10 Q_values_full_model            50         325          4 0.221067 0.024749       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       25
       12 Q_values_full_model            50         325          4 0.358299 0.269708       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       25
       15 Q_values_full_model            50         325          4 0.131053 0.013572       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       25
       20 Q_values_full_model            50         325          4 0.396940 0.088601       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       25
       25 Q_values_full_model            50         325          4 0.222820 0.026430       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       25

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.7308
Epoch 002, Loss: 0.5523
Epoch 003, Loss: 0.5659
Epoch 004, Loss: 0.5660
Epoch 005, Loss: 0.6209
Epoch 006, Loss: 0.6119
Epoch 007, Loss: 0.5768
Epoch 008, Loss: 0.6014
Epoch 009, Loss: 0.6043
Epoch 010, Loss: 0.6279
Epoch 011, Loss: 0.5906
Epoch 012, Loss: 0.5698
Epoch 013, Loss: 0.5834
Epoch 014, Loss: 0.5849
Epoch 015, Loss: 0.5470
Epoch 016, Loss: 0.6025
Epoch 017, Loss: 0.5400
Epoch 018, Loss: 0.5489
Epoch 019, Loss: 0.5575
Epoch 020, Loss: 0.5788
Epoch 021, Loss: 0.6003
Epoch 022, Loss: 0.5499
Epoch 023, Loss: 0.5895
Epoch 024, Loss: 0.5479
Epoch 025, Loss: 0.5583
Epoch 026, Loss: 0.6107
Epoch 027, Loss: 0.5367
Epoch 028, Loss: 0.5707
Epoch 029, Loss: 0.5382
Epoch 030, Loss: 0.5462
Epoch 031, Loss: 0.5737
Epoch 032, Loss: 0.5581
Epoch 033, Loss: 0.5336
Epoch 034, Loss: 0.5506
Epoch 035, Loss: 0.5312
Epoch 036, Loss: 0.5280
Epoch 037, Loss: 0.5216
Epoch 038, Loss: 0.5909
Epoch 039, Loss: 0.5736
Epoch 040, Loss: 0.5559
Epoch 041, Loss: 0.5210
Epoch 042, Loss: 0.5614
Epoch 043, Loss: 0.5470
Epoch 044, Loss: 0.5973
Epoch 045, Loss: 0.5376
Epoch 046, Loss: 0.5397
Epoch 047, Loss: 0.5271
Epoch 048, Loss: 0.5773
Epoch 049, Loss: 0.5441
Epoch 050, Loss: 0.5391
Epoch 051, Loss: 0.5541
Epoch 052, Loss: 0.5345
Epoch 053, Loss: 0.5610
Epoch 054, Loss: 0.5371
Epoch 055, Loss: 0.5262
Epoch 056, Loss: 0.5187
Epoch 057, Loss: 0.5473
Epoch 058, Loss: 0.4970
Epoch 059, Loss: 0.5047
Epoch 060, Loss: 0.5343
Epoch 061, Loss: 0.5257
Epoch 062, Loss: 0.5098
Epoch 063, Loss: 0.5077
Epoch 064, Loss: 0.4928
Epoch 065, Loss: 0.4807
Epoch 066, Loss: 0.4904
Epoch 067, Loss: 0.5039
Epoch 068, Loss: 0.4767
Epoch 069, Loss: 0.4944
Epoch 070, Loss: 0.4984
Epoch 071, Loss: 0.5370
Epoch 072, Loss: 0.5097
Epoch 073, Loss: 0.4774
Epoch 074, Loss: 0.4922
Epoch 075, Loss: 0.5169
Epoch 076, Loss: 0.5119
Epoch 077, Loss: 0.5039
Epoch 078, Loss: 0.5078
Epoch 079, Loss: 0.5137
Epoch 080, Loss: 0.4804
Epoch 081, Loss: 0.4768
Epoch 082, Loss: 0.4926
Epoch 083, Loss: 0.4650
Epoch 084, Loss: 0.4828
Epoch 085, Loss: 0.4732
Epoch 086, Loss: 0.5031
Epoch 087, Loss: 0.4685
Epoch 088, Loss: 0.4702
Epoch 089, Loss: 0.4510
Epoch 090, Loss: 0.4520
Epoch 091, Loss: 0.4948
Epoch 092, Loss: 0.4727
Epoch 093, Loss: 0.4699
Epoch 094, Loss: 0.4802
Epoch 095, Loss: 0.4588
Epoch 096, Loss: 0.4871
Epoch 097, Loss: 0.4651
Epoch 098, Loss: 0.4413
Epoch 099, Loss: 0.4874
Epoch 100, Loss: 0.4626

Test RMSE: 0.6361
Test MAPE: 0.2346
Training time: 12.23 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 4.2449
Epoch 002, Loss: 0.8848
Epoch 003, Loss: 0.8636
Epoch 004, Loss: 0.9837
Epoch 005, Loss: 0.8782
Epoch 006, Loss: 0.9737
Epoch 007, Loss: 0.8223
Epoch 008, Loss: 0.8876
Epoch 009, Loss: 0.8502
Epoch 010, Loss: 0.8854
Epoch 011, Loss: 0.9073
Epoch 012, Loss: 0.8600
Epoch 013, Loss: 0.9121
Epoch 014, Loss: 0.8401
Epoch 015, Loss: 0.8548
Epoch 016, Loss: 0.8093
Epoch 017, Loss: 0.8400
Epoch 018, Loss: 0.8332
Epoch 019, Loss: 0.8253
Epoch 020, Loss: 0.8100
Epoch 021, Loss: 0.8151
Epoch 022, Loss: 0.8470
Epoch 023, Loss: 0.8645
Epoch 024, Loss: 0.9608
Epoch 025, Loss: 0.9164
Epoch 026, Loss: 0.8083
Epoch 027, Loss: 0.8005
Epoch 028, Loss: 0.9043
Epoch 029, Loss: 0.7959
Epoch 030, Loss: 0.8077
Epoch 031, Loss: 0.8125
Epoch 032, Loss: 0.8044
Epoch 033, Loss: 0.7817
Epoch 034, Loss: 0.7645
Epoch 035, Loss: 0.8222
Epoch 036, Loss: 0.7728
Epoch 037, Loss: 0.7317
Epoch 038, Loss: 0.7841
Epoch 039, Loss: 0.7605
Epoch 040, Loss: 0.7761
Epoch 041, Loss: 0.7255
Epoch 042, Loss: 0.7942
Epoch 043, Loss: 0.6967
Epoch 044, Loss: 0.7012
Epoch 045, Loss: 0.7544
Epoch 046, Loss: 0.7432
Epoch 047, Loss: 0.7087
Epoch 048, Loss: 0.7093
Epoch 049, Loss: 0.7630
Epoch 050, Loss: 0.7638
Epoch 051, Loss: 0.7012
Epoch 052, Loss: 0.6884
Epoch 053, Loss: 0.6931
Epoch 054, Loss: 0.6770
Epoch 055, Loss: 0.6807
Epoch 056, Loss: 0.6463
Epoch 057, Loss: 0.6399
Epoch 058, Loss: 0.6633
Epoch 059, Loss: 0.6546
Epoch 060, Loss: 0.6438
Epoch 061, Loss: 0.6384
Epoch 062, Loss: 0.6382
Epoch 063, Loss: 0.6371
Epoch 064, Loss: 0.6621
Epoch 065, Loss: 0.6449
Epoch 066, Loss: 0.6214
Epoch 067, Loss: 0.7030
Epoch 068, Loss: 0.6116
Epoch 069, Loss: 0.5959
Epoch 070, Loss: 0.5891
Epoch 071, Loss: 0.6411
Epoch 072, Loss: 0.5982
Epoch 073, Loss: 0.5957
Epoch 074, Loss: 0.6135
Epoch 075, Loss: 0.6110
Epoch 076, Loss: 0.6218
Epoch 077, Loss: 0.5802
Epoch 078, Loss: 0.5797
Epoch 079, Loss: 0.5987
Epoch 080, Loss: 0.5971
Epoch 081, Loss: 0.6026
Epoch 082, Loss: 0.6385
Epoch 083, Loss: 0.6066
Epoch 084, Loss: 0.6070
Epoch 085, Loss: 0.6023
Epoch 086, Loss: 0.5728
Epoch 087, Loss: 0.5724
Epoch 088, Loss: 0.6243
Epoch 089, Loss: 0.5594
Epoch 090, Loss: 0.5662
Epoch 091, Loss: 0.5644
Epoch 092, Loss: 0.5825
Epoch 093, Loss: 0.5741
Epoch 094, Loss: 0.5750
Epoch 095, Loss: 0.5762
Epoch 096, Loss: 0.5731
Epoch 097, Loss: 0.5839
Epoch 098, Loss: 0.5790
Epoch 099, Loss: 0.5498
Epoch 100, Loss: 0.5405

Test RMSE: 0.7287
Test MAPE: 0.2121
Training time: 12.35 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.6950
Epoch 002, Loss: 0.9830
Epoch 003, Loss: 0.9738
Epoch 004, Loss: 0.9643
Epoch 005, Loss: 0.8967
Epoch 006, Loss: 0.9469
Epoch 007, Loss: 0.9057
Epoch 008, Loss: 0.9195
Epoch 009, Loss: 1.0305
Epoch 010, Loss: 1.0670
Epoch 011, Loss: 0.9711
Epoch 012, Loss: 0.9045
Epoch 013, Loss: 1.1669
Epoch 014, Loss: 1.0912
Epoch 015, Loss: 0.9612
Epoch 016, Loss: 0.9350
Epoch 017, Loss: 0.9595
Epoch 018, Loss: 0.9397
Epoch 019, Loss: 1.0040
Epoch 020, Loss: 0.9172
Epoch 021, Loss: 0.8863
Epoch 022, Loss: 0.8781
Epoch 023, Loss: 0.9129
Epoch 024, Loss: 0.9185
Epoch 025, Loss: 1.2173
Epoch 026, Loss: 0.9161
Epoch 027, Loss: 0.8631
Epoch 028, Loss: 0.8303
Epoch 029, Loss: 0.9237
Epoch 030, Loss: 0.9318
Epoch 031, Loss: 0.8944
Epoch 032, Loss: 0.8837
Epoch 033, Loss: 0.8679
Epoch 034, Loss: 0.8585
Epoch 035, Loss: 0.8812
Epoch 036, Loss: 0.8331
Epoch 037, Loss: 0.8625
Epoch 038, Loss: 0.9466
Epoch 039, Loss: 0.9948
Epoch 040, Loss: 0.7979
Epoch 041, Loss: 0.8064
Epoch 042, Loss: 0.7850
Epoch 043, Loss: 0.8282
Epoch 044, Loss: 0.7914
Epoch 045, Loss: 0.8656
Epoch 046, Loss: 0.7602
Epoch 047, Loss: 0.7630
Epoch 048, Loss: 0.7291
Epoch 049, Loss: 0.8013
Epoch 050, Loss: 0.7129
Epoch 051, Loss: 0.7699
Epoch 052, Loss: 0.6954
Epoch 053, Loss: 0.7937
Epoch 054, Loss: 0.6914
Epoch 055, Loss: 0.6857
Epoch 056, Loss: 0.7070
Epoch 057, Loss: 0.7383
Epoch 058, Loss: 0.6995
Epoch 059, Loss: 0.6842
Epoch 060, Loss: 0.6806
Epoch 061, Loss: 0.7009
Epoch 062, Loss: 0.6347
Epoch 063, Loss: 0.6249
Epoch 064, Loss: 0.8018
Epoch 065, Loss: 0.6912
Epoch 066, Loss: 0.7675
Epoch 067, Loss: 0.6426
Epoch 068, Loss: 0.7021
Epoch 069, Loss: 0.5738
Epoch 070, Loss: 0.6193
Epoch 071, Loss: 0.6056
Epoch 072, Loss: 0.6290
Epoch 073, Loss: 0.6003
Epoch 074, Loss: 0.6137
Epoch 075, Loss: 0.6049
Epoch 076, Loss: 0.6161
Epoch 077, Loss: 0.6147
Epoch 078, Loss: 0.6704
Epoch 079, Loss: 0.5900
Epoch 080, Loss: 0.6207
Epoch 081, Loss: 0.5714
Epoch 082, Loss: 0.5484
Epoch 083, Loss: 0.6260
Epoch 084, Loss: 0.6248
Epoch 085, Loss: 0.5456
Epoch 086, Loss: 0.5872
Epoch 087, Loss: 0.5647
Epoch 088, Loss: 0.5720
Epoch 089, Loss: 0.5653
Epoch 090, Loss: 0.5245
Epoch 091, Loss: 0.5225
Epoch 092, Loss: 0.6025
Epoch 093, Loss: 0.5651
Epoch 094, Loss: 0.5068
Epoch 095, Loss: 0.5524
Epoch 096, Loss: 0.5376
Epoch 097, Loss: 0.5232
Epoch 098, Loss: 0.5342
Epoch 099, Loss: 0.5215
Epoch 100, Loss: 0.5505

Test RMSE: 0.7828
Test MAPE: 0.1970
Training time: 12.58 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 8.2034
Epoch 002, Loss: 1.2349
Epoch 003, Loss: 1.2348
Epoch 004, Loss: 1.2570
Epoch 005, Loss: 1.2331
Epoch 006, Loss: 1.2758
Epoch 007, Loss: 1.2173
Epoch 008, Loss: 1.2097
Epoch 009, Loss: 1.1663
Epoch 010, Loss: 1.3419
Epoch 011, Loss: 1.1709
Epoch 012, Loss: 1.1440
Epoch 013, Loss: 1.4054
Epoch 014, Loss: 1.3290
Epoch 015, Loss: 1.2255
Epoch 016, Loss: 1.2452
Epoch 017, Loss: 1.4179
Epoch 018, Loss: 1.4615
Epoch 019, Loss: 1.2082
Epoch 020, Loss: 1.3056
Epoch 021, Loss: 1.2208
Epoch 022, Loss: 1.1570
Epoch 023, Loss: 1.2058
Epoch 024, Loss: 1.1953
Epoch 025, Loss: 1.2205
Epoch 026, Loss: 1.2045
Epoch 027, Loss: 1.1300
Epoch 028, Loss: 1.2696
Epoch 029, Loss: 1.2809
Epoch 030, Loss: 1.2582
Epoch 031, Loss: 1.2417
Epoch 032, Loss: 1.2539
Epoch 033, Loss: 1.2396
Epoch 034, Loss: 1.3287
Epoch 035, Loss: 1.2217
Epoch 036, Loss: 1.1439
Epoch 037, Loss: 1.1542
Epoch 038, Loss: 1.2451
Epoch 039, Loss: 1.1949
Epoch 040, Loss: 1.2171
Epoch 041, Loss: 1.0943
Epoch 042, Loss: 1.3027
Epoch 043, Loss: 1.1663
Epoch 044, Loss: 1.2540
Epoch 045, Loss: 1.3290
Epoch 046, Loss: 1.1723
Epoch 047, Loss: 1.1680
Epoch 048, Loss: 1.2184
Epoch 049, Loss: 1.2403
Epoch 050, Loss: 1.2332
Epoch 051, Loss: 1.2539
Epoch 052, Loss: 1.0743
Epoch 053, Loss: 1.2935
Epoch 054, Loss: 1.1412
Epoch 055, Loss: 1.1451
Epoch 056, Loss: 1.1156
Epoch 057, Loss: 1.3302
Epoch 058, Loss: 1.0902
Epoch 059, Loss: 1.1889
Epoch 060, Loss: 1.1661
Epoch 061, Loss: 1.0493
Epoch 062, Loss: 1.1647
Epoch 063, Loss: 1.1522
Epoch 064, Loss: 1.1445
Epoch 065, Loss: 1.1110
Epoch 066, Loss: 1.2467
Epoch 067, Loss: 1.1434
Epoch 068, Loss: 1.1499
Epoch 069, Loss: 1.1980
Epoch 070, Loss: 1.2049
Epoch 071, Loss: 1.1089
Epoch 072, Loss: 1.0647
Epoch 073, Loss: 1.0874
Epoch 074, Loss: 1.2282
Epoch 075, Loss: 1.1549
Epoch 076, Loss: 0.9672
Epoch 077, Loss: 0.9905
Epoch 078, Loss: 0.9846
Epoch 079, Loss: 0.9523
Epoch 080, Loss: 1.0510
Epoch 081, Loss: 0.9887
Epoch 082, Loss: 0.8914
Epoch 083, Loss: 0.8887
Epoch 084, Loss: 0.8814
Epoch 085, Loss: 0.8936
Epoch 086, Loss: 0.8359
Epoch 087, Loss: 0.8214
Epoch 088, Loss: 0.8362
Epoch 089, Loss: 0.7577
Epoch 090, Loss: 0.7533
Epoch 091, Loss: 0.8591
Epoch 092, Loss: 0.7424
Epoch 093, Loss: 0.7721
Epoch 094, Loss: 0.7395
Epoch 095, Loss: 0.7826
Epoch 096, Loss: 0.6870
Epoch 097, Loss: 0.6836
Epoch 098, Loss: 0.7253
Epoch 099, Loss: 0.7058
Epoch 100, Loss: 0.7263

Test RMSE: 0.9177
Test MAPE: 0.2218
Training time: 12.85 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 12.4490
Epoch 002, Loss: 1.6672
Epoch 003, Loss: 1.5658
Epoch 004, Loss: 1.6053
Epoch 005, Loss: 1.5807
Epoch 006, Loss: 1.9374
Epoch 007, Loss: 1.6211
Epoch 008, Loss: 1.7463
Epoch 009, Loss: 1.8422
Epoch 010, Loss: 1.5141
Epoch 011, Loss: 1.7290
Epoch 012, Loss: 1.6203
Epoch 013, Loss: 1.7230
Epoch 014, Loss: 1.5226
Epoch 015, Loss: 1.5209
Epoch 016, Loss: 1.5500
Epoch 017, Loss: 1.4531
Epoch 018, Loss: 1.6381
Epoch 019, Loss: 1.4971
Epoch 020, Loss: 1.4642
Epoch 021, Loss: 1.5179
Epoch 022, Loss: 1.5560
Epoch 023, Loss: 1.5424
Epoch 024, Loss: 1.4635
Epoch 025, Loss: 1.5793
Epoch 026, Loss: 1.7654
Epoch 027, Loss: 1.5896
Epoch 028, Loss: 1.5887
Epoch 029, Loss: 1.5285
Epoch 030, Loss: 1.6417
Epoch 031, Loss: 1.4993
Epoch 032, Loss: 1.4759
Epoch 033, Loss: 1.5116
Epoch 034, Loss: 1.6306
Epoch 035, Loss: 1.5484
Epoch 036, Loss: 1.4183
Epoch 037, Loss: 1.5663
Epoch 038, Loss: 1.6248
Epoch 039, Loss: 1.6131
Epoch 040, Loss: 1.4259
Epoch 041, Loss: 1.6033
Epoch 042, Loss: 1.6322
Epoch 043, Loss: 1.5139
Epoch 044, Loss: 1.4396
Epoch 045, Loss: 1.5218
Epoch 046, Loss: 1.4158
Epoch 047, Loss: 1.5255
Epoch 048, Loss: 1.4357
Epoch 049, Loss: 1.3641
Epoch 050, Loss: 1.3304
Epoch 051, Loss: 1.2825
Epoch 052, Loss: 1.3552
Epoch 053, Loss: 1.3441
Epoch 054, Loss: 1.4702
Epoch 055, Loss: 1.3087
Epoch 056, Loss: 1.2737
Epoch 057, Loss: 1.2393
Epoch 058, Loss: 1.1716
Epoch 059, Loss: 1.2468
Epoch 060, Loss: 1.0906
Epoch 061, Loss: 1.0914
Epoch 062, Loss: 1.1286
Epoch 063, Loss: 1.0849
Epoch 064, Loss: 1.1269
Epoch 065, Loss: 1.3028
Epoch 066, Loss: 1.1195
Epoch 067, Loss: 1.1694
Epoch 068, Loss: 1.0389
Epoch 069, Loss: 1.0097
Epoch 070, Loss: 1.1370
Epoch 071, Loss: 1.0014
Epoch 072, Loss: 0.9896
Epoch 073, Loss: 0.9732
Epoch 074, Loss: 1.0944
Epoch 075, Loss: 1.1559
Epoch 076, Loss: 1.0318
Epoch 077, Loss: 0.9810
Epoch 078, Loss: 0.9346
Epoch 079, Loss: 0.9738
Epoch 080, Loss: 0.9483
Epoch 081, Loss: 0.9047
Epoch 082, Loss: 1.0848
Epoch 083, Loss: 0.9260
Epoch 084, Loss: 1.0192
Epoch 085, Loss: 0.9547
Epoch 086, Loss: 0.9721
Epoch 087, Loss: 0.9288
Epoch 088, Loss: 1.0634
Epoch 089, Loss: 0.9554
Epoch 090, Loss: 1.0227
Epoch 091, Loss: 0.8682
Epoch 092, Loss: 0.9338
Epoch 093, Loss: 0.8432
Epoch 094, Loss: 0.8975
Epoch 095, Loss: 0.8570
Epoch 096, Loss: 0.8493
Epoch 097, Loss: 1.0222
Epoch 098, Loss: 1.2769
Epoch 099, Loss: 0.8669
Epoch 100, Loss: 0.9273

Test RMSE: 1.3062
Test MAPE: 0.1937
Training time: 13.35 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8922
Epoch 002, Loss: 3.3387
Epoch 003, Loss: 2.4264
Epoch 004, Loss: 0.9836
Epoch 005, Loss: 0.7818
Epoch 006, Loss: 0.8329
Epoch 007, Loss: 0.6546
Epoch 008, Loss: 0.7037
Epoch 009, Loss: 0.7180
Epoch 010, Loss: 0.6207
Epoch 011, Loss: 0.6707
Epoch 012, Loss: 0.6417
Epoch 013, Loss: 0.6567
Epoch 014, Loss: 0.6166
Epoch 015, Loss: 0.6834
Epoch 016, Loss: 0.6223
Epoch 017, Loss: 0.6404
Epoch 018, Loss: 0.6005
Epoch 019, Loss: 0.5935
Epoch 020, Loss: 0.5896
Epoch 021, Loss: 0.6521
Epoch 022, Loss: 0.6019
Epoch 023, Loss: 0.6247
Epoch 024, Loss: 0.5957
Epoch 025, Loss: 0.5649
Epoch 026, Loss: 0.6314
Epoch 027, Loss: 0.5813
Epoch 028, Loss: 0.6281
Epoch 029, Loss: 0.5638
Epoch 030, Loss: 0.5354
Epoch 031, Loss: 0.6716
Epoch 032, Loss: 0.6241
Epoch 033, Loss: 0.5855
Epoch 034, Loss: 0.5830
Epoch 035, Loss: 0.5911
Epoch 036, Loss: 0.6225
Epoch 037, Loss: 0.5462
Epoch 038, Loss: 0.6156
Epoch 039, Loss: 0.5867
Epoch 040, Loss: 0.5753
Epoch 041, Loss: 0.5889
Epoch 042, Loss: 0.5680
Epoch 043, Loss: 0.5482
Epoch 044, Loss: 0.5629
Epoch 045, Loss: 0.5462
Epoch 046, Loss: 0.5567
Epoch 047, Loss: 0.5965
Epoch 048, Loss: 0.5168
Epoch 049, Loss: 0.5881
Epoch 050, Loss: 0.5539
Epoch 051, Loss: 0.5833
Epoch 052, Loss: 0.5543
Epoch 053, Loss: 0.5291
Epoch 054, Loss: 0.4934
Epoch 055, Loss: 0.5693
Epoch 056, Loss: 0.5179
Epoch 057, Loss: 0.5413
Epoch 058, Loss: 0.5796
Epoch 059, Loss: 0.5161
Epoch 060, Loss: 0.5192
Epoch 061, Loss: 0.5412
Epoch 062, Loss: 0.5069
Epoch 063, Loss: 0.5796
Epoch 064, Loss: 0.5631
Epoch 065, Loss: 0.5601
Epoch 066, Loss: 0.5139
Epoch 067, Loss: 0.5452
Epoch 068, Loss: 0.5498
Epoch 069, Loss: 0.5378
Epoch 070, Loss: 0.5060
Epoch 071, Loss: 0.4967
Epoch 072, Loss: 0.5416
Epoch 073, Loss: 0.4726
Epoch 074, Loss: 0.4799
Epoch 075, Loss: 0.5599
Epoch 076, Loss: 0.4809
Epoch 077, Loss: 0.5151
Epoch 078, Loss: 0.4874
Epoch 079, Loss: 0.4711
Epoch 080, Loss: 0.4685
Epoch 081, Loss: 0.5012
Epoch 082, Loss: 0.5077
Epoch 083, Loss: 0.5022
Epoch 084, Loss: 0.5115
Epoch 085, Loss: 0.5193
Epoch 086, Loss: 0.4644
Epoch 087, Loss: 0.4755
Epoch 088, Loss: 0.4787
Epoch 089, Loss: 0.4456
Epoch 090, Loss: 0.4529
Epoch 091, Loss: 0.5249
Epoch 092, Loss: 0.4894
Epoch 093, Loss: 0.4565
Epoch 094, Loss: 0.4806
Epoch 095, Loss: 0.4943
Epoch 096, Loss: 0.4724
Epoch 097, Loss: 0.5341
Epoch 098, Loss: 0.4915
Epoch 099, Loss: 0.4992
Epoch 100, Loss: 0.4312

Test RMSE: 0.7362
Test MAPE: 394411108204544.0000
Training time: 65.08 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.636100 2.346468e-01      12.233388   GNN_model_10.pkl
       12   Q_values        0.2 0.728655 2.120757e-01      12.351321   GNN_model_12.pkl
       15   Q_values        0.2 0.782782 1.969617e-01      12.577179   GNN_model_15.pkl
       20   Q_values        0.2 0.917675 2.218463e-01      12.847931   GNN_model_20.pkl
       25   Q_values        0.2 1.306163 1.937365e-01      13.353464   GNN_model_25.pkl
     full   Q_values        0.2 0.736216 3.944111e+14      65.079110 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 21%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
