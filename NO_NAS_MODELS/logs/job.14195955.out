
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59093
 Mean Absolute Percentage Error: 0.24569
 Training time:  0.11494
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55286
 Mean Absolute Percentage Error: 0.39790
 Training time:  0.08807
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71553
 Mean Absolute Percentage Error: 0.57811
 Training time:  0.12784
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86300
 Mean Absolute Percentage Error: 0.54017
 Training time:  0.01618
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70586
 Mean Absolute Percentage Error: 0.30471
 Training time:  0.03368
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52185
 Mean Absolute Percentage Error: 0.17699
 Training time:  0.05034
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60418
 Mean Absolute Percentage Error: 0.22714
 Training time:  0.04862
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61140
 Mean Absolute Percentage Error: 0.25951
 Training time:  0.04998
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53819
 Mean Absolute Percentage Error: 0.17780
 Training time:  0.09775
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67523
 Mean Absolute Percentage Error: 0.21878
 Training time:  0.01660
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61679
 Mean Absolute Percentage Error: 0.23909
 Training time:  0.10755
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65522
 Mean Absolute Percentage Error: 0.29679
 Training time:  0.02077
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60209
  MAPE on 10 nodes subset: 0.26819

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.70970
  MAPE on 12 nodes subset: 0.57084

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68711
  MAPE on 15 nodes subset: 0.29196

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58619
  MAPE on 20 nodes subset: 0.22604

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.53140
  MAPE on 25 nodes subset: 0.18470

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.590934 0.245693       0.114941       True             3                       MLP_model_10.pkl       93
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.552861 0.397897       0.088073       True             4               MLP_model_10_Circuit.pkl       93
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.715525 0.578107       0.127843       True             4                       MLP_model_12.pkl       93
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.862995 0.540169       0.016180       True             4               MLP_model_12_Circuit.pkl       93
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705860 0.304711       0.033679       True             4                       MLP_model_15.pkl       93
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.521850 0.176985       0.050339       True             4               MLP_model_15_Circuit.pkl       93
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604178 0.227142       0.048619       True             4                       MLP_model_20.pkl       93
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611405 0.259508       0.049984       True             4               MLP_model_20_Circuit.pkl       93
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.538190 0.177802       0.097746       True             4                       MLP_model_25.pkl       93
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.675232 0.218781       0.016600       True             4               MLP_model_25_Circuit.pkl       93
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.616792 0.239090       0.107549       True             4                     MLP_model_full.pkl       93
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.655219 0.296790       0.020768       True             4             MLP_model_full_Circuit.pkl       93
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.602095 0.268187       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       93
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.709704 0.570844       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       93
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.687112 0.291959       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       93
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.586189 0.226041       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       93
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.531398 0.184696       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       93

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59539
 Mean Absolute Percentage Error: 0.43709
 Training time:  0.38439
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76245
 Mean Absolute Percentage Error: 0.39529
 Training time:  0.23932
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.01438
 Mean Absolute Percentage Error: 0.68791
 Training time:  0.35905
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.09625
 Mean Absolute Percentage Error: 0.65901
 Training time:  0.24176
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.63304
 Mean Absolute Percentage Error: 0.19574
 Training time:  0.44694
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.79546
 Mean Absolute Percentage Error: 0.23034
 Training time:  0.23806
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.66188
 Mean Absolute Percentage Error: 0.27976
 Training time:  0.61934
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85027
 Mean Absolute Percentage Error: 0.33096
 Training time:  0.24135
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.74231
 Mean Absolute Percentage Error: 0.23064
 Training time:  0.69159
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.70250
 Mean Absolute Percentage Error: 0.18852
 Training time:  0.23865
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.71333
 Mean Absolute Percentage Error: 0.30248
 Training time:  2.94498
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74912
 Mean Absolute Percentage Error: 0.29928
 Training time:  0.30447
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22549
  MAPE on 10 nodes subset: 0.02577

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.33541
  MAPE on 12 nodes subset: 0.27042

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.13284
  MAPE on 15 nodes subset: 0.01673

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.39095
  MAPE on 20 nodes subset: 0.09186

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.19462
  MAPE on 25 nodes subset: 0.02457

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.595385 0.437094       0.384393                           xgboost_model_10.pkl       35
       10             Circuit            50           5          4 0.762453 0.395286       0.239318                   xgboost_model_10_Circuit.pkl       35
       12            Q_values            50          78          4 1.014379 0.687913       0.359055                           xgboost_model_12.pkl       35
       12             Circuit            50           5          4 1.096255 0.659014       0.241756                   xgboost_model_12_Circuit.pkl       35
       15            Q_values            50         120          4 0.633041 0.195740       0.446937                           xgboost_model_15.pkl       35
       15             Circuit            50           5          4 0.795456 0.230344       0.238064                   xgboost_model_15_Circuit.pkl       35
       20            Q_values            50         210          4 0.661880 0.279755       0.619342                           xgboost_model_20.pkl       35
       20             Circuit            50           5          4 0.850266 0.330959       0.241350                   xgboost_model_20_Circuit.pkl       35
       25            Q_values            50         325          4 0.742313 0.230639       0.691591                           xgboost_model_25.pkl       35
       25             Circuit            50           5          4 0.702499 0.188516       0.238646                   xgboost_model_25_Circuit.pkl       35
     full            Q_values           250         325          4 0.713325 0.302484       2.944982                         xgboost_model_full.pkl       35
     full             Circuit           250           5          4 0.749121 0.299279       0.304467                 xgboost_model_full_Circuit.pkl       35
       10 Q_values_full_model            50         325          4 0.225489 0.025774       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       12 Q_values_full_model            50         325          4 0.335413 0.270422       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       15 Q_values_full_model            50         325          4 0.132837 0.016726       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       20 Q_values_full_model            50         325          4 0.390947 0.091857       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35
       25 Q_values_full_model            50         325          4 0.194622 0.024565       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       35

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.6976
Epoch 002, Loss: 0.5806
Epoch 003, Loss: 0.6902
Epoch 004, Loss: 0.5737
Epoch 005, Loss: 0.5931
Epoch 006, Loss: 0.5654
Epoch 007, Loss: 0.5906
Epoch 008, Loss: 0.5829
Epoch 009, Loss: 0.5801
Epoch 010, Loss: 0.6025
Epoch 011, Loss: 0.6076
Epoch 012, Loss: 0.6418
Epoch 013, Loss: 0.5533
Epoch 014, Loss: 0.5560
Epoch 015, Loss: 0.5651
Epoch 016, Loss: 0.5434
Epoch 017, Loss: 0.6011
Epoch 018, Loss: 0.5841
Epoch 019, Loss: 0.5744
Epoch 020, Loss: 0.5411
Epoch 021, Loss: 0.6355
Epoch 022, Loss: 0.5438
Epoch 023, Loss: 0.5461
Epoch 024, Loss: 0.5628
Epoch 025, Loss: 0.5981
Epoch 026, Loss: 0.5501
Epoch 027, Loss: 0.5529
Epoch 028, Loss: 0.5265
Epoch 029, Loss: 0.5503
Epoch 030, Loss: 0.5331
Epoch 031, Loss: 0.5852
Epoch 032, Loss: 0.5648
Epoch 033, Loss: 0.5573
Epoch 034, Loss: 0.5417
Epoch 035, Loss: 0.5644
Epoch 036, Loss: 0.5416
Epoch 037, Loss: 0.5215
Epoch 038, Loss: 0.5450
Epoch 039, Loss: 0.5487
Epoch 040, Loss: 0.5695
Epoch 041, Loss: 0.5312
Epoch 042, Loss: 0.6161
Epoch 043, Loss: 0.5574
Epoch 044, Loss: 0.5330
Epoch 045, Loss: 0.5247
Epoch 046, Loss: 0.5425
Epoch 047, Loss: 0.5390
Epoch 048, Loss: 0.5332
Epoch 049, Loss: 0.5355
Epoch 050, Loss: 0.5505
Epoch 051, Loss: 0.5228
Epoch 052, Loss: 0.5332
Epoch 053, Loss: 0.5137
Epoch 054, Loss: 0.5249
Epoch 055, Loss: 0.5521
Epoch 056, Loss: 0.5165
Epoch 057, Loss: 0.5261
Epoch 058, Loss: 0.5120
Epoch 059, Loss: 0.5154
Epoch 060, Loss: 0.5303
Epoch 061, Loss: 0.5077
Epoch 062, Loss: 0.5323
Epoch 063, Loss: 0.5164
Epoch 064, Loss: 0.5515
Epoch 065, Loss: 0.5139
Epoch 066, Loss: 0.5137
Epoch 067, Loss: 0.4998
Epoch 068, Loss: 0.5341
Epoch 069, Loss: 0.5062
Epoch 070, Loss: 0.4996
Epoch 071, Loss: 0.4867
Epoch 072, Loss: 0.5499
Epoch 073, Loss: 0.4950
Epoch 074, Loss: 0.5049
Epoch 075, Loss: 0.4961
Epoch 076, Loss: 0.5075
Epoch 077, Loss: 0.5011
Epoch 078, Loss: 0.4937
Epoch 079, Loss: 0.4949
Epoch 080, Loss: 0.5010
Epoch 081, Loss: 0.4719
Epoch 082, Loss: 0.4581
Epoch 083, Loss: 0.4738
Epoch 084, Loss: 0.4757
Epoch 085, Loss: 0.4932
Epoch 086, Loss: 0.4434
Epoch 087, Loss: 0.4651
Epoch 088, Loss: 0.4967
Epoch 089, Loss: 0.4664
Epoch 090, Loss: 0.4402
Epoch 091, Loss: 0.4888
Epoch 092, Loss: 0.4507
Epoch 093, Loss: 0.4550
Epoch 094, Loss: 0.4500
Epoch 095, Loss: 0.4391
Epoch 096, Loss: 0.4277
Epoch 097, Loss: 0.4319
Epoch 098, Loss: 0.4466
Epoch 099, Loss: 0.4278
Epoch 100, Loss: 0.4335

Test RMSE: 0.5987
Test MAPE: 0.2025
Training time: 12.12 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.4268
Epoch 002, Loss: 0.9594
Epoch 003, Loss: 0.9224
Epoch 004, Loss: 0.8559
Epoch 005, Loss: 0.8943
Epoch 006, Loss: 0.9539
Epoch 007, Loss: 0.8764
Epoch 008, Loss: 0.8291
Epoch 009, Loss: 0.8454
Epoch 010, Loss: 0.9332
Epoch 011, Loss: 0.9136
Epoch 012, Loss: 0.8418
Epoch 013, Loss: 0.8486
Epoch 014, Loss: 0.8363
Epoch 015, Loss: 0.8492
Epoch 016, Loss: 0.8183
Epoch 017, Loss: 0.8230
Epoch 018, Loss: 0.8575
Epoch 019, Loss: 0.8497
Epoch 020, Loss: 0.9628
Epoch 021, Loss: 0.8356
Epoch 022, Loss: 0.8946
Epoch 023, Loss: 0.8594
Epoch 024, Loss: 0.8952
Epoch 025, Loss: 0.8779
Epoch 026, Loss: 0.8136
Epoch 027, Loss: 0.8649
Epoch 028, Loss: 0.8581
Epoch 029, Loss: 0.8193
Epoch 030, Loss: 0.8163
Epoch 031, Loss: 0.8626
Epoch 032, Loss: 0.8295
Epoch 033, Loss: 0.8211
Epoch 034, Loss: 0.8586
Epoch 035, Loss: 0.8088
Epoch 036, Loss: 0.8293
Epoch 037, Loss: 0.8079
Epoch 038, Loss: 0.8274
Epoch 039, Loss: 0.8534
Epoch 040, Loss: 0.8356
Epoch 041, Loss: 0.8504
Epoch 042, Loss: 0.8594
Epoch 043, Loss: 0.8139
Epoch 044, Loss: 0.8311
Epoch 045, Loss: 0.8469
Epoch 046, Loss: 0.8501
Epoch 047, Loss: 0.8315
Epoch 048, Loss: 0.8025
Epoch 049, Loss: 0.8281
Epoch 050, Loss: 0.7811
Epoch 051, Loss: 0.7658
Epoch 052, Loss: 0.7960
Epoch 053, Loss: 0.7758
Epoch 054, Loss: 0.7716
Epoch 055, Loss: 0.7569
Epoch 056, Loss: 0.7951
Epoch 057, Loss: 0.7487
Epoch 058, Loss: 0.7418
Epoch 059, Loss: 0.7690
Epoch 060, Loss: 0.7437
Epoch 061, Loss: 0.7504
Epoch 062, Loss: 0.7391
Epoch 063, Loss: 0.7427
Epoch 064, Loss: 0.7495
Epoch 065, Loss: 0.7438
Epoch 066, Loss: 0.7099
Epoch 067, Loss: 0.7129
Epoch 068, Loss: 0.7155
Epoch 069, Loss: 0.7064
Epoch 070, Loss: 0.7073
Epoch 071, Loss: 0.6940
Epoch 072, Loss: 0.6938
Epoch 073, Loss: 0.6737
Epoch 074, Loss: 0.7418
Epoch 075, Loss: 0.6734
Epoch 076, Loss: 0.6712
Epoch 077, Loss: 0.6783
Epoch 078, Loss: 0.7200
Epoch 079, Loss: 0.7234
Epoch 080, Loss: 0.6668
Epoch 081, Loss: 0.7084
Epoch 082, Loss: 0.6721
Epoch 083, Loss: 0.6676
Epoch 084, Loss: 0.6748
Epoch 085, Loss: 0.6335
Epoch 086, Loss: 0.6429
Epoch 087, Loss: 0.6320
Epoch 088, Loss: 0.6174
Epoch 089, Loss: 0.6114
Epoch 090, Loss: 0.6161
Epoch 091, Loss: 0.6249
Epoch 092, Loss: 0.6163
Epoch 093, Loss: 0.6133
Epoch 094, Loss: 0.6262
Epoch 095, Loss: 0.6072
Epoch 096, Loss: 0.6109
Epoch 097, Loss: 0.6467
Epoch 098, Loss: 0.6065
Epoch 099, Loss: 0.6127
Epoch 100, Loss: 0.5931

Test RMSE: 0.6232
Test MAPE: 0.1896
Training time: 12.03 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.6912
Epoch 002, Loss: 1.0298
Epoch 003, Loss: 0.9884
Epoch 004, Loss: 0.9463
Epoch 005, Loss: 0.9176
Epoch 006, Loss: 0.9138
Epoch 007, Loss: 0.9403
Epoch 008, Loss: 0.9043
Epoch 009, Loss: 0.9427
Epoch 010, Loss: 1.0875
Epoch 011, Loss: 1.1192
Epoch 012, Loss: 1.0618
Epoch 013, Loss: 0.9536
Epoch 014, Loss: 1.0198
Epoch 015, Loss: 0.8731
Epoch 016, Loss: 0.9538
Epoch 017, Loss: 0.9501
Epoch 018, Loss: 0.9653
Epoch 019, Loss: 0.8855
Epoch 020, Loss: 0.8904
Epoch 021, Loss: 0.9906
Epoch 022, Loss: 0.9942
Epoch 023, Loss: 0.9617
Epoch 024, Loss: 0.9058
Epoch 025, Loss: 0.9646
Epoch 026, Loss: 0.8961
Epoch 027, Loss: 1.0230
Epoch 028, Loss: 0.8758
Epoch 029, Loss: 0.9089
Epoch 030, Loss: 0.9493
Epoch 031, Loss: 0.9253
Epoch 032, Loss: 0.8985
Epoch 033, Loss: 0.8902
Epoch 034, Loss: 0.9819
Epoch 035, Loss: 1.0228
Epoch 036, Loss: 1.0022
Epoch 037, Loss: 0.9847
Epoch 038, Loss: 0.9163
Epoch 039, Loss: 0.9239
Epoch 040, Loss: 0.9117
Epoch 041, Loss: 0.9887
Epoch 042, Loss: 0.8948
Epoch 043, Loss: 0.8981
Epoch 044, Loss: 0.9383
Epoch 045, Loss: 0.9494
Epoch 046, Loss: 0.9169
Epoch 047, Loss: 0.8690
Epoch 048, Loss: 0.9118
Epoch 049, Loss: 0.9009
Epoch 050, Loss: 0.8872
Epoch 051, Loss: 0.8496
Epoch 052, Loss: 0.8756
Epoch 053, Loss: 0.9055
Epoch 054, Loss: 0.8720
Epoch 055, Loss: 0.9091
Epoch 056, Loss: 0.8676
Epoch 057, Loss: 0.8764
Epoch 058, Loss: 0.8739
Epoch 059, Loss: 0.8787
Epoch 060, Loss: 0.8709
Epoch 061, Loss: 0.8566
Epoch 062, Loss: 0.8686
Epoch 063, Loss: 0.9038
Epoch 064, Loss: 0.8723
Epoch 065, Loss: 0.8846
Epoch 066, Loss: 0.8629
Epoch 067, Loss: 0.8719
Epoch 068, Loss: 0.8461
Epoch 069, Loss: 0.8911
Epoch 070, Loss: 0.8769
Epoch 071, Loss: 0.8929
Epoch 072, Loss: 0.9045
Epoch 073, Loss: 0.9137
Epoch 074, Loss: 0.8549
Epoch 075, Loss: 0.7978
Epoch 076, Loss: 0.7965
Epoch 077, Loss: 0.7755
Epoch 078, Loss: 0.8251
Epoch 079, Loss: 0.7904
Epoch 080, Loss: 0.7631
Epoch 081, Loss: 0.8072
Epoch 082, Loss: 0.7967
Epoch 083, Loss: 0.7633
Epoch 084, Loss: 0.7364
Epoch 085, Loss: 0.7247
Epoch 086, Loss: 0.7244
Epoch 087, Loss: 0.7105
Epoch 088, Loss: 0.6889
Epoch 089, Loss: 0.7197
Epoch 090, Loss: 0.7306
Epoch 091, Loss: 0.6830
Epoch 092, Loss: 0.6472
Epoch 093, Loss: 0.6713
Epoch 094, Loss: 0.6669
Epoch 095, Loss: 0.6861
Epoch 096, Loss: 0.6410
Epoch 097, Loss: 0.6365
Epoch 098, Loss: 0.6636
Epoch 099, Loss: 0.6646
Epoch 100, Loss: 0.6221

Test RMSE: 0.8830
Test MAPE: 0.2466
Training time: 12.20 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.0835
Epoch 002, Loss: 1.3659
Epoch 003, Loss: 1.2252
Epoch 004, Loss: 1.2156
Epoch 005, Loss: 1.2101
Epoch 006, Loss: 1.1937
Epoch 007, Loss: 1.2307
Epoch 008, Loss: 1.3929
Epoch 009, Loss: 1.4183
Epoch 010, Loss: 1.3757
Epoch 011, Loss: 1.1925
Epoch 012, Loss: 1.1861
Epoch 013, Loss: 1.3230
Epoch 014, Loss: 1.2805
Epoch 015, Loss: 1.3234
Epoch 016, Loss: 1.2362
Epoch 017, Loss: 1.1712
Epoch 018, Loss: 1.2045
Epoch 019, Loss: 1.3507
Epoch 020, Loss: 1.2707
Epoch 021, Loss: 1.2164
Epoch 022, Loss: 1.3251
Epoch 023, Loss: 1.2177
Epoch 024, Loss: 1.2083
Epoch 025, Loss: 1.1817
Epoch 026, Loss: 1.2591
Epoch 027, Loss: 1.4851
Epoch 028, Loss: 1.3540
Epoch 029, Loss: 1.1905
Epoch 030, Loss: 1.1708
Epoch 031, Loss: 1.2285
Epoch 032, Loss: 1.1551
Epoch 033, Loss: 1.1946
Epoch 034, Loss: 1.2598
Epoch 035, Loss: 1.2834
Epoch 036, Loss: 1.4345
Epoch 037, Loss: 1.3257
Epoch 038, Loss: 1.2117
Epoch 039, Loss: 1.2831
Epoch 040, Loss: 1.2764
Epoch 041, Loss: 1.2031
Epoch 042, Loss: 1.1740
Epoch 043, Loss: 1.3026
Epoch 044, Loss: 1.1763
Epoch 045, Loss: 1.2605
Epoch 046, Loss: 1.2231
Epoch 047, Loss: 1.2640
Epoch 048, Loss: 1.2495
Epoch 049, Loss: 1.2403
Epoch 050, Loss: 1.3151
Epoch 051, Loss: 1.1387
Epoch 052, Loss: 1.1962
Epoch 053, Loss: 1.1961
Epoch 054, Loss: 1.1672
Epoch 055, Loss: 1.1365
Epoch 056, Loss: 1.1947
Epoch 057, Loss: 1.0962
Epoch 058, Loss: 1.1950
Epoch 059, Loss: 1.0887
Epoch 060, Loss: 1.0223
Epoch 061, Loss: 1.0182
Epoch 062, Loss: 1.0764
Epoch 063, Loss: 0.9523
Epoch 064, Loss: 1.0603
Epoch 065, Loss: 0.9470
Epoch 066, Loss: 0.9413
Epoch 067, Loss: 1.1627
Epoch 068, Loss: 0.9839
Epoch 069, Loss: 0.8858
Epoch 070, Loss: 0.8353
Epoch 071, Loss: 0.8411
Epoch 072, Loss: 0.8022
Epoch 073, Loss: 0.7534
Epoch 074, Loss: 0.8644
Epoch 075, Loss: 0.9943
Epoch 076, Loss: 0.9553
Epoch 077, Loss: 0.7238
Epoch 078, Loss: 0.7623
Epoch 079, Loss: 0.9220
Epoch 080, Loss: 0.8321
Epoch 081, Loss: 0.6573
Epoch 082, Loss: 0.8335
Epoch 083, Loss: 0.6549
Epoch 084, Loss: 0.7006
Epoch 085, Loss: 0.6539
Epoch 086, Loss: 0.7112
Epoch 087, Loss: 0.7142
Epoch 088, Loss: 0.6723
Epoch 089, Loss: 0.6702
Epoch 090, Loss: 0.6521
Epoch 091, Loss: 0.6880
Epoch 092, Loss: 0.6809
Epoch 093, Loss: 0.7219
Epoch 094, Loss: 0.6466
Epoch 095, Loss: 0.6520
Epoch 096, Loss: 0.6369
Epoch 097, Loss: 0.6321
Epoch 098, Loss: 0.5915
Epoch 099, Loss: 0.5950
Epoch 100, Loss: 0.5856

Test RMSE: 1.0264
Test MAPE: 0.2638
Training time: 12.58 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 11.1529
Epoch 002, Loss: 1.7539
Epoch 003, Loss: 1.6333
Epoch 004, Loss: 1.8569
Epoch 005, Loss: 1.6843
Epoch 006, Loss: 1.5735
Epoch 007, Loss: 1.7033
Epoch 008, Loss: 2.1721
Epoch 009, Loss: 1.5956
Epoch 010, Loss: 1.6178
Epoch 011, Loss: 1.6501
Epoch 012, Loss: 1.9630
Epoch 013, Loss: 1.6868
Epoch 014, Loss: 1.5493
Epoch 015, Loss: 1.7196
Epoch 016, Loss: 1.7755
Epoch 017, Loss: 1.6205
Epoch 018, Loss: 1.7097
Epoch 019, Loss: 1.5368
Epoch 020, Loss: 1.7202
Epoch 021, Loss: 1.4860
Epoch 022, Loss: 1.6191
Epoch 023, Loss: 1.5758
Epoch 024, Loss: 1.6081
Epoch 025, Loss: 1.5133
Epoch 026, Loss: 1.5396
Epoch 027, Loss: 1.9649
Epoch 028, Loss: 1.5601
Epoch 029, Loss: 1.4758
Epoch 030, Loss: 1.4753
Epoch 031, Loss: 1.7335
Epoch 032, Loss: 1.5547
Epoch 033, Loss: 1.5261
Epoch 034, Loss: 1.4722
Epoch 035, Loss: 1.5742
Epoch 036, Loss: 1.5526
Epoch 037, Loss: 1.6607
Epoch 038, Loss: 1.5426
Epoch 039, Loss: 1.5129
Epoch 040, Loss: 1.6191
Epoch 041, Loss: 1.5475
Epoch 042, Loss: 1.7053
Epoch 043, Loss: 1.5281
Epoch 044, Loss: 1.5445
Epoch 045, Loss: 1.4908
Epoch 046, Loss: 1.4138
Epoch 047, Loss: 1.5914
Epoch 048, Loss: 1.4914
Epoch 049, Loss: 1.8073
Epoch 050, Loss: 1.5874
Epoch 051, Loss: 1.5098
Epoch 052, Loss: 1.4573
Epoch 053, Loss: 1.5617
Epoch 054, Loss: 1.5008
Epoch 055, Loss: 1.4647
Epoch 056, Loss: 1.7316
Epoch 057, Loss: 1.5302
Epoch 058, Loss: 1.5227
Epoch 059, Loss: 1.4794
Epoch 060, Loss: 1.4748
Epoch 061, Loss: 1.4088
Epoch 062, Loss: 1.4954
Epoch 063, Loss: 1.3688
Epoch 064, Loss: 1.4987
Epoch 065, Loss: 1.5232
Epoch 066, Loss: 1.5037
Epoch 067, Loss: 1.5186
Epoch 068, Loss: 1.6410
Epoch 069, Loss: 1.4632
Epoch 070, Loss: 1.4375
Epoch 071, Loss: 1.4513
Epoch 072, Loss: 1.4111
Epoch 073, Loss: 1.6065
Epoch 074, Loss: 1.3665
Epoch 075, Loss: 1.4573
Epoch 076, Loss: 1.5733
Epoch 077, Loss: 1.8365
Epoch 078, Loss: 1.3903
Epoch 079, Loss: 1.4584
Epoch 080, Loss: 1.3929
Epoch 081, Loss: 1.3597
Epoch 082, Loss: 1.4526
Epoch 083, Loss: 1.4686
Epoch 084, Loss: 1.4581
Epoch 085, Loss: 1.3563
Epoch 086, Loss: 1.3692
Epoch 087, Loss: 1.2595
Epoch 088, Loss: 1.2788
Epoch 089, Loss: 1.2630
Epoch 090, Loss: 1.1766
Epoch 091, Loss: 1.3268
Epoch 092, Loss: 1.2480
Epoch 093, Loss: 1.3601
Epoch 094, Loss: 1.2733
Epoch 095, Loss: 1.1106
Epoch 096, Loss: 1.1309
Epoch 097, Loss: 1.1222
Epoch 098, Loss: 1.0493
Epoch 099, Loss: 1.2563
Epoch 100, Loss: 1.0867

Test RMSE: 1.4902
Test MAPE: 0.2004
Training time: 12.91 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.7627
Epoch 002, Loss: 3.3916
Epoch 003, Loss: 3.2506
Epoch 004, Loss: 3.1572
Epoch 005, Loss: 2.2244
Epoch 006, Loss: 1.1280
Epoch 007, Loss: 1.0231
Epoch 008, Loss: 0.7616
Epoch 009, Loss: 0.7593
Epoch 010, Loss: 0.6762
Epoch 011, Loss: 0.7381
Epoch 012, Loss: 0.6701
Epoch 013, Loss: 0.6771
Epoch 014, Loss: 0.6962
Epoch 015, Loss: 0.6703
Epoch 016, Loss: 0.7574
Epoch 017, Loss: 0.6640
Epoch 018, Loss: 0.6366
Epoch 019, Loss: 0.6269
Epoch 020, Loss: 0.7034
Epoch 021, Loss: 0.6808
Epoch 022, Loss: 0.6109
Epoch 023, Loss: 0.5856
Epoch 024, Loss: 0.6069
Epoch 025, Loss: 0.5506
Epoch 026, Loss: 0.6346
Epoch 027, Loss: 0.6641
Epoch 028, Loss: 0.6401
Epoch 029, Loss: 0.6722
Epoch 030, Loss: 0.6160
Epoch 031, Loss: 0.6461
Epoch 032, Loss: 0.6246
Epoch 033, Loss: 0.6191
Epoch 034, Loss: 0.5979
Epoch 035, Loss: 0.6854
Epoch 036, Loss: 0.6254
Epoch 037, Loss: 0.6083
Epoch 038, Loss: 0.5861
Epoch 039, Loss: 0.6227
Epoch 040, Loss: 0.6004
Epoch 041, Loss: 0.6276
Epoch 042, Loss: 0.5649
Epoch 043, Loss: 0.5343
Epoch 044, Loss: 0.6337
Epoch 045, Loss: 0.5518
Epoch 046, Loss: 0.5911
Epoch 047, Loss: 0.5670
Epoch 048, Loss: 0.6043
Epoch 049, Loss: 0.5509
Epoch 050, Loss: 0.5782
Epoch 051, Loss: 0.5695
Epoch 052, Loss: 0.5692
Epoch 053, Loss: 0.5898
Epoch 054, Loss: 0.6036
Epoch 055, Loss: 0.6097
Epoch 056, Loss: 0.5471
Epoch 057, Loss: 0.5776
Epoch 058, Loss: 0.6009
Epoch 059, Loss: 0.5627
Epoch 060, Loss: 0.6253
Epoch 061, Loss: 0.5642
Epoch 062, Loss: 0.5864
Epoch 063, Loss: 0.5650
Epoch 064, Loss: 0.5743
Epoch 065, Loss: 0.5512
Epoch 066, Loss: 0.5770
Epoch 067, Loss: 0.5480
Epoch 068, Loss: 0.6016
Epoch 069, Loss: 0.5649
Epoch 070, Loss: 0.5639
Epoch 071, Loss: 0.5369
Epoch 072, Loss: 0.5996
Epoch 073, Loss: 0.5682
Epoch 074, Loss: 0.5802
Epoch 075, Loss: 0.5388
Epoch 076, Loss: 0.6002
Epoch 077, Loss: 0.5491
Epoch 078, Loss: 0.5535
Epoch 079, Loss: 0.6343
Epoch 080, Loss: 0.5432
Epoch 081, Loss: 0.6499
Epoch 082, Loss: 0.5659
Epoch 083, Loss: 0.5625
Epoch 084, Loss: 0.5203
Epoch 085, Loss: 0.5554
Epoch 086, Loss: 0.5665
Epoch 087, Loss: 0.5681
Epoch 088, Loss: 0.5425
Epoch 089, Loss: 0.5408
Epoch 090, Loss: 0.5883
Epoch 091, Loss: 0.5603
Epoch 092, Loss: 0.5698
Epoch 093, Loss: 0.5871
Epoch 094, Loss: 0.5401
Epoch 095, Loss: 0.5690
Epoch 096, Loss: 0.5491
Epoch 097, Loss: 0.5432
Epoch 098, Loss: 0.5564
Epoch 099, Loss: 0.5442
Epoch 100, Loss: 0.6027

Test RMSE: 0.7045
Test MAPE: 222764015288320.0000
Training time: 62.97 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.598680 2.025335e-01      12.124820   GNN_model_10.pkl
       12   Q_values        0.2 0.623179 1.895520e-01      12.025078   GNN_model_12.pkl
       15   Q_values        0.2 0.882982 2.465585e-01      12.200453   GNN_model_15.pkl
       20   Q_values        0.2 1.026381 2.637752e-01      12.579902   GNN_model_20.pkl
       25   Q_values        0.2 1.490201 2.003589e-01      12.907977   GNN_model_25.pkl
     full   Q_values        0.2 0.704533 2.227640e+14      62.969905 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 20%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 24%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 25%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 61%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 51%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 88%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
