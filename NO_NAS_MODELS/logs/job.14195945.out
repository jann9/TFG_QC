
 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.59015
 Mean Absolute Percentage Error: 0.24511
 Training time:  0.03934
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.55305
 Mean Absolute Percentage Error: 0.39815
 Training time:  0.06980
 Model saved as Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 0.71830
 Mean Absolute Percentage Error: 0.57140
 Training time:  0.15749
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 0.86321
 Mean Absolute Percentage Error: 0.53988
 Training time:  0.01812
 Model saved as Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.70503
 Mean Absolute Percentage Error: 0.30270
 Training time:  0.03635
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.52200
 Mean Absolute Percentage Error: 0.17705
 Training time:  0.05418
 Model saved as Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.60486
 Mean Absolute Percentage Error: 0.22789
 Training time:  0.06802
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.61155
 Mean Absolute Percentage Error: 0.25969
 Training time:  0.10831
 Model saved as Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.53793
 Mean Absolute Percentage Error: 0.17646
 Training time:  0.17954
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.67485
 Mean Absolute Percentage Error: 0.21885
 Training time:  0.03687
 Model saved as Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.61738
 Mean Absolute Percentage Error: 0.23816
 Training time:  0.18440
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.65488
 Mean Absolute Percentage Error: 0.29679
 Training time:  0.02684
 Model saved as Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.60171
  MAPE on 10 nodes subset: 0.26690

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.71112
  MAPE on 12 nodes subset: 0.56742

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.68547
  MAPE on 15 nodes subset: 0.28911

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.58491
  MAPE on 20 nodes subset: 0.22590

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.52960
  MAPE on 25 nodes subset: 0.18378

Metrics saved to Models/ml_vs_ml/mlp/MLP_Training_metrics.csv

 **Final Training and Cross-Testing Results:**
node_size          model_type  dataset_size  n_features  n_outputs hidden_layers activation solver  test_size     rmse     mape  training_time  converged  n_iterations                             model_file  seeding
       10            Q_values            50          55          4 (128, 64, 32)   logistic  lbfgs        0.2 0.590146 0.245107       0.039340       True             3                       MLP_model_10.pkl       11
       10             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.553055 0.398152       0.069803       True             4               MLP_model_10_Circuit.pkl       11
       12            Q_values            50          78          4 (128, 64, 32)   logistic  lbfgs        0.2 0.718299 0.571396       0.157487       True             3                       MLP_model_12.pkl       11
       12             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.863207 0.539885       0.018124       True             4               MLP_model_12_Circuit.pkl       11
       15            Q_values            50         120          4 (128, 64, 32)   logistic  lbfgs        0.2 0.705033 0.302702       0.036354       True             4                       MLP_model_15.pkl       11
       15             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.522000 0.177053       0.054178       True             4               MLP_model_15_Circuit.pkl       11
       20            Q_values            50         210          4 (128, 64, 32)   logistic  lbfgs        0.2 0.604855 0.227891       0.068020       True             4                       MLP_model_20.pkl       11
       20             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.611545 0.259686       0.108309       True             4               MLP_model_20_Circuit.pkl       11
       25            Q_values            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.537928 0.176458       0.179541       True             4                       MLP_model_25.pkl       11
       25             Circuit            50           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.674854 0.218852       0.036871       True             4               MLP_model_25_Circuit.pkl       11
     full            Q_values           250         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.617379 0.238156       0.184399       True             4                     MLP_model_full.pkl       11
     full             Circuit           250           5          4 (128, 64, 32)   logistic  lbfgs        0.2 0.654883 0.296787       0.026842       True             4             MLP_model_full_Circuit.pkl       11
       10 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.601711 0.266901       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       12 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.711125 0.567416       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       15 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.685473 0.289108       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       20 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.584908 0.225899       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11
       25 Q_values_full_model            50         325          4 (128, 64, 32)   logistic  lbfgs        0.2 0.529598 0.183776       0.000000       True             0 Models/ml_vs_ml/mlp/MLP_model_full.pkl       11

 Training and cross-testing complete for all datasets!

 Training on dataset_10_nodes.csv...
 Root Mean Squared Error: 0.58104
 Mean Absolute Percentage Error: 0.40931
 Training time:  0.43233
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10.pkl

 Training on dataset_10_nodes_Circuit.csv...
 Root Mean Squared Error: 0.76438
 Mean Absolute Percentage Error: 0.39694
 Training time:  0.25225
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl

 Training on dataset_12_nodes.csv...
 Root Mean Squared Error: 1.00174
 Mean Absolute Percentage Error: 0.67051
 Training time:  0.40066
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12.pkl

 Training on dataset_12_nodes_Circuit.csv...
 Root Mean Squared Error: 1.10408
 Mean Absolute Percentage Error: 0.66175
 Training time:  0.25338
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl

 Training on dataset_15_nodes.csv...
 Root Mean Squared Error: 0.62815
 Mean Absolute Percentage Error: 0.19670
 Training time:  0.47058
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15.pkl

 Training on dataset_15_nodes_Circuit.csv...
 Root Mean Squared Error: 0.81147
 Mean Absolute Percentage Error: 0.23548
 Training time:  0.25640
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl

 Training on dataset_20_nodes.csv...
 Root Mean Squared Error: 0.62387
 Mean Absolute Percentage Error: 0.26164
 Training time:  0.68671
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20.pkl

 Training on dataset_20_nodes_Circuit.csv...
 Root Mean Squared Error: 0.85202
 Mean Absolute Percentage Error: 0.33103
 Training time:  0.27323
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl

 Training on dataset_25_nodes.csv...
 Root Mean Squared Error: 0.72693
 Mean Absolute Percentage Error: 0.21331
 Training time:  0.78898
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25.pkl

 Training on dataset_25_nodes_Circuit.csv...
 Root Mean Squared Error: 0.69796
 Mean Absolute Percentage Error: 0.18817
 Training time:  0.25874
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl

 Training on dataset_full.csv...
 Root Mean Squared Error: 0.70989
 Mean Absolute Percentage Error: 0.30507
 Training time:  3.28842
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full.pkl

 Training on dataset_full_Circuit.csv...
 Root Mean Squared Error: 0.74910
 Mean Absolute Percentage Error: 0.29955
 Training time:  0.33121
 Model saved as Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl

=== Testing Full Models on Individual Node Test Sets ===
Full Q-values model loaded successfully

Testing full Q-values model on 10 nodes subset...
  RMSE on 10 nodes subset: 0.22871
  MAPE on 10 nodes subset: 0.02463

Testing full Q-values model on 12 nodes subset...
  RMSE on 12 nodes subset: 0.34215
  MAPE on 12 nodes subset: 0.27719

Testing full Q-values model on 15 nodes subset...
  RMSE on 15 nodes subset: 0.16312
  MAPE on 15 nodes subset: 0.01826

Testing full Q-values model on 20 nodes subset...
  RMSE on 20 nodes subset: 0.36317
  MAPE on 20 nodes subset: 0.07933

Testing full Q-values model on 25 nodes subset...
  RMSE on 25 nodes subset: 0.21500
  MAPE on 25 nodes subset: 0.02689

Metrics saved to Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv

 **Final Training Results:**

 **Final Training Results:**
node_size          model_type  dataset_size  n_features  n_outputs     rmse     mape  training_time                                     model_file  seeding
       10            Q_values            50          55          4 0.581038 0.409309       0.432325                           xgboost_model_10.pkl       94
       10             Circuit            50           5          4 0.764376 0.396937       0.252254                   xgboost_model_10_Circuit.pkl       94
       12            Q_values            50          78          4 1.001741 0.670506       0.400659                           xgboost_model_12.pkl       94
       12             Circuit            50           5          4 1.104079 0.661745       0.253384                   xgboost_model_12_Circuit.pkl       94
       15            Q_values            50         120          4 0.628151 0.196704       0.470582                           xgboost_model_15.pkl       94
       15             Circuit            50           5          4 0.811472 0.235476       0.256402                   xgboost_model_15_Circuit.pkl       94
       20            Q_values            50         210          4 0.623869 0.261642       0.686706                           xgboost_model_20.pkl       94
       20             Circuit            50           5          4 0.852024 0.331028       0.273231                   xgboost_model_20_Circuit.pkl       94
       25            Q_values            50         325          4 0.726927 0.213313       0.788977                           xgboost_model_25.pkl       94
       25             Circuit            50           5          4 0.697962 0.188174       0.258741                   xgboost_model_25_Circuit.pkl       94
     full            Q_values           250         325          4 0.709894 0.305071       3.288418                         xgboost_model_full.pkl       94
     full             Circuit           250           5          4 0.749103 0.299553       0.331213                 xgboost_model_full_Circuit.pkl       94
       10 Q_values_full_model            50         325          4 0.228707 0.024626       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       12 Q_values_full_model            50         325          4 0.342154 0.277193       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       15 Q_values_full_model            50         325          4 0.163121 0.018256       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       20 Q_values_full_model            50         325          4 0.363167 0.079335       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94
       25 Q_values_full_model            50         325          4 0.215005 0.026890       0.000000 Models/ml_vs_ml/xgboost/xgboost_model_full.pkl       94

 Training complete for all datasets!

 Training on dataset_10_nodes.csv...
Total rows in CSV: 50
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
10 55
Loaded 50 valid graphs.
Epoch 001, Loss: 2.5535
Epoch 002, Loss: 0.6088
Epoch 003, Loss: 0.6152
Epoch 004, Loss: 0.5537
Epoch 005, Loss: 0.5866
Epoch 006, Loss: 0.5750
Epoch 007, Loss: 0.6117
Epoch 008, Loss: 0.6309
Epoch 009, Loss: 0.6026
Epoch 010, Loss: 0.6198
Epoch 011, Loss: 0.6138
Epoch 012, Loss: 0.6565
Epoch 013, Loss: 0.5691
Epoch 014, Loss: 0.5873
Epoch 015, Loss: 0.5530
Epoch 016, Loss: 0.5641
Epoch 017, Loss: 0.6342
Epoch 018, Loss: 0.6212
Epoch 019, Loss: 0.6021
Epoch 020, Loss: 0.5717
Epoch 021, Loss: 0.5402
Epoch 022, Loss: 0.5474
Epoch 023, Loss: 0.5447
Epoch 024, Loss: 0.5434
Epoch 025, Loss: 0.6001
Epoch 026, Loss: 0.5572
Epoch 027, Loss: 0.6353
Epoch 028, Loss: 0.5964
Epoch 029, Loss: 0.5071
Epoch 030, Loss: 0.5238
Epoch 031, Loss: 0.5077
Epoch 032, Loss: 0.5177
Epoch 033, Loss: 0.5114
Epoch 034, Loss: 0.5648
Epoch 035, Loss: 0.4942
Epoch 036, Loss: 0.5132
Epoch 037, Loss: 0.4975
Epoch 038, Loss: 0.5062
Epoch 039, Loss: 0.4839
Epoch 040, Loss: 0.4994
Epoch 041, Loss: 0.5279
Epoch 042, Loss: 0.5000
Epoch 043, Loss: 0.5089
Epoch 044, Loss: 0.4878
Epoch 045, Loss: 0.4918
Epoch 046, Loss: 0.5157
Epoch 047, Loss: 0.4862
Epoch 048, Loss: 0.4766
Epoch 049, Loss: 0.5149
Epoch 050, Loss: 0.5114
Epoch 051, Loss: 0.5025
Epoch 052, Loss: 0.4907
Epoch 053, Loss: 0.5029
Epoch 054, Loss: 0.4959
Epoch 055, Loss: 0.4711
Epoch 056, Loss: 0.4855
Epoch 057, Loss: 0.4837
Epoch 058, Loss: 0.4970
Epoch 059, Loss: 0.4758
Epoch 060, Loss: 0.4740
Epoch 061, Loss: 0.4898
Epoch 062, Loss: 0.4761
Epoch 063, Loss: 0.4703
Epoch 064, Loss: 0.4940
Epoch 065, Loss: 0.4398
Epoch 066, Loss: 0.5001
Epoch 067, Loss: 0.4736
Epoch 068, Loss: 0.4745
Epoch 069, Loss: 0.4312
Epoch 070, Loss: 0.4311
Epoch 071, Loss: 0.4581
Epoch 072, Loss: 0.4460
Epoch 073, Loss: 0.4503
Epoch 074, Loss: 0.4550
Epoch 075, Loss: 0.4403
Epoch 076, Loss: 0.4236
Epoch 077, Loss: 0.4418
Epoch 078, Loss: 0.4245
Epoch 079, Loss: 0.4237
Epoch 080, Loss: 0.4245
Epoch 081, Loss: 0.4377
Epoch 082, Loss: 0.4193
Epoch 083, Loss: 0.4750
Epoch 084, Loss: 0.4297
Epoch 085, Loss: 0.4211
Epoch 086, Loss: 0.4220
Epoch 087, Loss: 0.4259
Epoch 088, Loss: 0.4232
Epoch 089, Loss: 0.4182
Epoch 090, Loss: 0.4358
Epoch 091, Loss: 0.4218
Epoch 092, Loss: 0.4212
Epoch 093, Loss: 0.4410
Epoch 094, Loss: 0.4292
Epoch 095, Loss: 0.4188
Epoch 096, Loss: 0.4291
Epoch 097, Loss: 0.4030
Epoch 098, Loss: 0.4147
Epoch 099, Loss: 0.4188
Epoch 100, Loss: 0.4213

Test RMSE: 0.6370
Test MAPE: 0.2299
Training time: 15.96 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_10.pkl

 Training on dataset_12_nodes.csv...
Total rows in CSV: 50
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
12 78
Loaded 50 valid graphs.
Epoch 001, Loss: 3.6512
Epoch 002, Loss: 0.8173
Epoch 003, Loss: 0.8925
Epoch 004, Loss: 0.8945
Epoch 005, Loss: 0.9863
Epoch 006, Loss: 0.8868
Epoch 007, Loss: 0.8680
Epoch 008, Loss: 0.8883
Epoch 009, Loss: 0.9309
Epoch 010, Loss: 0.8247
Epoch 011, Loss: 0.8701
Epoch 012, Loss: 0.8714
Epoch 013, Loss: 0.8508
Epoch 014, Loss: 0.9234
Epoch 015, Loss: 0.8072
Epoch 016, Loss: 0.8872
Epoch 017, Loss: 0.7930
Epoch 018, Loss: 0.8985
Epoch 019, Loss: 0.8870
Epoch 020, Loss: 0.8827
Epoch 021, Loss: 0.8657
Epoch 022, Loss: 0.8343
Epoch 023, Loss: 0.8882
Epoch 024, Loss: 0.9125
Epoch 025, Loss: 0.8910
Epoch 026, Loss: 0.8393
Epoch 027, Loss: 0.8626
Epoch 028, Loss: 0.8503
Epoch 029, Loss: 0.8487
Epoch 030, Loss: 0.8504
Epoch 031, Loss: 0.8436
Epoch 032, Loss: 0.8617
Epoch 033, Loss: 0.8311
Epoch 034, Loss: 0.8487
Epoch 035, Loss: 0.8084
Epoch 036, Loss: 0.8696
Epoch 037, Loss: 0.8540
Epoch 038, Loss: 0.8144
Epoch 039, Loss: 0.8453
Epoch 040, Loss: 0.8291
Epoch 041, Loss: 0.9004
Epoch 042, Loss: 0.8424
Epoch 043, Loss: 0.8163
Epoch 044, Loss: 0.8570
Epoch 045, Loss: 0.8140
Epoch 046, Loss: 0.8491
Epoch 047, Loss: 0.8183
Epoch 048, Loss: 0.8143
Epoch 049, Loss: 0.8031
Epoch 050, Loss: 0.8466
Epoch 051, Loss: 0.8027
Epoch 052, Loss: 0.8251
Epoch 053, Loss: 0.8120
Epoch 054, Loss: 0.7844
Epoch 055, Loss: 0.7674
Epoch 056, Loss: 0.7648
Epoch 057, Loss: 0.7778
Epoch 058, Loss: 0.7921
Epoch 059, Loss: 0.8080
Epoch 060, Loss: 0.7535
Epoch 061, Loss: 0.7546
Epoch 062, Loss: 0.7749
Epoch 063, Loss: 0.7680
Epoch 064, Loss: 0.7407
Epoch 065, Loss: 0.7357
Epoch 066, Loss: 0.7305
Epoch 067, Loss: 0.7437
Epoch 068, Loss: 0.7199
Epoch 069, Loss: 0.7192
Epoch 070, Loss: 0.7191
Epoch 071, Loss: 0.6998
Epoch 072, Loss: 0.7060
Epoch 073, Loss: 0.7191
Epoch 074, Loss: 0.7169
Epoch 075, Loss: 0.7359
Epoch 076, Loss: 0.7054
Epoch 077, Loss: 0.6967
Epoch 078, Loss: 0.6830
Epoch 079, Loss: 0.6736
Epoch 080, Loss: 0.6664
Epoch 081, Loss: 0.6843
Epoch 082, Loss: 0.6333
Epoch 083, Loss: 0.6538
Epoch 084, Loss: 0.6806
Epoch 085, Loss: 0.6546
Epoch 086, Loss: 0.6402
Epoch 087, Loss: 0.6254
Epoch 088, Loss: 0.6079
Epoch 089, Loss: 0.6242
Epoch 090, Loss: 0.6155
Epoch 091, Loss: 0.6654
Epoch 092, Loss: 0.6160
Epoch 093, Loss: 0.6210
Epoch 094, Loss: 0.6110
Epoch 095, Loss: 0.6461
Epoch 096, Loss: 0.5786
Epoch 097, Loss: 0.5967
Epoch 098, Loss: 0.5996
Epoch 099, Loss: 0.5957
Epoch 100, Loss: 0.5838

Test RMSE: 0.7384
Test MAPE: 0.2359
Training time: 16.09 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_12.pkl

 Training on dataset_15_nodes.csv...
Total rows in CSV: 50
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
15 120
Loaded 50 valid graphs.
Epoch 001, Loss: 4.3207
Epoch 002, Loss: 1.0205
Epoch 003, Loss: 0.9784
Epoch 004, Loss: 0.9576
Epoch 005, Loss: 0.9712
Epoch 006, Loss: 0.9016
Epoch 007, Loss: 0.9705
Epoch 008, Loss: 1.0278
Epoch 009, Loss: 0.9794
Epoch 010, Loss: 0.9821
Epoch 011, Loss: 1.0720
Epoch 012, Loss: 1.0064
Epoch 013, Loss: 0.9466
Epoch 014, Loss: 0.9143
Epoch 015, Loss: 0.9119
Epoch 016, Loss: 0.9707
Epoch 017, Loss: 0.9555
Epoch 018, Loss: 0.9339
Epoch 019, Loss: 1.0032
Epoch 020, Loss: 1.0340
Epoch 021, Loss: 0.9087
Epoch 022, Loss: 0.9340
Epoch 023, Loss: 0.9272
Epoch 024, Loss: 0.9555
Epoch 025, Loss: 1.0230
Epoch 026, Loss: 0.9440
Epoch 027, Loss: 1.0041
Epoch 028, Loss: 0.9169
Epoch 029, Loss: 0.9196
Epoch 030, Loss: 0.9359
Epoch 031, Loss: 0.9282
Epoch 032, Loss: 0.9155
Epoch 033, Loss: 0.9998
Epoch 034, Loss: 0.9044
Epoch 035, Loss: 0.9303
Epoch 036, Loss: 0.8903
Epoch 037, Loss: 1.0731
Epoch 038, Loss: 0.9707
Epoch 039, Loss: 0.8768
Epoch 040, Loss: 0.8805
Epoch 041, Loss: 0.9260
Epoch 042, Loss: 0.8572
Epoch 043, Loss: 0.8696
Epoch 044, Loss: 0.9906
Epoch 045, Loss: 0.9023
Epoch 046, Loss: 0.9138
Epoch 047, Loss: 0.8473
Epoch 048, Loss: 0.8953
Epoch 049, Loss: 0.8937
Epoch 050, Loss: 0.9065
Epoch 051, Loss: 0.9576
Epoch 052, Loss: 0.9369
Epoch 053, Loss: 0.8976
Epoch 054, Loss: 0.9593
Epoch 055, Loss: 0.9825
Epoch 056, Loss: 0.9005
Epoch 057, Loss: 0.9438
Epoch 058, Loss: 0.8830
Epoch 059, Loss: 0.9151
Epoch 060, Loss: 0.9404
Epoch 061, Loss: 0.8426
Epoch 062, Loss: 0.9486
Epoch 063, Loss: 0.8788
Epoch 064, Loss: 0.8163
Epoch 065, Loss: 0.8222
Epoch 066, Loss: 0.8247
Epoch 067, Loss: 0.8126
Epoch 068, Loss: 0.7935
Epoch 069, Loss: 0.7677
Epoch 070, Loss: 0.8321
Epoch 071, Loss: 0.7559
Epoch 072, Loss: 0.7507
Epoch 073, Loss: 0.7805
Epoch 074, Loss: 0.7014
Epoch 075, Loss: 0.7343
Epoch 076, Loss: 0.7886
Epoch 077, Loss: 0.7044
Epoch 078, Loss: 0.6829
Epoch 079, Loss: 0.6780
Epoch 080, Loss: 0.6537
Epoch 081, Loss: 0.7332
Epoch 082, Loss: 0.6581
Epoch 083, Loss: 0.7085
Epoch 084, Loss: 0.6452
Epoch 085, Loss: 0.6317
Epoch 086, Loss: 0.6404
Epoch 087, Loss: 0.6710
Epoch 088, Loss: 0.6198
Epoch 089, Loss: 0.7014
Epoch 090, Loss: 0.7192
Epoch 091, Loss: 0.6336
Epoch 092, Loss: 0.6102
Epoch 093, Loss: 0.6185
Epoch 094, Loss: 0.6156
Epoch 095, Loss: 0.6541
Epoch 096, Loss: 0.6720
Epoch 097, Loss: 0.6688
Epoch 098, Loss: 0.6101
Epoch 099, Loss: 0.5905
Epoch 100, Loss: 0.6163

Test RMSE: 0.7766
Test MAPE: 0.2038
Training time: 16.19 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_15.pkl

 Training on dataset_20_nodes.csv...
Total rows in CSV: 50
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
20 210
Loaded 50 valid graphs.
Epoch 001, Loss: 7.0777
Epoch 002, Loss: 1.3434
Epoch 003, Loss: 1.4183
Epoch 004, Loss: 1.3062
Epoch 005, Loss: 1.3285
Epoch 006, Loss: 1.4627
Epoch 007, Loss: 1.2437
Epoch 008, Loss: 1.3542
Epoch 009, Loss: 1.3108
Epoch 010, Loss: 1.2240
Epoch 011, Loss: 1.2616
Epoch 012, Loss: 1.2827
Epoch 013, Loss: 1.2913
Epoch 014, Loss: 1.2092
Epoch 015, Loss: 1.1835
Epoch 016, Loss: 1.2214
Epoch 017, Loss: 1.2238
Epoch 018, Loss: 1.2474
Epoch 019, Loss: 1.1866
Epoch 020, Loss: 1.2779
Epoch 021, Loss: 1.1997
Epoch 022, Loss: 1.1523
Epoch 023, Loss: 1.2261
Epoch 024, Loss: 1.1766
Epoch 025, Loss: 1.1297
Epoch 026, Loss: 1.0825
Epoch 027, Loss: 1.0648
Epoch 028, Loss: 1.0151
Epoch 029, Loss: 1.0821
Epoch 030, Loss: 1.0451
Epoch 031, Loss: 0.9411
Epoch 032, Loss: 0.8940
Epoch 033, Loss: 0.8899
Epoch 034, Loss: 0.9005
Epoch 035, Loss: 0.9693
Epoch 036, Loss: 0.9847
Epoch 037, Loss: 0.8577
Epoch 038, Loss: 0.8466
Epoch 039, Loss: 0.9363
Epoch 040, Loss: 0.8649
Epoch 041, Loss: 0.7519
Epoch 042, Loss: 0.8048
Epoch 043, Loss: 0.7657
Epoch 044, Loss: 0.9875
Epoch 045, Loss: 0.8181
Epoch 046, Loss: 0.7474
Epoch 047, Loss: 0.7800
Epoch 048, Loss: 0.6933
Epoch 049, Loss: 0.9613
Epoch 050, Loss: 0.7597
Epoch 051, Loss: 0.7135
Epoch 052, Loss: 0.7595
Epoch 053, Loss: 0.7598
Epoch 054, Loss: 0.7543
Epoch 055, Loss: 0.6810
Epoch 056, Loss: 0.6823
Epoch 057, Loss: 0.6676
Epoch 058, Loss: 0.7133
Epoch 059, Loss: 0.8257
Epoch 060, Loss: 0.6605
Epoch 061, Loss: 0.6145
Epoch 062, Loss: 0.6639
Epoch 063, Loss: 0.6476
Epoch 064, Loss: 0.6858
Epoch 065, Loss: 0.7233
Epoch 066, Loss: 0.6358
Epoch 067, Loss: 0.6419
Epoch 068, Loss: 0.6154
Epoch 069, Loss: 0.6544
Epoch 070, Loss: 0.6237
Epoch 071, Loss: 0.7771
Epoch 072, Loss: 0.7845
Epoch 073, Loss: 0.6407
Epoch 074, Loss: 0.6483
Epoch 075, Loss: 0.6111
Epoch 076, Loss: 0.6883
Epoch 077, Loss: 0.7027
Epoch 078, Loss: 0.5829
Epoch 079, Loss: 0.6944
Epoch 080, Loss: 0.7128
Epoch 081, Loss: 0.6370
Epoch 082, Loss: 0.5764
Epoch 083, Loss: 0.6464
Epoch 084, Loss: 0.5910
Epoch 085, Loss: 0.6195
Epoch 086, Loss: 0.5919
Epoch 087, Loss: 0.6411
Epoch 088, Loss: 0.5712
Epoch 089, Loss: 0.5754
Epoch 090, Loss: 0.5688
Epoch 091, Loss: 0.6261
Epoch 092, Loss: 0.6211
Epoch 093, Loss: 0.5895
Epoch 094, Loss: 0.5225
Epoch 095, Loss: 0.7385
Epoch 096, Loss: 0.6057
Epoch 097, Loss: 0.5904
Epoch 098, Loss: 0.5831
Epoch 099, Loss: 0.6345
Epoch 100, Loss: 0.5705

Test RMSE: 1.0410
Test MAPE: 0.2228
Training time: 16.72 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_20.pkl

 Training on dataset_25_nodes.csv...
Total rows in CSV: 50
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 50 valid graphs.
Epoch 001, Loss: 10.6300
Epoch 002, Loss: 1.9558
Epoch 003, Loss: 1.7279
Epoch 004, Loss: 1.6646
Epoch 005, Loss: 1.9037
Epoch 006, Loss: 1.7045
Epoch 007, Loss: 1.6543
Epoch 008, Loss: 1.6113
Epoch 009, Loss: 1.7508
Epoch 010, Loss: 1.6217
Epoch 011, Loss: 1.5436
Epoch 012, Loss: 1.5485
Epoch 013, Loss: 1.5445
Epoch 014, Loss: 1.4906
Epoch 015, Loss: 1.5819
Epoch 016, Loss: 1.5083
Epoch 017, Loss: 1.5227
Epoch 018, Loss: 1.7060
Epoch 019, Loss: 1.6267
Epoch 020, Loss: 1.4544
Epoch 021, Loss: 1.5916
Epoch 022, Loss: 1.8102
Epoch 023, Loss: 1.5759
Epoch 024, Loss: 1.5551
Epoch 025, Loss: 1.5783
Epoch 026, Loss: 1.7463
Epoch 027, Loss: 1.7076
Epoch 028, Loss: 1.5658
Epoch 029, Loss: 1.4610
Epoch 030, Loss: 1.4388
Epoch 031, Loss: 1.5536
Epoch 032, Loss: 1.3887
Epoch 033, Loss: 1.5203
Epoch 034, Loss: 1.4427
Epoch 035, Loss: 1.7718
Epoch 036, Loss: 1.4354
Epoch 037, Loss: 1.4302
Epoch 038, Loss: 1.3042
Epoch 039, Loss: 1.2982
Epoch 040, Loss: 1.2446
Epoch 041, Loss: 1.3093
Epoch 042, Loss: 1.1644
Epoch 043, Loss: 1.2432
Epoch 044, Loss: 1.2390
Epoch 045, Loss: 1.2224
Epoch 046, Loss: 1.0252
Epoch 047, Loss: 1.2155
Epoch 048, Loss: 1.1100
Epoch 049, Loss: 1.1561
Epoch 050, Loss: 0.9655
Epoch 051, Loss: 0.9717
Epoch 052, Loss: 1.0978
Epoch 053, Loss: 1.0385
Epoch 054, Loss: 1.0629
Epoch 055, Loss: 0.9405
Epoch 056, Loss: 0.9814
Epoch 057, Loss: 0.9680
Epoch 058, Loss: 1.0491
Epoch 059, Loss: 0.9835
Epoch 060, Loss: 0.8818
Epoch 061, Loss: 0.9406
Epoch 062, Loss: 0.8106
Epoch 063, Loss: 0.9412
Epoch 064, Loss: 0.8675
Epoch 065, Loss: 0.8250
Epoch 066, Loss: 0.9489
Epoch 067, Loss: 0.8634
Epoch 068, Loss: 0.9040
Epoch 069, Loss: 0.8550
Epoch 070, Loss: 0.8831
Epoch 071, Loss: 0.8353
Epoch 072, Loss: 0.8414
Epoch 073, Loss: 0.7573
Epoch 074, Loss: 0.8562
Epoch 075, Loss: 0.8195
Epoch 076, Loss: 0.7780
Epoch 077, Loss: 0.8098
Epoch 078, Loss: 0.8221
Epoch 079, Loss: 0.8019
Epoch 080, Loss: 0.8410
Epoch 081, Loss: 0.7433
Epoch 082, Loss: 0.7162
Epoch 083, Loss: 0.7713
Epoch 084, Loss: 0.9281
Epoch 085, Loss: 0.8967
Epoch 086, Loss: 0.6934
Epoch 087, Loss: 0.7143
Epoch 088, Loss: 0.8326
Epoch 089, Loss: 0.9106
Epoch 090, Loss: 0.7186
Epoch 091, Loss: 0.7751
Epoch 092, Loss: 0.6728
Epoch 093, Loss: 0.7185
Epoch 094, Loss: 0.7180
Epoch 095, Loss: 0.6919
Epoch 096, Loss: 0.6868
Epoch 097, Loss: 0.6840
Epoch 098, Loss: 0.6327
Epoch 099, Loss: 0.6324
Epoch 100, Loss: 0.6790

Test RMSE: 1.4045
Test MAPE: 0.1949
Training time: 17.05 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_25.pkl

 Training on dataset_full.csv...
Total rows in CSV: 250
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
25 325
Loaded 250 valid graphs.
Epoch 001, Loss: 3.8479
Epoch 002, Loss: 3.2639
Epoch 003, Loss: 2.7246
Epoch 004, Loss: 1.0983
Epoch 005, Loss: 0.7685
Epoch 006, Loss: 0.6724
Epoch 007, Loss: 0.7192
Epoch 008, Loss: 0.7172
Epoch 009, Loss: 0.6612
Epoch 010, Loss: 0.6328
Epoch 011, Loss: 0.6402
Epoch 012, Loss: 0.6658
Epoch 013, Loss: 0.7314
Epoch 014, Loss: 0.6897
Epoch 015, Loss: 0.5958
Epoch 016, Loss: 0.6607
Epoch 017, Loss: 0.7206
Epoch 018, Loss: 0.6367
Epoch 019, Loss: 0.6605
Epoch 020, Loss: 0.6075
Epoch 021, Loss: 0.6254
Epoch 022, Loss: 0.6097
Epoch 023, Loss: 0.6526
Epoch 024, Loss: 0.6985
Epoch 025, Loss: 0.6315
Epoch 026, Loss: 0.6167
Epoch 027, Loss: 0.6203
Epoch 028, Loss: 0.5999
Epoch 029, Loss: 0.6073
Epoch 030, Loss: 0.6070
Epoch 031, Loss: 0.6079
Epoch 032, Loss: 0.5760
Epoch 033, Loss: 0.5636
Epoch 034, Loss: 0.5773
Epoch 035, Loss: 0.6165
Epoch 036, Loss: 0.5704
Epoch 037, Loss: 0.5951
Epoch 038, Loss: 0.5875
Epoch 039, Loss: 0.5357
Epoch 040, Loss: 0.5704
Epoch 041, Loss: 0.5838
Epoch 042, Loss: 0.5612
Epoch 043, Loss: 0.5535
Epoch 044, Loss: 0.5900
Epoch 045, Loss: 0.5834
Epoch 046, Loss: 0.5666
Epoch 047, Loss: 0.5775
Epoch 048, Loss: 0.5571
Epoch 049, Loss: 0.5981
Epoch 050, Loss: 0.5384
Epoch 051, Loss: 0.5427
Epoch 052, Loss: 0.4966
Epoch 053, Loss: 0.5296
Epoch 054, Loss: 0.5286
Epoch 055, Loss: 0.5396
Epoch 056, Loss: 0.5093
Epoch 057, Loss: 0.5622
Epoch 058, Loss: 0.5858
Epoch 059, Loss: 0.5473
Epoch 060, Loss: 0.5957
Epoch 061, Loss: 0.5528
Epoch 062, Loss: 0.5280
Epoch 063, Loss: 0.5333
Epoch 064, Loss: 0.5037
Epoch 065, Loss: 0.5409
Epoch 066, Loss: 0.4991
Epoch 067, Loss: 0.5492
Epoch 068, Loss: 0.5583
Epoch 069, Loss: 0.5373
Epoch 070, Loss: 0.5286
Epoch 071, Loss: 0.5307
Epoch 072, Loss: 0.5152
Epoch 073, Loss: 0.5164
Epoch 074, Loss: 0.5611
Epoch 075, Loss: 0.5008
Epoch 076, Loss: 0.5233
Epoch 077, Loss: 0.5264
Epoch 078, Loss: 0.5112
Epoch 079, Loss: 0.5109
Epoch 080, Loss: 0.5430
Epoch 081, Loss: 0.5178
Epoch 082, Loss: 0.4842
Epoch 083, Loss: 0.5270
Epoch 084, Loss: 0.5036
Epoch 085, Loss: 0.5267
Epoch 086, Loss: 0.5484
Epoch 087, Loss: 0.4827
Epoch 088, Loss: 0.4887
Epoch 089, Loss: 0.5064
Epoch 090, Loss: 0.5578
Epoch 091, Loss: 0.4962
Epoch 092, Loss: 0.5616
Epoch 093, Loss: 0.5065
Epoch 094, Loss: 0.4827
Epoch 095, Loss: 0.4779
Epoch 096, Loss: 0.4920
Epoch 097, Loss: 0.4961
Epoch 098, Loss: 0.5210
Epoch 099, Loss: 0.5155
Epoch 100, Loss: 0.5010

Test RMSE: 0.8073
Test MAPE: 295246588018688.0000
Training time: 83.90 seconds
Model saved to Models/ml_vs_ml/gnn/GCN_model_full.pkl

Metrics saved to Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv

 **Final Training Results:**
node_size model_type  test_size     rmse         mape  training_time         model_file
       10   Q_values        0.2 0.637000 2.299090e-01      15.962148   GNN_model_10.pkl
       12   Q_values        0.2 0.738411 2.359121e-01      16.092380   GNN_model_12.pkl
       15   Q_values        0.2 0.776592 2.037753e-01      16.186093   GNN_model_15.pkl
       20   Q_values        0.2 1.040984 2.228040e-01      16.723825   GNN_model_20.pkl
       25   Q_values        0.2 1.404467 1.949268e-01      17.053182   GNN_model_25.pkl
     full   Q_values        0.2 0.807337 2.952466e+14      83.900000 GNN_model_full.pkl

 Training complete for all datasets!
  adding: Models/ml_vs_ml/gnn/ (stored 0%)
  adding: Models/ml_vs_ml/gnn/GCN_model_15.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_results.txt (deflated 60%)
  adding: Models/ml_vs_ml/gnn/GCN_model_10.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_25.pkl (deflated 21%)
  adding: Models/ml_vs_ml/gnn/Graph_Neural_Training_metrics.csv (deflated 50%)
  adding: Models/ml_vs_ml/gnn/GCN_model_full.pkl (deflated 22%)
  adding: Models/ml_vs_ml/gnn/GCN_model_12.pkl (deflated 23%)
  adding: Models/ml_vs_ml/gnn/GCN_model_20.pkl (deflated 22%)
  adding: Models/ml_vs_ml/mlp/ (stored 0%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_Training_metrics.csv (deflated 68%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_15_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_25_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_10.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/MLP_model_full.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20.pkl (deflated 4%)
  adding: Models/ml_vs_ml/mlp/MLP_model_20_Circuit.pkl (deflated 5%)
  adding: Models/ml_vs_ml/mlp/Neural_Training_results.txt (deflated 73%)
  adding: Models/ml_vs_ml/mlp/MLP_model_12.pkl (deflated 5%)
  adding: Models/ml_vs_ml/xgboost/ (stored 0%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full_Circuit.pkl (deflated 81%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_10.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12.pkl (deflated 86%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_12_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20.pkl (deflated 87%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_15_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_metrics.csv (deflated 63%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_full.pkl (deflated 79%)
  adding: Models/ml_vs_ml/xgboost/XGB_Training_results.txt (deflated 72%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_20_Circuit.pkl (deflated 83%)
  adding: Models/ml_vs_ml/xgboost/xgboost_model_25.pkl (deflated 87%)
